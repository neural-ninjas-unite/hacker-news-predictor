{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import more_itertools\n",
    "import random\n",
    "from torchmetrics import Accuracy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tokenisation-related libraries\n",
    "import re\n",
    "from typing import Union, List\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "# Setup random seed\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all necessary NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 characters:\n",
      " anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or anomie but rather a harmonious anti authoritarian society in place of what are regarded as authoritarian political structures and coercive economic instituti\n",
      "\n",
      "Total characters: 100000000\n",
      "\n",
      "Total words (raw split): 17005207\n",
      "Initial vocabulary size: 253854\n"
     ]
    }
   ],
   "source": [
    "# Read the text8 file\n",
    "with open('../scripts/text8', 'r', encoding='utf-8') as file:\n",
    "    text8_data = file.read()\n",
    "\n",
    "# Print first few characters to verify\n",
    "print(\"First 100 characters:\")\n",
    "print(text8_data[:1000])\n",
    "\n",
    "# Print total length\n",
    "print(f\"\\nTotal characters: {len(text8_data)}\")\n",
    "\n",
    "# Get initial word count (simple split)\n",
    "initial_words = text8_data.split()\n",
    "characters = len(text8_data) / 100\n",
    "print(f\"\\nTotal words (raw split): {len(initial_words)}\")\n",
    "print(f\"Initial vocabulary size: {len(set(initial_words))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>nasa's 3d-printed rotating detonation rocket e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.0</td>\n",
       "      <td>heat pumps of the 1800s are becoming the techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>why you should develop local-first web apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tool to make twitter archive publishable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>fedora packages versus upstream flatpaks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                              title\n",
       "0    8.0  nasa's 3d-printed rotating detonation rocket e...\n",
       "1   62.0  heat pumps of the 1800s are becoming the techn...\n",
       "2    1.0        why you should develop local-first web apps\n",
       "3    1.0           tool to make twitter archive publishable\n",
       "4    2.0           fedora packages versus upstream flatpaks"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../HN Score, Title 10k.csv')\n",
    "df.title = df.title.str.lower()\n",
    "df.dropna(inplace= True) # Remove rows with incomplete data\n",
    "\n",
    "# Convert titles to a single string\n",
    "titles_text = ' '.join(df.title.astype(str).tolist())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# num_lines = 10000\n",
    "# lines = df.title.tolist()[:num_lines]\n",
    "\n",
    "# for i in df.title[:num_lines]:\n",
    "#     for j in str(i).split():\n",
    "#         if j not in words and j != \"nan\":\n",
    "#             words.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itos = {num:word for num, word in zip(range(len(words)),words)}\n",
    "# stoi = {word:num for num,word in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text_input: Union[str, List[str]], min_freq: int = 5) -> tuple[List[str], dict]:\n",
    "    \"\"\"\n",
    "    Preprocess text input and create vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Define special tokens using a marker that word_tokenize won't split\n",
    "    SPECIAL_TOKENS = {\n",
    "        '.': 'XPERIODX',\n",
    "        ',': 'XCOMMAX',\n",
    "        '\"': 'XQUOTATION_MARKX',\n",
    "        ';': 'XSEMICOLONX',\n",
    "        '!': 'XEXCLAMATION_MARKX',\n",
    "        '?': 'XQUESTION_MARKX',\n",
    "        '(': 'XLEFT_PARENX',\n",
    "        ')': 'XRIGHT_PARENX',\n",
    "        '--': 'XHYPHENSX',\n",
    "        ':': 'XCOLONX',\n",
    "        \"'\": 'XAPOSTROPHEX'\n",
    "    }\n",
    "    \n",
    "    # Mapping for restoring angle brackets\n",
    "    RESTORE_TOKENS = {\n",
    "        f'XPERIODX': '<PERIOD>',\n",
    "        f'XCOMMAX': '<COMMA>',\n",
    "        f'XQUOTATION_MARKX': '<QUOTATION_MARK>',\n",
    "        f'XSEMICOLONX': '<SEMICOLON>',\n",
    "        f'XEXCLAMATION_MARKX': '<EXCLAMATION_MARK>',\n",
    "        f'XQUESTION_MARKX': '<QUESTION_MARK>',\n",
    "        f'XLEFT_PARENX': '<LEFT_PAREN>',\n",
    "        f'XRIGHT_PARENX': '<RIGHT_PAREN>',\n",
    "        f'XHYPHENSX': '<HYPHENS>',\n",
    "        f'XCOLONX': '<COLON>',\n",
    "        f'XAPOSTROPHEX': '<APOSTROPHE>'\n",
    "    }\n",
    "    \n",
    "    def clean_text(text: str) -> str:\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Replace special characters with temporary tokens\n",
    "        for char, token in SPECIAL_TOKENS.items():\n",
    "            text = text.replace(char, f' {token} ')\n",
    "        \n",
    "        # Remove special characters and extra whitespace\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s_X]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    # Convert input to list of sentences\n",
    "    if isinstance(text_input, str):\n",
    "        sentences = sent_tokenize(text_input)\n",
    "    elif isinstance(text_input, list):\n",
    "        sentences = []\n",
    "        for line in text_input:\n",
    "            if isinstance(line, str):\n",
    "                try:\n",
    "                    sentences.extend(sent_tokenize(line))\n",
    "                except:\n",
    "                    sentences.append(line)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a string or list of strings\")\n",
    "\n",
    "    # Process all sentences\n",
    "    processed_words = []\n",
    "    for sentence in sentences:\n",
    "        # Clean the text\n",
    "        cleaned_text = clean_text(sentence)\n",
    "        # Tokenize\n",
    "        try:\n",
    "            words = word_tokenize(cleaned_text)\n",
    "            # Restore angle bracket format\n",
    "            words = [RESTORE_TOKENS.get(word, word) for word in words]\n",
    "            # Apply lemmatization only to non-special tokens\n",
    "            words = [word if word in RESTORE_TOKENS.values() \n",
    "                    else lemmatizer.lemmatize(word) \n",
    "                    for word in words]\n",
    "        except:\n",
    "            words = cleaned_text.split()\n",
    "        processed_words.extend(words)\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(processed_words)\n",
    "    \n",
    "    # Create vocabulary (only including words that meet minimum frequency)\n",
    "    vocab = [word for word, count in word_counts.items() if count >= min_freq]\n",
    "    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    # Filter words based on vocabulary\n",
    "    processed_words = [word for word in processed_words if word in word_to_idx]\n",
    "    \n",
    "    return processed_words, word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process text inputs, receive tokens and word to index dictionary\n",
    "# processed_words, word_to_idx = preprocess_text(text8_data, min_freq=5)\n",
    "\n",
    "# # Set vocab_size, determine dimensions of layers in model\n",
    "# vocab_size = len(word_to_idx)\n",
    "\n",
    "# len(processed_words)\n",
    "# len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 1\n",
    "\n",
    "def create_skipgram_pairs(processed_words: List[str], \n",
    "                         word_to_idx: dict, \n",
    "                         context_len: int = 3) -> tuple[List[int], List[List[int]]]:\n",
    "    \"\"\"\n",
    "    Create skipgram pairs from a list of processed words.\n",
    "    \"\"\"\n",
    "    if context_len % 2 == 0:\n",
    "        raise ValueError(\"context_len should be an odd number\")\n",
    "        \n",
    "    window_radius = context_len // 2\n",
    "    input_indices = []\n",
    "    context_indices = []\n",
    "    vocab_size = len(word_to_idx)  # Added this line\n",
    "    \n",
    "    # Use sliding window to create pairs\n",
    "    windows = list(more_itertools.windowed(processed_words, context_len))\n",
    "    \n",
    "    for window in windows:\n",
    "        if None in window:  # Skip incomplete windows\n",
    "            continue\n",
    "            \n",
    "        # Get center word and context\n",
    "        center_word = window[window_radius]\n",
    "        context = list(window[:window_radius]) + list(window[window_radius + 1:])\n",
    "        \n",
    "        # Only add if all words are in vocabulary AND indices are within range\n",
    "        if center_word in word_to_idx and all(w in word_to_idx for w in context):\n",
    "            center_idx = word_to_idx[center_word]\n",
    "            context_idxs = [word_to_idx[w] for w in context]\n",
    "            \n",
    "            # Added this check\n",
    "            if center_idx < vocab_size and all(idx < vocab_size for idx in context_idxs):\n",
    "                input_indices.append(center_idx)\n",
    "                context_indices.append(context_idxs)\n",
    "    \n",
    "    return input_indices, context_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_skipgram_pairs(processed_words: List[str], \n",
    "#                          word_to_idx: dict, \n",
    "#                          context_len: int = 3) -> tuple[List[int], List[List[int]]]:\n",
    "#     \"\"\"\n",
    "#     Create skipgram pairs from a list of processed words.\n",
    "#     \"\"\"\n",
    "#     if context_len % 2 == 0:\n",
    "#         raise ValueError(\"context_len should be an odd number\")\n",
    "        \n",
    "#     window_radius = context_len // 2\n",
    "#     input_indices = []\n",
    "#     context_indices = []\n",
    "    \n",
    "#     # Use sliding window to create pairs\n",
    "#     windows = list(more_itertools.windowed(processed_words, context_len))\n",
    "    \n",
    "#     for window in windows:\n",
    "#         if None in window:  # Skip incomplete windows\n",
    "#             continue\n",
    "            \n",
    "#         # Get center word and context\n",
    "#         center_word = window[window_radius]\n",
    "#         context = list(window[:window_radius]) + list(window[window_radius + 1:])\n",
    "        \n",
    "#         # Only add if all words are in vocabulary\n",
    "#         if center_word in word_to_idx and all(w in word_to_idx for w in context):\n",
    "#             input_indices.append(word_to_idx[center_word])\n",
    "#             context_indices.append([word_to_idx[w] for w in context])\n",
    "    \n",
    "#     return input_indices, context_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3727\n",
      "Original text vocabulary size: 17069112\n",
      "Dataset size: 149736\n",
      "Sample from vocabulary: ['anarchism', 'originated', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early']\n",
      "Sample from processed words: ['anarchism', 'originated', 'a', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n",
      "X shape:  torch.Size([149736]) ; Y shape:  torch.Size([149736, 2]) ; Shapes compatible:  True\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the Wikipedia & Hacker News datasets\n",
    "combined_text = text8_data + \" \" + titles_text\n",
    "\n",
    "# Determine input size\n",
    "input=text8_data[:int(len(combined_text)/100)]\n",
    "\n",
    "# Process text inputs, receive tokens and word to index dictionary\n",
    "processed_words, word_to_idx = preprocess_text(input, min_freq=5)\n",
    "\n",
    "# Set vocab_size, determine dimensions of layers in model\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "# Set context length\n",
    "context_len = 3\n",
    "\n",
    "# Create Skip-gram dataset using processed, tokenized text input:\n",
    "input_indices, context_indices = create_skipgram_pairs(processed_words, word_to_idx, context_len)\n",
    "\n",
    "# Convert dataset indices to tensors\n",
    "X = torch.tensor(input_indices, dtype=torch.long)\n",
    "Y = torch.tensor(context_indices, dtype=torch.long)\n",
    "\n",
    "# Debug prints\n",
    "print(\"Vocabulary size:\", len(word_to_idx))\n",
    "print(\"Original text vocabulary size:\", len(combined_text.split()))\n",
    "print(\"Dataset size:\", len(input_indices))\n",
    "print(\"Sample from vocabulary:\", list(word_to_idx.keys())[:10])\n",
    "print(\"Sample from processed words:\", processed_words[:10])\n",
    "print(\"X shape: \", X.shape, \"; Y shape: \", Y.shape, \"; Shapes compatible: \", X.shape[0] == Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from vocabulary: ['anarchism', 'originated', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample from vocabulary:\", list(word_to_idx)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([[ 0,  2],\n",
       "         [ 1,  2],\n",
       "         [ 2,  3],\n",
       "         [ 2,  4],\n",
       "         [ 3,  5],\n",
       "         [ 4,  6],\n",
       "         [ 5,  7],\n",
       "         [ 6,  8],\n",
       "         [ 7,  9],\n",
       "         [ 8, 10]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Samples of tensors\n",
    "X[:10], Y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 149736 ; context length: 3 ; vocab size: 3727\n"
     ]
    }
   ],
   "source": [
    "inputs_len = len(X)\n",
    "print(\"Dataset size:\", inputs_len, \"; context length:\", context_len, \"; vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set embedding dimensions\n",
    "emb_dims = 20\n",
    "\n",
    "# Build Word2Vec model\n",
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dims):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeddings = nn.Embedding(num_embeddings= vocab_size, embedding_dim= emb_dims)\n",
    "        self.output_weights = nn.Linear(in_features = emb_dims, out_features = vocab_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, positive_samples, negative_samples):\n",
    "        # Add dimension checks\n",
    "        if x.max() >= self.vocab_size or positive_samples.max() >= self.vocab_size or negative_samples.max() >= self.vocab_size:\n",
    "            raise ValueError(f\"Input indices must be less than vocab_size ({self.vocab_size})\")\n",
    "\n",
    "        emb = self.embeddings(x)\n",
    "        context_weights = self.output_weights.weight[positive_samples]\n",
    "        negative_sample_weights = self.output_weights.weight[negative_samples]\n",
    "        positive_out = torch.bmm(context_weights, emb.unsqueeze(-1)).squeeze(-1)\n",
    "        negative_out = torch.bmm(negative_sample_weights, emb.unsqueeze(-1)).squeeze(-1)\n",
    "        positive_out = self.sigmoid(positive_out)\n",
    "        negative_out = self.sigmoid(negative_out)\n",
    "        positive_loss = -positive_out.log().mean()\n",
    "        negative_loss = -(1 - negative_out + 10**(-3)).log().mean()\n",
    "        return positive_loss + negative_loss\n",
    "\n",
    "# Instantiate model\n",
    "word2vec = Word2Vec(vocab_size = vocab_size, emb_dims= emb_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss function\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Set up optimizer to optimize model's parameters\n",
    "optimiser = torch.optim.SGD(params= word2vec.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, X, Y, vocab_size):\n",
    "    \"\"\"\n",
    "    Calculate accuracy by comparing positive sample scores with negative sample scores.\n",
    "    We want positive context words to have higher scores than random negative words.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get embeddings for all input words\n",
    "        emb = model.embeddings(X)  # [num_samples, embedding_dim]\n",
    "        \n",
    "        # Get positive context embeddings\n",
    "        pos_ctx = model.output_weights.weight[Y]  # [num_samples, 2, embedding_dim]\n",
    "        \n",
    "        # Generate negative samples\n",
    "        neg_samples = torch.randint(0, vocab_size, Y.shape)\n",
    "        neg_ctx = model.output_weights.weight[neg_samples]\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        emb_reshaped = emb.unsqueeze(-1)  # [num_samples, embedding_dim, 1]\n",
    "        pos_scores = torch.bmm(pos_ctx, emb_reshaped).squeeze(-1)  # [num_samples, 2]\n",
    "        neg_scores = torch.bmm(neg_ctx, emb_reshaped).squeeze(-1)  # [num_samples, 2]\n",
    "        \n",
    "        # Accuracy: how often positive scores > negative scores\n",
    "        accuracy = (pos_scores > neg_scores).float().mean().item()\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where input len is used, delete if otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 149736\n",
      "Vocabulary size: 3727\n",
      "Max index in X: 3726\n",
      "Max index in Y: 3726\n",
      "Sample X values: tensor([1, 2, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Sample Y values: tensor([[ 0,  2],\n",
      "        [ 1,  2],\n",
      "        [ 2,  3],\n",
      "        [ 2,  4],\n",
      "        [ 3,  5],\n",
      "        [ 4,  6],\n",
      "        [ 5,  7],\n",
      "        [ 6,  8],\n",
      "        [ 7,  9],\n",
      "        [ 8, 10]])\n"
     ]
    }
   ],
   "source": [
    "# After creating the dataset\n",
    "print(\"Dataset size:\", len(X))\n",
    "print(\"Vocabulary size:\", len(word_to_idx))\n",
    "print(\"Max index in X:\", X.max().item())\n",
    "print(\"Max index in Y:\", Y.max().item())\n",
    "print(\"Sample X values:\", X[:10])\n",
    "print(\"Sample Y values:\", Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes - X: torch.Size([32]), Pos: torch.Size([32, 2]), Neg: torch.Size([32, 2])\n",
      "Max indices - X: 3405, Pos: 3532, Neg: 3660\n",
      "Vocab size: 3727\n",
      "Epoch 1 | Batch 1 | Loss: 1.46319 | Accuracy: 0.4898\n",
      "Epoch 1 | Batch 101 | Loss: 1.48292 | Accuracy: 0.5047\n",
      "Epoch 1 | Batch 201 | Loss: 1.51153 | Accuracy: 0.5184\n",
      "Epoch 1 | Batch 301 | Loss: 1.55030 | Accuracy: 0.5226\n",
      "Epoch 1 | Batch 401 | Loss: 1.42311 | Accuracy: 0.5275\n",
      "Epoch 1 | Batch 501 | Loss: 1.50041 | Accuracy: 0.5326\n",
      "Epoch 1 | Batch 601 | Loss: 1.42261 | Accuracy: 0.5367\n",
      "Epoch 1 | Batch 701 | Loss: 1.31336 | Accuracy: 0.5410\n",
      "Epoch 1 | Batch 801 | Loss: 1.34595 | Accuracy: 0.5450\n",
      "Epoch 1 | Batch 901 | Loss: 1.46743 | Accuracy: 0.5454\n",
      "Epoch 1 | Batch 1001 | Loss: 1.40181 | Accuracy: 0.5482\n",
      "Epoch 1 | Batch 1101 | Loss: 1.48503 | Accuracy: 0.5512\n",
      "Epoch 1 | Batch 1201 | Loss: 1.37432 | Accuracy: 0.5534\n",
      "Epoch 1 | Batch 1301 | Loss: 1.46818 | Accuracy: 0.5548\n",
      "Epoch 1 | Batch 1401 | Loss: 1.46475 | Accuracy: 0.5594\n",
      "Epoch 1 | Batch 1501 | Loss: 1.40190 | Accuracy: 0.5616\n",
      "Epoch 1 | Batch 1601 | Loss: 1.46960 | Accuracy: 0.5620\n",
      "Epoch 1 | Batch 1701 | Loss: 1.46438 | Accuracy: 0.5626\n",
      "Epoch 1 | Batch 1801 | Loss: 1.50027 | Accuracy: 0.5648\n",
      "Epoch 1 | Batch 1901 | Loss: 1.33408 | Accuracy: 0.5678\n",
      "Epoch 1 | Batch 2001 | Loss: 1.42049 | Accuracy: 0.5689\n",
      "Epoch 1 | Batch 2101 | Loss: 1.40374 | Accuracy: 0.5693\n",
      "Epoch 1 | Batch 2201 | Loss: 1.40284 | Accuracy: 0.5718\n",
      "Epoch 1 | Batch 2301 | Loss: 1.36633 | Accuracy: 0.5726\n",
      "Epoch 1 | Batch 2401 | Loss: 1.28696 | Accuracy: 0.5747\n",
      "Epoch 1 | Batch 2501 | Loss: 1.43923 | Accuracy: 0.5756\n",
      "Epoch 1 | Batch 2601 | Loss: 1.40463 | Accuracy: 0.5774\n",
      "Epoch 1 | Batch 2701 | Loss: 1.39064 | Accuracy: 0.5789\n",
      "Epoch 1 | Batch 2801 | Loss: 1.41427 | Accuracy: 0.5801\n",
      "Epoch 1 | Batch 2901 | Loss: 1.32320 | Accuracy: 0.5813\n",
      "Epoch 1 | Batch 3001 | Loss: 1.43175 | Accuracy: 0.5838\n",
      "Epoch 1 | Batch 3101 | Loss: 1.44363 | Accuracy: 0.5828\n",
      "Epoch 1 | Batch 3201 | Loss: 1.41177 | Accuracy: 0.5849\n",
      "Epoch 1 | Batch 3301 | Loss: 1.38980 | Accuracy: 0.5865\n",
      "Epoch 1 | Batch 3401 | Loss: 1.33508 | Accuracy: 0.5890\n",
      "Epoch 1 | Batch 3501 | Loss: 1.41605 | Accuracy: 0.5898\n",
      "Epoch 1 | Batch 3601 | Loss: 1.39458 | Accuracy: 0.5918\n",
      "Epoch 1 | Batch 3701 | Loss: 1.42380 | Accuracy: 0.5923\n",
      "Epoch 1 | Batch 3801 | Loss: 1.25620 | Accuracy: 0.5917\n",
      "Epoch 1 | Batch 3901 | Loss: 1.42739 | Accuracy: 0.5921\n",
      "Epoch 1 | Batch 4001 | Loss: 1.44668 | Accuracy: 0.5951\n",
      "Epoch 1 | Batch 4101 | Loss: 1.38560 | Accuracy: 0.5970\n",
      "Epoch 1 | Batch 4201 | Loss: 1.33039 | Accuracy: 0.5976\n",
      "Epoch 1 | Batch 4301 | Loss: 1.40135 | Accuracy: 0.5970\n",
      "Epoch 1 | Batch 4401 | Loss: 1.25287 | Accuracy: 0.5994\n",
      "Epoch 1 | Batch 4501 | Loss: 1.28518 | Accuracy: 0.5998\n",
      "Epoch 1 | Batch 4601 | Loss: 1.36984 | Accuracy: 0.5999\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED) # Set manual seed\n",
    "\n",
    "epochs = 1          # Set epochs\n",
    "batch_size = 32     # Set batch size\n",
    "\n",
    "lossi = []          # Track loss\n",
    "\n",
    "# Send data to the device\n",
    "# X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "# X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Create batches from dataset\n",
    "dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True, \n",
    "                                         drop_last=True)\n",
    "\n",
    "# Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    total_loss = 0  # Track loss across batches\n",
    "    \n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        # Unpack batch\n",
    "        X_batch, positive_samples = batch\n",
    "        # Generate negative samples\n",
    "        negative_samples = torch.randint(0, vocab_size, (X_batch.size(0), context_len -1))\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(f\"Batch shapes - X: {X_batch.shape}, Pos: {positive_samples.shape}, Neg: {negative_samples.shape}\")\n",
    "            print(f\"Max indices - X: {X_batch.max()}, Pos: {positive_samples.max()}, Neg: {negative_samples.max()}\")\n",
    "            print(f\"Vocab size: {vocab_size}\")\n",
    "\n",
    "        # 1. Forward pass (now returns loss directly)\n",
    "        loss = word2vec(X_batch, positive_samples, negative_samples)  # Model computes loss internally\n",
    "        \n",
    "        # 2. Zero the gradients\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        # 3. Loss backwards\n",
    "        loss.backward()\n",
    "        \n",
    "        # 4. Step the optimiser\n",
    "        optimiser.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Track loss\n",
    "        lossi.append(loss.item())\n",
    "        \n",
    "        accuracy = evaluate_accuracy(word2vec, X, Y, vocab_size)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1} | Batch {batch_idx + 1} | Loss: {loss.item():.5f} | Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # print(f\"Epoch {epoch + 1} | Loss: {loss.item():.5f} | Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # print(f\"Epoch {epoch + 1} | Batch {batch_idx + 1} | Loss: {loss.item():.5f}\")\n",
    "    # Print out what's happening every 100 epochs\n",
    "    # if epoch % 100 == 0:\n",
    "    #     avg_loss = total_loss / len(dataloader)\n",
    "    #     print(f\"Epoch: {epoch} | Average Loss: {avg_loss:.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(lossi):\n",
    "    \"\"\"\n",
    "    Plot loss values using PyTorch operations.\n",
    "    \"\"\"\n",
    "    losses = torch.tensor(lossi)\n",
    "    window_size = max(len(losses) // 100, 1)\n",
    "    \n",
    "    # Reshape and mean\n",
    "    remainder = len(losses) % window_size\n",
    "    if remainder:\n",
    "        # Pad with the last value to make it evenly divisible\n",
    "        padding = window_size - remainder\n",
    "        losses = torch.cat([losses, losses[-1].repeat(padding)])\n",
    "    \n",
    "    averaged_losses = losses.view(-1, window_size).mean(1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(averaged_losses)\n",
    "    plt.title('Training Loss Over Time')\n",
    "    plt.xlabel(f'Steps (averaged over {window_size} steps)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_neighbors(word, stoi, embeddings, n=5):\n",
    "    \"\"\"\n",
    "    Find the top-n nearest neighbors of a word in the embedding space.\n",
    "    \n",
    "    Args:\n",
    "        word (str): The target word.\n",
    "        stoi (dict): Mapping from words to indices.\n",
    "        embeddings (torch.Tensor): Learned word embeddings (shape: V x d).\n",
    "        n (int): Number of nearest neighbors to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples (neighbor_word, similarity_score).\n",
    "    \"\"\"\n",
    "    if word not in stoi:\n",
    "        return f\"'{word}' not in vocabulary.\"\n",
    "    \n",
    "    word_idx = stoi[word]\n",
    "    word_embedding = embeddings[word_idx].unsqueeze(0)  # Shape: 1 x d\n",
    "    \n",
    "    # Compute cosine similarity between the target embedding and all embeddings\n",
    "    similarities = cosine_similarity(word_embedding.detach().numpy(), embeddings.detach().numpy())\n",
    "    similarities = similarities[0]  # Flatten\n",
    "    \n",
    "    # Get top-n similar words (excluding the word itself)\n",
    "    nearest_indices = similarities.argsort()[-n-1:][::-1][1:]  # Exclude the word itself\n",
    "    nearest_words = [(list(stoi.keys())[idx], similarities[idx]) for idx in nearest_indices]\n",
    "    return nearest_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors of 'pollen':\n",
      "'pollen' not in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "word = \"pollen\"\n",
    "nearest_neighbors = get_nearest_neighbors(word, word_to_idx, word2vec.embeddings.weight, n=5)\n",
    "print(f\"Nearest neighbors of '{word}':\")\n",
    "print(nearest_neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample of words:\n",
      "['country', 'ad', 'them', 'that', 'it', 'called', 'a', 'ch', 'first', 'held', 'to', 'following', 'air', 'the', 'capitalism', 'to', 'to', 'the', 'to', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Using random\n",
    "# Make a copy so you don't shuffle the original list\n",
    "words_sample = processed_words.copy()\n",
    "random.shuffle(words_sample)\n",
    "\n",
    "# Print first 10 shuffled words\n",
    "print(\"Random sample of words:\")\n",
    "print(words_sample[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3727, 20])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.embeddings.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'a',\n",
       " 'a',\n",
       " 'term',\n",
       " 'of',\n",
       " 'abuse',\n",
       " 'first',\n",
       " 'used',\n",
       " 'against',\n",
       " 'early',\n",
       " 'working',\n",
       " 'class',\n",
       " 'radical']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets build the regression model\n",
    "\n",
    "title = \"anarchism originated as a term of abuse first used against early working class radicals\"\n",
    "title_words, title_words_to_idx = preprocess_text(title,1)\n",
    "# title_idx = word_to_idx['anarchism']\n",
    "# title_words, \n",
    "title_words\n",
    "# word2vec.embeddings.weight[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_indices(words: List[str], word_to_idx: dict) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get indices for a list of words, with error handling for unknown words.\n",
    "    \n",
    "    Args:\n",
    "        words: List of words to look up\n",
    "        word_to_idx: Dictionary mapping words to indices\n",
    "    \n",
    "    Returns:\n",
    "        List of indices for the input words. Unknown words will be noted.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in word_to_idx:\n",
    "            indices.append(word_to_idx[word])\n",
    "        else:\n",
    "            unknown_words.append(word)\n",
    "    \n",
    "    # Uncomment below to print unknown words\n",
    "    # if unknown_words:\n",
    "    #     print(f\"Warning: Words not in vocabulary: {unknown_words}\")\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20]), torch.Size([14, 20]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a tensor of indexes for tokenized words in input title\n",
    "title_idx = torch.tensor(get_word_indices(title_words, word_to_idx))\n",
    "\n",
    "word2vec.embeddings.weight[title_idx].shape, title_idx.shape\n",
    "\n",
    "avg_pooling = torch.mean(word2vec.embeddings.weight[title_idx], dim= 0)\n",
    "# avg_pooling.unsqueeze(dim=0).shape\n",
    "avg_pooling.shape, word2vec.embeddings.weight[title_idx].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes - X: torch.Size([7567, 20]), y: torch.Size([7567, 1])\n",
      "Sample scores: tensor([ 8., 62.,  1.,  1.,  2.])\n",
      "torch.float32\n",
      "tensor([[-0.7956,  0.3645, -0.2649, -0.3656, -0.2964, -0.5467, -0.0615, -0.1068,\n",
      "          0.2167,  0.5863,  0.4340,  0.6665,  0.0364,  0.0570, -0.1958,  0.6612,\n",
      "         -0.3121, -0.1556, -0.4343,  0.0285],\n",
      "        [-0.0154, -0.1454,  1.0242, -0.0073, -0.1848,  0.6347, -0.2985,  0.6058,\n",
      "         -0.5334, -0.6250, -0.5470, -0.1749, -0.1629,  0.4863,  0.6589, -0.3425,\n",
      "         -0.0696, -0.2098,  0.1485,  0.1731],\n",
      "        [-0.6162, -0.0877,  0.6994, -0.3604, -0.5395,  0.5786,  0.2867, -0.2762,\n",
      "          0.0690, -0.1263, -0.0982, -0.0039, -0.2433,  0.1414,  0.7383,  0.6488,\n",
      "         -0.4515,  0.6960, -0.0731, -1.0586],\n",
      "        [-0.5687,  1.1848,  0.0820,  0.2764, -0.2918, -0.6866, -0.6163, -0.2802,\n",
      "          0.0085, -0.4782, -0.0610,  0.5441, -0.8858,  0.0931, -1.1854, -0.0535,\n",
      "          0.8694, -0.0911,  0.2068,  0.4297],\n",
      "        [ 0.2534,  0.8215,  0.6671, -0.2588, -0.0903,  0.2737,  0.1396,  0.2986,\n",
      "         -0.6660,  0.4754,  0.2769,  0.6534,  0.3108,  0.1884, -0.1695,  0.1349,\n",
      "          0.2303,  0.4401,  0.0250, -0.2719],\n",
      "        [-0.4835,  0.1000,  0.1725, -0.0951,  0.0613, -0.1495, -0.0902, -0.3015,\n",
      "          0.1847, -0.1222, -0.2514,  0.0871,  0.2719,  0.1049, -0.1453, -0.5470,\n",
      "          0.1166, -0.5476, -0.4162,  0.1946],\n",
      "        [-0.0445, -0.1514,  0.7520,  0.2979,  0.6463, -0.1823, -0.0151, -0.7199,\n",
      "          0.3439, -0.6047,  0.6005, -0.0307, -0.3061, -1.1943,  0.2403, -0.5262,\n",
      "          0.2492,  0.1953, -0.4472, -0.6867],\n",
      "        [-0.3588, -0.4639, -0.0195,  0.1301, -0.9888, -0.1648, -0.6026, -0.1845,\n",
      "          0.3735, -0.2718, -0.0943, -0.4882, -0.3993, -0.5447,  0.8242,  0.0553,\n",
      "         -0.4934,  0.2377,  0.1525, -0.3845],\n",
      "        [-0.1777,  0.0198,  0.4810,  0.9335,  0.2730, -0.6198, -0.0952, -0.3861,\n",
      "         -0.1925,  0.8355,  1.0774,  0.1686,  0.3916,  0.9489,  0.4481,  0.0225,\n",
      "         -0.2184,  0.5714, -0.2583, -0.4355],\n",
      "        [ 0.1366, -0.0273, -0.0376,  0.4795,  0.3884,  0.1823,  1.2061, -0.7773,\n",
      "          0.0776, -0.5506, -0.1895, -0.3294, -1.1484, -0.3031,  0.3081,  0.5547,\n",
      "         -0.7508, -0.1325,  0.1709, -0.1949]])\n"
     ]
    }
   ],
   "source": [
    "def get_title_embeddings(title: str, word2vec: nn.Module, word_to_idx: dict) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Process a single title and get its embedding representation.\n",
    "    \"\"\"\n",
    "    # Preprocess the title\n",
    "    title_words, _ = preprocess_text(title, min_freq=1)  # min_freq=1 since we're using existing vocabulary\n",
    "    \n",
    "    # Get indices for words that exist in our vocabulary\n",
    "    title_idx = get_word_indices(title_words, word_to_idx)\n",
    "    \n",
    "    # Uncomment below for printing when title not included \n",
    "    # if not title_idx:  # If no words from title are in vocabulary\n",
    "    #     print(f\"Warning: No words from title found in vocabulary: {title}\")\n",
    "    #     return None\n",
    "    \n",
    "    # Convert to tensor and get embeddings\n",
    "    title_tensor = torch.tensor(title_idx, dtype=torch.long)\n",
    "    word_embeddings = word2vec.embeddings.weight[title_tensor].detach() # Detach to avoid tracking gradients from word2vec\n",
    "    \n",
    "    # Average the word embeddings to get title embedding\n",
    "    title_embedding = torch.mean(word_embeddings, dim=0)\n",
    "    \n",
    "    return title_embedding\n",
    "\n",
    "# Process all titles in the dataframe\n",
    "def prepare_regression_dataset(df: pd.DataFrame, word2vec: nn.Module, word_to_idx: dict) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Prepare dataset for regression model.\n",
    "    \"\"\"\n",
    "    title_embeddings = []\n",
    "    scores = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        title_emb = get_title_embeddings(row['title'], word2vec, word_to_idx)\n",
    "        if title_emb is not None and not torch.isnan(title_emb).any():  # Only include if we got valid embeddings\n",
    "            title_embeddings.append(title_emb)\n",
    "            scores.append(row['score'])\n",
    "    \n",
    "    # Stack all embeddings and scores\n",
    "    X = torch.stack(title_embeddings)\n",
    "    Y = torch.tensor(scores, dtype=torch.float).reshape(-1, 1)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "# Example usage:\n",
    "# First, ensure word2vec is trained on combined dataset\n",
    "# Then prepare regression dataset\n",
    "X_titles, Y_scores = prepare_regression_dataset(df, word2vec, word_to_idx)\n",
    "\n",
    "print(f\"Dataset shapes - X: {X_titles.shape}, y: {Y_scores.shape}\")\n",
    "print(f\"Sample scores: {Y_scores[:5].squeeze()}\")\n",
    "print(X_titles[:10].dtype)\n",
    "print(X_titles[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the regression model\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, emb_dims, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.emb_dims = emb_dims\n",
    "        self.hidden_dims = hidden_dims\n",
    "\n",
    "        # Define layers\n",
    "        self.layer1 = nn.Linear(in_features=self.emb_dims, out_features=self.hidden_dims, bias= True)\n",
    "        self.layer2 = nn.Linear(in_features=self.hidden_dims, out_features=self.hidden_dims, bias= True)\n",
    "        self.out_layer = nn.Linear(in_features=self.hidden_dims, out_features= 1, bias= True)\n",
    "\n",
    "        # Define ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.layer1(x))\n",
    "        h2 = self.relu(self.layer2(h1))\n",
    "        out = self.out_layer(h2)\n",
    "        return out \n",
    "\n",
    "# Set hidden dimensions\n",
    "hidden_dims = 20\n",
    "\n",
    "# Instantiate the model\n",
    "regression_model = RegressionModel(emb_dims= emb_dims, hidden_dims=hidden_dims)\n",
    "\n",
    "# Define loss function\n",
    "regression_loss_fn = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial tensor types:\n",
      "X_titles dtype: torch.float32\n",
      "Y_scores dtype: torch.float32\n",
      "Model weight dtype: torch.float32\n",
      "\n",
      "Batch tensor types:\n",
      "batch_X dtype: torch.float32\n",
      "batch_y dtype: torch.float32\n",
      "\n",
      "Testing forward pass:\n",
      "Predictions dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Check initial tensor types\n",
    "print(\"Initial tensor types:\")\n",
    "print(f\"X_titles dtype: {X_titles.dtype}\")\n",
    "print(f\"Y_scores dtype: {Y_scores.dtype}\")\n",
    "print(f\"Model weight dtype: {next(regression_model.parameters()).dtype}\")\n",
    "\n",
    "# Create dataset and check batch types\n",
    "dataset = torch.utils.data.TensorDataset(X_titles, Y_scores)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check first batch\n",
    "for batch_X, batch_y in dataloader:\n",
    "    print(\"\\nBatch tensor types:\")\n",
    "    print(f\"batch_X dtype: {batch_X.dtype}\")\n",
    "    print(f\"batch_y dtype: {batch_y.dtype}\")\n",
    "    break\n",
    "\n",
    "# Try a single forward pass\n",
    "try:\n",
    "    print(\"\\nTesting forward pass:\")\n",
    "    predictions = regression_model(batch_X)\n",
    "    print(f\"Predictions dtype: {predictions.dtype}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in forward pass: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting debug...\n",
      "\n",
      "Batch information:\n",
      "batch_X shape: torch.Size([32, 20]), dtype: torch.float32\n",
      "batch_y shape: torch.Size([32, 1]), dtype: torch.float32\n",
      "\n",
      "Model parameters:\n",
      "layer1.weight dtype: torch.float32\n",
      "layer1.bias dtype: torch.float32\n",
      "layer2.weight dtype: torch.float32\n",
      "layer2.bias dtype: torch.float32\n",
      "out_layer.weight dtype: torch.float32\n",
      "out_layer.bias dtype: torch.float32\n",
      "\n",
      "Forward pass steps:\n",
      "1. First layer\n",
      "   Passed layer1\n",
      "2. First ReLU\n",
      "   Passed ReLU\n",
      "3. Second layer\n",
      "   Passed layer2\n",
      "4. Second ReLU\n",
      "   Passed ReLU\n",
      "5. Output layer\n",
      "   Passed output layer\n",
      "\n",
      "All steps completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Debug version of training loop\n",
    "print(\"Starting debug...\")\n",
    "\n",
    "try:\n",
    "    # Get first batch\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        print(\"\\nBatch information:\")\n",
    "        print(f\"batch_X shape: {batch_X.shape}, dtype: {batch_X.dtype}\")\n",
    "        print(f\"batch_y shape: {batch_y.shape}, dtype: {batch_y.dtype}\")\n",
    "        \n",
    "        # Check model parameters\n",
    "        print(\"\\nModel parameters:\")\n",
    "        for name, param in regression_model.named_parameters():\n",
    "            print(f\"{name} dtype: {param.dtype}\")\n",
    "        \n",
    "        # Try forward pass step by step\n",
    "        print(\"\\nForward pass steps:\")\n",
    "        print(\"1. First layer\")\n",
    "        h1 = regression_model.layer1(batch_X)\n",
    "        print(\"   Passed layer1\")\n",
    "        \n",
    "        print(\"2. First ReLU\")\n",
    "        h1 = regression_model.relu(h1)\n",
    "        print(\"   Passed ReLU\")\n",
    "        \n",
    "        print(\"3. Second layer\")\n",
    "        h2 = regression_model.layer2(h1)\n",
    "        print(\"   Passed layer2\")\n",
    "        \n",
    "        print(\"4. Second ReLU\")\n",
    "        h2 = regression_model.relu(h2)\n",
    "        print(\"   Passed ReLU\")\n",
    "        \n",
    "        print(\"5. Output layer\")\n",
    "        out = regression_model.out_layer(h2)\n",
    "        print(\"   Passed output layer\")\n",
    "        \n",
    "        print(\"\\nAll steps completed successfully\")\n",
    "        break\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nError occurred at: {str(e)}\")\n",
    "    # Print local variables if available\n",
    "    if 'batch_X' in locals():\n",
    "        print(f\"Last batch_X dtype: {batch_X.dtype}\")\n",
    "    if 'h1' in locals():\n",
    "        print(f\"Last h1 dtype: {h1.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Dataset size: 7567\n",
      "Number of batches: 237\n",
      "X_titles shape: torch.Size([7567, 20])\n",
      "Y_scores shape: torch.Size([7567, 1])\n",
      "Sample batch shapes: torch.Size([32, 20]), torch.Size([32, 1])\n",
      "Epoch 1/1000 | Batch 0/237 | Loss: 10945.6709\n",
      "Epoch 1/1000 | Batch 100/237 | Loss: 17875.7773\n",
      "Epoch 1/1000 | Batch 200/237 | Loss: 1337.7999\n",
      "Epoch 1/1000 complete | Avg Loss: 5353.7083\n",
      "Epoch 2/1000 | Batch 0/237 | Loss: 2187.4475\n",
      "Epoch 2/1000 | Batch 100/237 | Loss: 9139.4355\n",
      "Epoch 2/1000 | Batch 200/237 | Loss: 3885.3809\n",
      "Epoch 2/1000 complete | Avg Loss: 5349.0714\n",
      "Epoch 3/1000 | Batch 0/237 | Loss: 2109.4412\n",
      "Epoch 3/1000 | Batch 100/237 | Loss: 7842.4448\n",
      "Epoch 3/1000 | Batch 200/237 | Loss: 397.0869\n",
      "Epoch 3/1000 complete | Avg Loss: 5340.2157\n",
      "Epoch 4/1000 | Batch 0/237 | Loss: 2244.3198\n",
      "Epoch 4/1000 | Batch 100/237 | Loss: 857.9862\n",
      "Epoch 4/1000 | Batch 200/237 | Loss: 776.4371\n",
      "Epoch 4/1000 complete | Avg Loss: 5355.9355\n",
      "Epoch 5/1000 | Batch 0/237 | Loss: 1711.2963\n",
      "Epoch 5/1000 | Batch 100/237 | Loss: 1122.8364\n",
      "Epoch 5/1000 | Batch 200/237 | Loss: 486.5511\n",
      "Epoch 5/1000 complete | Avg Loss: 5490.2557\n",
      "Epoch 6/1000 | Batch 0/237 | Loss: 1181.2390\n",
      "Epoch 6/1000 | Batch 100/237 | Loss: 1501.2411\n",
      "Epoch 6/1000 | Batch 200/237 | Loss: 4937.6777\n",
      "Epoch 6/1000 complete | Avg Loss: 5337.7919\n",
      "Epoch 7/1000 | Batch 0/237 | Loss: 1878.9568\n",
      "Epoch 7/1000 | Batch 100/237 | Loss: 6716.6699\n",
      "Epoch 7/1000 | Batch 200/237 | Loss: 2355.1750\n",
      "Epoch 7/1000 complete | Avg Loss: 5333.5151\n",
      "Epoch 8/1000 | Batch 0/237 | Loss: 1249.4414\n",
      "Epoch 8/1000 | Batch 100/237 | Loss: 929.8984\n",
      "Epoch 8/1000 | Batch 200/237 | Loss: 3366.5981\n",
      "Epoch 8/1000 complete | Avg Loss: 5330.9683\n",
      "Epoch 9/1000 | Batch 0/237 | Loss: 2322.0635\n",
      "Epoch 9/1000 | Batch 100/237 | Loss: 34141.0312\n",
      "Epoch 9/1000 | Batch 200/237 | Loss: 1773.3910\n",
      "Epoch 9/1000 complete | Avg Loss: 5327.8299\n",
      "Epoch 10/1000 | Batch 0/237 | Loss: 3923.3440\n",
      "Epoch 10/1000 | Batch 100/237 | Loss: 828.2231\n",
      "Epoch 10/1000 | Batch 200/237 | Loss: 1538.5575\n",
      "Epoch 10/1000 complete | Avg Loss: 5322.4303\n",
      "Epoch 11/1000 | Batch 0/237 | Loss: 1401.2974\n",
      "Epoch 11/1000 | Batch 100/237 | Loss: 9137.4414\n",
      "Epoch 11/1000 | Batch 200/237 | Loss: 446.3261\n",
      "Epoch 11/1000 complete | Avg Loss: 5320.5154\n",
      "Epoch 12/1000 | Batch 0/237 | Loss: 583.7563\n",
      "Epoch 12/1000 | Batch 100/237 | Loss: 521.5164\n",
      "Epoch 12/1000 | Batch 200/237 | Loss: 1168.4651\n",
      "Epoch 12/1000 complete | Avg Loss: 5326.1251\n",
      "Epoch 13/1000 | Batch 0/237 | Loss: 1022.5497\n",
      "Epoch 13/1000 | Batch 100/237 | Loss: 4141.0508\n",
      "Epoch 13/1000 | Batch 200/237 | Loss: 2116.6616\n",
      "Epoch 13/1000 complete | Avg Loss: 5314.9381\n",
      "Epoch 14/1000 | Batch 0/237 | Loss: 681.4455\n",
      "Epoch 14/1000 | Batch 100/237 | Loss: 4208.4766\n",
      "Epoch 14/1000 | Batch 200/237 | Loss: 7910.8711\n",
      "Epoch 14/1000 complete | Avg Loss: 5331.6254\n",
      "Epoch 15/1000 | Batch 0/237 | Loss: 2721.1182\n",
      "Epoch 15/1000 | Batch 100/237 | Loss: 4269.5146\n",
      "Epoch 15/1000 | Batch 200/237 | Loss: 3142.8413\n",
      "Epoch 15/1000 complete | Avg Loss: 5309.3265\n",
      "Epoch 16/1000 | Batch 0/237 | Loss: 655.4463\n",
      "Epoch 16/1000 | Batch 100/237 | Loss: 5626.2622\n",
      "Epoch 16/1000 | Batch 200/237 | Loss: 1268.8655\n",
      "Epoch 16/1000 complete | Avg Loss: 5317.0687\n",
      "Epoch 17/1000 | Batch 0/237 | Loss: 25370.9531\n",
      "Epoch 17/1000 | Batch 100/237 | Loss: 4437.8315\n",
      "Epoch 17/1000 | Batch 200/237 | Loss: 660.6785\n",
      "Epoch 17/1000 complete | Avg Loss: 5307.5838\n",
      "Epoch 18/1000 | Batch 0/237 | Loss: 679.3604\n",
      "Epoch 18/1000 | Batch 100/237 | Loss: 13971.5850\n",
      "Epoch 18/1000 | Batch 200/237 | Loss: 4079.9043\n",
      "Epoch 18/1000 complete | Avg Loss: 5314.9274\n",
      "Epoch 19/1000 | Batch 0/237 | Loss: 1866.6421\n",
      "Epoch 19/1000 | Batch 100/237 | Loss: 10651.4551\n",
      "Epoch 19/1000 | Batch 200/237 | Loss: 567.2807\n",
      "Epoch 19/1000 complete | Avg Loss: 5300.3767\n",
      "Epoch 20/1000 | Batch 0/237 | Loss: 2655.8333\n",
      "Epoch 20/1000 | Batch 100/237 | Loss: 7261.6270\n",
      "Epoch 20/1000 | Batch 200/237 | Loss: 2312.7622\n",
      "Epoch 20/1000 complete | Avg Loss: 5309.1492\n",
      "Epoch 21/1000 | Batch 0/237 | Loss: 2073.1763\n",
      "Epoch 21/1000 | Batch 100/237 | Loss: 2344.3779\n",
      "Epoch 21/1000 | Batch 200/237 | Loss: 8360.5059\n",
      "Epoch 21/1000 complete | Avg Loss: 5300.9115\n",
      "Epoch 22/1000 | Batch 0/237 | Loss: 1833.5369\n",
      "Epoch 22/1000 | Batch 100/237 | Loss: 685.4716\n",
      "Epoch 22/1000 | Batch 200/237 | Loss: 727.5309\n",
      "Epoch 22/1000 complete | Avg Loss: 5294.6771\n",
      "Epoch 23/1000 | Batch 0/237 | Loss: 2981.8674\n",
      "Epoch 23/1000 | Batch 100/237 | Loss: 3737.3276\n",
      "Epoch 23/1000 | Batch 200/237 | Loss: 859.1286\n",
      "Epoch 23/1000 complete | Avg Loss: 5291.6164\n",
      "Epoch 24/1000 | Batch 0/237 | Loss: 6593.7334\n",
      "Epoch 24/1000 | Batch 100/237 | Loss: 38150.2930\n",
      "Epoch 24/1000 | Batch 200/237 | Loss: 1360.3131\n",
      "Epoch 24/1000 complete | Avg Loss: 5287.7564\n",
      "Epoch 25/1000 | Batch 0/237 | Loss: 2608.7695\n",
      "Epoch 25/1000 | Batch 100/237 | Loss: 4225.9580\n",
      "Epoch 25/1000 | Batch 200/237 | Loss: 4034.7124\n",
      "Epoch 25/1000 complete | Avg Loss: 5286.8201\n",
      "Epoch 26/1000 | Batch 0/237 | Loss: 1771.2870\n",
      "Epoch 26/1000 | Batch 100/237 | Loss: 1727.8627\n",
      "Epoch 26/1000 | Batch 200/237 | Loss: 2382.3611\n",
      "Epoch 26/1000 complete | Avg Loss: 5284.9624\n",
      "Epoch 27/1000 | Batch 0/237 | Loss: 756.0491\n",
      "Epoch 27/1000 | Batch 100/237 | Loss: 8462.4307\n",
      "Epoch 27/1000 | Batch 200/237 | Loss: 5169.9209\n",
      "Epoch 27/1000 complete | Avg Loss: 5281.9847\n",
      "Epoch 28/1000 | Batch 0/237 | Loss: 3185.8430\n",
      "Epoch 28/1000 | Batch 100/237 | Loss: 1001.4299\n",
      "Epoch 28/1000 | Batch 200/237 | Loss: 3730.9961\n",
      "Epoch 28/1000 complete | Avg Loss: 5280.1377\n",
      "Epoch 29/1000 | Batch 0/237 | Loss: 796.7413\n",
      "Epoch 29/1000 | Batch 100/237 | Loss: 510.0078\n",
      "Epoch 29/1000 | Batch 200/237 | Loss: 3654.8550\n",
      "Epoch 29/1000 complete | Avg Loss: 5277.8318\n",
      "Epoch 30/1000 | Batch 0/237 | Loss: 1472.3168\n",
      "Epoch 30/1000 | Batch 100/237 | Loss: 1320.0128\n",
      "Epoch 30/1000 | Batch 200/237 | Loss: 714.3674\n",
      "Epoch 30/1000 complete | Avg Loss: 5272.0845\n",
      "Epoch 31/1000 | Batch 0/237 | Loss: 3909.5432\n",
      "Epoch 31/1000 | Batch 100/237 | Loss: 383.0623\n",
      "Epoch 31/1000 | Batch 200/237 | Loss: 2367.7854\n",
      "Epoch 31/1000 complete | Avg Loss: 5269.6229\n",
      "Epoch 32/1000 | Batch 0/237 | Loss: 2335.6868\n",
      "Epoch 32/1000 | Batch 100/237 | Loss: 3891.3977\n",
      "Epoch 32/1000 | Batch 200/237 | Loss: 37533.2852\n",
      "Epoch 32/1000 complete | Avg Loss: 5272.5524\n",
      "Epoch 33/1000 | Batch 0/237 | Loss: 884.2701\n",
      "Epoch 33/1000 | Batch 100/237 | Loss: 3783.3452\n",
      "Epoch 33/1000 | Batch 200/237 | Loss: 5707.4614\n",
      "Epoch 33/1000 complete | Avg Loss: 5270.7575\n",
      "Epoch 34/1000 | Batch 0/237 | Loss: 553.6878\n",
      "Epoch 34/1000 | Batch 100/237 | Loss: 32546.7480\n",
      "Epoch 34/1000 | Batch 200/237 | Loss: 775.3757\n",
      "Epoch 34/1000 complete | Avg Loss: 5264.1738\n",
      "Epoch 35/1000 | Batch 0/237 | Loss: 1660.5381\n",
      "Epoch 35/1000 | Batch 100/237 | Loss: 3228.5474\n",
      "Epoch 35/1000 | Batch 200/237 | Loss: 32750.0273\n",
      "Epoch 35/1000 complete | Avg Loss: 5259.1122\n",
      "Epoch 36/1000 | Batch 0/237 | Loss: 1727.4501\n",
      "Epoch 36/1000 | Batch 100/237 | Loss: 24957.5547\n",
      "Epoch 36/1000 | Batch 200/237 | Loss: 3557.3567\n",
      "Epoch 36/1000 complete | Avg Loss: 5263.6172\n",
      "Epoch 37/1000 | Batch 0/237 | Loss: 1170.6107\n",
      "Epoch 37/1000 | Batch 100/237 | Loss: 1723.6497\n",
      "Epoch 37/1000 | Batch 200/237 | Loss: 2210.5898\n",
      "Epoch 37/1000 complete | Avg Loss: 5259.4688\n",
      "Epoch 38/1000 | Batch 0/237 | Loss: 2693.6045\n",
      "Epoch 38/1000 | Batch 100/237 | Loss: 1826.0422\n",
      "Epoch 38/1000 | Batch 200/237 | Loss: 2011.0742\n",
      "Epoch 38/1000 complete | Avg Loss: 5251.0314\n",
      "Epoch 39/1000 | Batch 0/237 | Loss: 811.3231\n",
      "Epoch 39/1000 | Batch 100/237 | Loss: 2051.8394\n",
      "Epoch 39/1000 | Batch 200/237 | Loss: 388.9679\n",
      "Epoch 39/1000 complete | Avg Loss: 5257.8920\n",
      "Epoch 40/1000 | Batch 0/237 | Loss: 325.8814\n",
      "Epoch 40/1000 | Batch 100/237 | Loss: 30554.4980\n",
      "Epoch 40/1000 | Batch 200/237 | Loss: 16947.6055\n",
      "Epoch 40/1000 complete | Avg Loss: 5247.4186\n",
      "Epoch 41/1000 | Batch 0/237 | Loss: 317.7297\n",
      "Epoch 41/1000 | Batch 100/237 | Loss: 768.0505\n",
      "Epoch 41/1000 | Batch 200/237 | Loss: 2025.3789\n",
      "Epoch 41/1000 complete | Avg Loss: 5249.8203\n",
      "Epoch 42/1000 | Batch 0/237 | Loss: 1634.9930\n",
      "Epoch 42/1000 | Batch 100/237 | Loss: 1296.4666\n",
      "Epoch 42/1000 | Batch 200/237 | Loss: 464.2366\n",
      "Epoch 42/1000 complete | Avg Loss: 5273.8262\n",
      "Epoch 43/1000 | Batch 0/237 | Loss: 5246.1582\n",
      "Epoch 43/1000 | Batch 100/237 | Loss: 1777.1267\n",
      "Epoch 43/1000 | Batch 200/237 | Loss: 1766.9185\n",
      "Epoch 43/1000 complete | Avg Loss: 5239.7397\n",
      "Epoch 44/1000 | Batch 0/237 | Loss: 7469.2593\n",
      "Epoch 44/1000 | Batch 100/237 | Loss: 405.5372\n",
      "Epoch 44/1000 | Batch 200/237 | Loss: 673.5601\n",
      "Epoch 44/1000 complete | Avg Loss: 5244.2743\n",
      "Epoch 45/1000 | Batch 0/237 | Loss: 6268.3525\n",
      "Epoch 45/1000 | Batch 100/237 | Loss: 1633.5645\n",
      "Epoch 45/1000 | Batch 200/237 | Loss: 10711.4980\n",
      "Epoch 45/1000 complete | Avg Loss: 5233.4760\n",
      "Epoch 46/1000 | Batch 0/237 | Loss: 2053.6516\n",
      "Epoch 46/1000 | Batch 100/237 | Loss: 4877.5195\n",
      "Epoch 46/1000 | Batch 200/237 | Loss: 1127.7399\n",
      "Epoch 46/1000 complete | Avg Loss: 5244.5631\n",
      "Epoch 47/1000 | Batch 0/237 | Loss: 9373.8184\n",
      "Epoch 47/1000 | Batch 100/237 | Loss: 1179.6604\n",
      "Epoch 47/1000 | Batch 200/237 | Loss: 1686.9591\n",
      "Epoch 47/1000 complete | Avg Loss: 5238.0197\n",
      "Epoch 48/1000 | Batch 0/237 | Loss: 1470.1340\n",
      "Epoch 48/1000 | Batch 100/237 | Loss: 723.6220\n",
      "Epoch 48/1000 | Batch 200/237 | Loss: 340.4967\n",
      "Epoch 48/1000 complete | Avg Loss: 5235.6099\n",
      "Epoch 49/1000 | Batch 0/237 | Loss: 523.3457\n",
      "Epoch 49/1000 | Batch 100/237 | Loss: 3710.7878\n",
      "Epoch 49/1000 | Batch 200/237 | Loss: 1107.2949\n",
      "Epoch 49/1000 complete | Avg Loss: 5226.1615\n",
      "Epoch 50/1000 | Batch 0/237 | Loss: 14154.3779\n",
      "Epoch 50/1000 | Batch 100/237 | Loss: 7374.3901\n",
      "Epoch 50/1000 | Batch 200/237 | Loss: 3694.3733\n",
      "Epoch 50/1000 complete | Avg Loss: 5226.4766\n",
      "Epoch 51/1000 | Batch 0/237 | Loss: 999.0829\n",
      "Epoch 51/1000 | Batch 100/237 | Loss: 438.3218\n",
      "Epoch 51/1000 | Batch 200/237 | Loss: 1146.7423\n",
      "Epoch 51/1000 complete | Avg Loss: 5233.7813\n",
      "Epoch 52/1000 | Batch 0/237 | Loss: 860.3892\n",
      "Epoch 52/1000 | Batch 100/237 | Loss: 5186.0361\n",
      "Epoch 52/1000 | Batch 200/237 | Loss: 4268.4653\n",
      "Epoch 52/1000 complete | Avg Loss: 5219.0378\n",
      "Epoch 53/1000 | Batch 0/237 | Loss: 23904.9180\n",
      "Epoch 53/1000 | Batch 100/237 | Loss: 3197.5188\n",
      "Epoch 53/1000 | Batch 200/237 | Loss: 2588.6736\n",
      "Epoch 53/1000 complete | Avg Loss: 5218.0522\n",
      "Epoch 54/1000 | Batch 0/237 | Loss: 1517.4958\n",
      "Epoch 54/1000 | Batch 100/237 | Loss: 558.3858\n",
      "Epoch 54/1000 | Batch 200/237 | Loss: 15374.5674\n",
      "Epoch 54/1000 complete | Avg Loss: 5224.5887\n",
      "Epoch 55/1000 | Batch 0/237 | Loss: 877.1875\n",
      "Epoch 55/1000 | Batch 100/237 | Loss: 3852.2632\n",
      "Epoch 55/1000 | Batch 200/237 | Loss: 4048.4033\n",
      "Epoch 55/1000 complete | Avg Loss: 5215.9283\n",
      "Epoch 56/1000 | Batch 0/237 | Loss: 3788.0933\n",
      "Epoch 56/1000 | Batch 100/237 | Loss: 1396.9280\n",
      "Epoch 56/1000 | Batch 200/237 | Loss: 1590.3643\n",
      "Epoch 56/1000 complete | Avg Loss: 5207.7938\n",
      "Epoch 57/1000 | Batch 0/237 | Loss: 11695.0166\n",
      "Epoch 57/1000 | Batch 100/237 | Loss: 1018.4348\n",
      "Epoch 57/1000 | Batch 200/237 | Loss: 838.6989\n",
      "Epoch 57/1000 complete | Avg Loss: 5216.0380\n",
      "Epoch 58/1000 | Batch 0/237 | Loss: 5988.5640\n",
      "Epoch 58/1000 | Batch 100/237 | Loss: 19439.9297\n",
      "Epoch 58/1000 | Batch 200/237 | Loss: 5060.6582\n",
      "Epoch 58/1000 complete | Avg Loss: 5206.5611\n",
      "Epoch 59/1000 | Batch 0/237 | Loss: 4821.2529\n",
      "Epoch 59/1000 | Batch 100/237 | Loss: 417.7094\n",
      "Epoch 59/1000 | Batch 200/237 | Loss: 615.8786\n",
      "Epoch 59/1000 complete | Avg Loss: 5204.5411\n",
      "Epoch 60/1000 | Batch 0/237 | Loss: 1519.7570\n",
      "Epoch 60/1000 | Batch 100/237 | Loss: 10339.3359\n",
      "Epoch 60/1000 | Batch 200/237 | Loss: 5694.5332\n",
      "Epoch 60/1000 complete | Avg Loss: 5199.7811\n",
      "Epoch 61/1000 | Batch 0/237 | Loss: 1248.5159\n",
      "Epoch 61/1000 | Batch 100/237 | Loss: 8292.8252\n",
      "Epoch 61/1000 | Batch 200/237 | Loss: 666.8438\n",
      "Epoch 61/1000 complete | Avg Loss: 5197.4839\n",
      "Epoch 62/1000 | Batch 0/237 | Loss: 1908.6641\n",
      "Epoch 62/1000 | Batch 100/237 | Loss: 1999.2314\n",
      "Epoch 62/1000 | Batch 200/237 | Loss: 55053.3320\n",
      "Epoch 62/1000 complete | Avg Loss: 5191.5140\n",
      "Epoch 63/1000 | Batch 0/237 | Loss: 16248.7695\n",
      "Epoch 63/1000 | Batch 100/237 | Loss: 9926.3506\n",
      "Epoch 63/1000 | Batch 200/237 | Loss: 2690.4590\n",
      "Epoch 63/1000 complete | Avg Loss: 5195.7470\n",
      "Epoch 64/1000 | Batch 0/237 | Loss: 3058.2300\n",
      "Epoch 64/1000 | Batch 100/237 | Loss: 12238.2031\n",
      "Epoch 64/1000 | Batch 200/237 | Loss: 38365.8633\n",
      "Epoch 64/1000 complete | Avg Loss: 5192.0539\n",
      "Epoch 65/1000 | Batch 0/237 | Loss: 628.1646\n",
      "Epoch 65/1000 | Batch 100/237 | Loss: 474.7812\n",
      "Epoch 65/1000 | Batch 200/237 | Loss: 628.8461\n",
      "Epoch 65/1000 complete | Avg Loss: 5189.6997\n",
      "Epoch 66/1000 | Batch 0/237 | Loss: 2823.0122\n",
      "Epoch 66/1000 | Batch 100/237 | Loss: 968.8910\n",
      "Epoch 66/1000 | Batch 200/237 | Loss: 8621.4512\n",
      "Epoch 66/1000 complete | Avg Loss: 5188.0071\n",
      "Epoch 67/1000 | Batch 0/237 | Loss: 1587.4911\n",
      "Epoch 67/1000 | Batch 100/237 | Loss: 1340.7947\n",
      "Epoch 67/1000 | Batch 200/237 | Loss: 536.8796\n",
      "Epoch 67/1000 complete | Avg Loss: 5180.6566\n",
      "Epoch 68/1000 | Batch 0/237 | Loss: 2377.9136\n",
      "Epoch 68/1000 | Batch 100/237 | Loss: 23212.8066\n",
      "Epoch 68/1000 | Batch 200/237 | Loss: 4257.6089\n",
      "Epoch 68/1000 complete | Avg Loss: 5182.1627\n",
      "Epoch 69/1000 | Batch 0/237 | Loss: 2576.6416\n",
      "Epoch 69/1000 | Batch 100/237 | Loss: 788.3801\n",
      "Epoch 69/1000 | Batch 200/237 | Loss: 6141.0571\n",
      "Epoch 69/1000 complete | Avg Loss: 5189.5062\n",
      "Epoch 70/1000 | Batch 0/237 | Loss: 9907.8486\n",
      "Epoch 70/1000 | Batch 100/237 | Loss: 10560.6523\n",
      "Epoch 70/1000 | Batch 200/237 | Loss: 960.7755\n",
      "Epoch 70/1000 complete | Avg Loss: 5174.8471\n",
      "Epoch 71/1000 | Batch 0/237 | Loss: 1633.3256\n",
      "Epoch 71/1000 | Batch 100/237 | Loss: 4055.5708\n",
      "Epoch 71/1000 | Batch 200/237 | Loss: 3590.2881\n",
      "Epoch 71/1000 complete | Avg Loss: 5176.4127\n",
      "Epoch 72/1000 | Batch 0/237 | Loss: 3298.9617\n",
      "Epoch 72/1000 | Batch 100/237 | Loss: 1178.0374\n",
      "Epoch 72/1000 | Batch 200/237 | Loss: 625.8070\n",
      "Epoch 72/1000 complete | Avg Loss: 5179.7609\n",
      "Epoch 73/1000 | Batch 0/237 | Loss: 3508.5659\n",
      "Epoch 73/1000 | Batch 100/237 | Loss: 1292.3167\n",
      "Epoch 73/1000 | Batch 200/237 | Loss: 2960.4666\n",
      "Epoch 73/1000 complete | Avg Loss: 5193.6027\n",
      "Epoch 74/1000 | Batch 0/237 | Loss: 1946.7944\n",
      "Epoch 74/1000 | Batch 100/237 | Loss: 335.8202\n",
      "Epoch 74/1000 | Batch 200/237 | Loss: 5743.2603\n",
      "Epoch 74/1000 complete | Avg Loss: 5173.0050\n",
      "Epoch 75/1000 | Batch 0/237 | Loss: 642.0460\n",
      "Epoch 75/1000 | Batch 100/237 | Loss: 1001.8051\n",
      "Epoch 75/1000 | Batch 200/237 | Loss: 1438.9460\n",
      "Epoch 75/1000 complete | Avg Loss: 5165.0274\n",
      "Epoch 76/1000 | Batch 0/237 | Loss: 408.3962\n",
      "Epoch 76/1000 | Batch 100/237 | Loss: 822.9065\n",
      "Epoch 76/1000 | Batch 200/237 | Loss: 1284.6960\n",
      "Epoch 76/1000 complete | Avg Loss: 5164.7908\n",
      "Epoch 77/1000 | Batch 0/237 | Loss: 1213.5752\n",
      "Epoch 77/1000 | Batch 100/237 | Loss: 496.7285\n",
      "Epoch 77/1000 | Batch 200/237 | Loss: 35195.3750\n",
      "Epoch 77/1000 complete | Avg Loss: 5160.0464\n",
      "Epoch 78/1000 | Batch 0/237 | Loss: 1506.9368\n",
      "Epoch 78/1000 | Batch 100/237 | Loss: 19708.1797\n",
      "Epoch 78/1000 | Batch 200/237 | Loss: 1934.2147\n",
      "Epoch 78/1000 complete | Avg Loss: 5160.6563\n",
      "Epoch 79/1000 | Batch 0/237 | Loss: 5683.4312\n",
      "Epoch 79/1000 | Batch 100/237 | Loss: 1912.0637\n",
      "Epoch 79/1000 | Batch 200/237 | Loss: 3119.3105\n",
      "Epoch 79/1000 complete | Avg Loss: 5149.2103\n",
      "Epoch 80/1000 | Batch 0/237 | Loss: 4784.6187\n",
      "Epoch 80/1000 | Batch 100/237 | Loss: 691.4135\n",
      "Epoch 80/1000 | Batch 200/237 | Loss: 2696.1218\n",
      "Epoch 80/1000 complete | Avg Loss: 5159.1794\n",
      "Epoch 81/1000 | Batch 0/237 | Loss: 2299.9663\n",
      "Epoch 81/1000 | Batch 100/237 | Loss: 717.0020\n",
      "Epoch 81/1000 | Batch 200/237 | Loss: 2005.0632\n",
      "Epoch 81/1000 complete | Avg Loss: 5147.8730\n",
      "Epoch 82/1000 | Batch 0/237 | Loss: 2017.1288\n",
      "Epoch 82/1000 | Batch 100/237 | Loss: 1145.6389\n",
      "Epoch 82/1000 | Batch 200/237 | Loss: 3634.1562\n",
      "Epoch 82/1000 complete | Avg Loss: 5150.4285\n",
      "Epoch 83/1000 | Batch 0/237 | Loss: 2512.0376\n",
      "Epoch 83/1000 | Batch 100/237 | Loss: 1590.1024\n",
      "Epoch 83/1000 | Batch 200/237 | Loss: 8414.0928\n",
      "Epoch 83/1000 complete | Avg Loss: 5148.6534\n",
      "Epoch 84/1000 | Batch 0/237 | Loss: 2868.9265\n",
      "Epoch 84/1000 | Batch 100/237 | Loss: 32270.4902\n",
      "Epoch 84/1000 | Batch 200/237 | Loss: 2038.2039\n",
      "Epoch 84/1000 complete | Avg Loss: 5147.5535\n",
      "Epoch 85/1000 | Batch 0/237 | Loss: 38879.4492\n",
      "Epoch 85/1000 | Batch 100/237 | Loss: 11683.2217\n",
      "Epoch 85/1000 | Batch 200/237 | Loss: 720.6682\n",
      "Epoch 85/1000 complete | Avg Loss: 5142.7006\n",
      "Epoch 86/1000 | Batch 0/237 | Loss: 2868.6670\n",
      "Epoch 86/1000 | Batch 100/237 | Loss: 4140.1069\n",
      "Epoch 86/1000 | Batch 200/237 | Loss: 2191.9663\n",
      "Epoch 86/1000 complete | Avg Loss: 5211.8966\n",
      "Epoch 87/1000 | Batch 0/237 | Loss: 782.5615\n",
      "Epoch 87/1000 | Batch 100/237 | Loss: 2458.3264\n",
      "Epoch 87/1000 | Batch 200/237 | Loss: 31501.5625\n",
      "Epoch 87/1000 complete | Avg Loss: 5141.8717\n",
      "Epoch 88/1000 | Batch 0/237 | Loss: 3481.0095\n",
      "Epoch 88/1000 | Batch 100/237 | Loss: 2462.3311\n",
      "Epoch 88/1000 | Batch 200/237 | Loss: 1482.5143\n",
      "Epoch 88/1000 complete | Avg Loss: 5138.7480\n",
      "Epoch 89/1000 | Batch 0/237 | Loss: 536.2144\n",
      "Epoch 89/1000 | Batch 100/237 | Loss: 948.1562\n",
      "Epoch 89/1000 | Batch 200/237 | Loss: 922.9749\n",
      "Epoch 89/1000 complete | Avg Loss: 5134.9623\n",
      "Epoch 90/1000 | Batch 0/237 | Loss: 30949.5488\n",
      "Epoch 90/1000 | Batch 100/237 | Loss: 1144.0339\n",
      "Epoch 90/1000 | Batch 200/237 | Loss: 354.3743\n",
      "Epoch 90/1000 complete | Avg Loss: 5166.1484\n",
      "Epoch 91/1000 | Batch 0/237 | Loss: 730.7523\n",
      "Epoch 91/1000 | Batch 100/237 | Loss: 8149.9141\n",
      "Epoch 91/1000 | Batch 200/237 | Loss: 1223.9673\n",
      "Epoch 91/1000 complete | Avg Loss: 5131.6630\n",
      "Epoch 92/1000 | Batch 0/237 | Loss: 2536.4883\n",
      "Epoch 92/1000 | Batch 100/237 | Loss: 5424.9907\n",
      "Epoch 92/1000 | Batch 200/237 | Loss: 3976.3242\n",
      "Epoch 92/1000 complete | Avg Loss: 5130.1747\n",
      "Epoch 93/1000 | Batch 0/237 | Loss: 2506.1504\n",
      "Epoch 93/1000 | Batch 100/237 | Loss: 3420.3574\n",
      "Epoch 93/1000 | Batch 200/237 | Loss: 1576.5146\n",
      "Epoch 93/1000 complete | Avg Loss: 5124.3009\n",
      "Epoch 94/1000 | Batch 0/237 | Loss: 1107.2766\n",
      "Epoch 94/1000 | Batch 100/237 | Loss: 1073.0847\n",
      "Epoch 94/1000 | Batch 200/237 | Loss: 439.4735\n",
      "Epoch 94/1000 complete | Avg Loss: 5279.4365\n",
      "Epoch 95/1000 | Batch 0/237 | Loss: 28712.3086\n",
      "Epoch 95/1000 | Batch 100/237 | Loss: 3415.4407\n",
      "Epoch 95/1000 | Batch 200/237 | Loss: 20991.0742\n",
      "Epoch 95/1000 complete | Avg Loss: 5136.9650\n",
      "Epoch 96/1000 | Batch 0/237 | Loss: 8031.2739\n",
      "Epoch 96/1000 | Batch 100/237 | Loss: 3686.7583\n",
      "Epoch 96/1000 | Batch 200/237 | Loss: 657.6053\n",
      "Epoch 96/1000 complete | Avg Loss: 5122.2885\n",
      "Epoch 97/1000 | Batch 0/237 | Loss: 4976.7178\n",
      "Epoch 97/1000 | Batch 100/237 | Loss: 1154.4231\n",
      "Epoch 97/1000 | Batch 200/237 | Loss: 2149.3374\n",
      "Epoch 97/1000 complete | Avg Loss: 5123.1625\n",
      "Epoch 98/1000 | Batch 0/237 | Loss: 1159.0322\n",
      "Epoch 98/1000 | Batch 100/237 | Loss: 1624.8060\n",
      "Epoch 98/1000 | Batch 200/237 | Loss: 580.9982\n",
      "Epoch 98/1000 complete | Avg Loss: 5115.7061\n",
      "Epoch 99/1000 | Batch 0/237 | Loss: 546.0759\n",
      "Epoch 99/1000 | Batch 100/237 | Loss: 7914.8271\n",
      "Epoch 99/1000 | Batch 200/237 | Loss: 3897.5251\n",
      "Epoch 99/1000 complete | Avg Loss: 5117.9977\n",
      "Epoch 100/1000 | Batch 0/237 | Loss: 579.9080\n",
      "Epoch 100/1000 | Batch 100/237 | Loss: 1536.1470\n",
      "Epoch 100/1000 | Batch 200/237 | Loss: 1642.5972\n",
      "Epoch 100/1000 complete | Avg Loss: 5121.0838\n",
      "Epoch 101/1000 | Batch 0/237 | Loss: 1839.1746\n",
      "Epoch 101/1000 | Batch 100/237 | Loss: 2482.9243\n",
      "Epoch 101/1000 | Batch 200/237 | Loss: 693.6445\n",
      "Epoch 101/1000 complete | Avg Loss: 5110.6823\n",
      "Epoch 102/1000 | Batch 0/237 | Loss: 514.7612\n",
      "Epoch 102/1000 | Batch 100/237 | Loss: 4596.3159\n",
      "Epoch 102/1000 | Batch 200/237 | Loss: 746.5341\n",
      "Epoch 102/1000 complete | Avg Loss: 5105.4289\n",
      "Epoch 103/1000 | Batch 0/237 | Loss: 1972.0609\n",
      "Epoch 103/1000 | Batch 100/237 | Loss: 1147.0894\n",
      "Epoch 103/1000 | Batch 200/237 | Loss: 3468.1748\n",
      "Epoch 103/1000 complete | Avg Loss: 5104.2364\n",
      "Epoch 104/1000 | Batch 0/237 | Loss: 1735.6326\n",
      "Epoch 104/1000 | Batch 100/237 | Loss: 1524.6859\n",
      "Epoch 104/1000 | Batch 200/237 | Loss: 6474.4604\n",
      "Epoch 104/1000 complete | Avg Loss: 5119.3054\n",
      "Epoch 105/1000 | Batch 0/237 | Loss: 1646.6401\n",
      "Epoch 105/1000 | Batch 100/237 | Loss: 11224.2842\n",
      "Epoch 105/1000 | Batch 200/237 | Loss: 570.8984\n",
      "Epoch 105/1000 complete | Avg Loss: 5100.8870\n",
      "Epoch 106/1000 | Batch 0/237 | Loss: 4181.2466\n",
      "Epoch 106/1000 | Batch 100/237 | Loss: 2984.1594\n",
      "Epoch 106/1000 | Batch 200/237 | Loss: 4449.5083\n",
      "Epoch 106/1000 complete | Avg Loss: 5107.7527\n",
      "Epoch 107/1000 | Batch 0/237 | Loss: 1444.5979\n",
      "Epoch 107/1000 | Batch 100/237 | Loss: 459.4045\n",
      "Epoch 107/1000 | Batch 200/237 | Loss: 2398.5366\n",
      "Epoch 107/1000 complete | Avg Loss: 5104.8852\n",
      "Epoch 108/1000 | Batch 0/237 | Loss: 1449.0333\n",
      "Epoch 108/1000 | Batch 100/237 | Loss: 2321.0503\n",
      "Epoch 108/1000 | Batch 200/237 | Loss: 597.0325\n",
      "Epoch 108/1000 complete | Avg Loss: 5096.4820\n",
      "Epoch 109/1000 | Batch 0/237 | Loss: 2573.0669\n",
      "Epoch 109/1000 | Batch 100/237 | Loss: 33495.1055\n",
      "Epoch 109/1000 | Batch 200/237 | Loss: 502.1690\n",
      "Epoch 109/1000 complete | Avg Loss: 5138.5980\n",
      "Epoch 110/1000 | Batch 0/237 | Loss: 24083.8125\n",
      "Epoch 110/1000 | Batch 100/237 | Loss: 814.0806\n",
      "Epoch 110/1000 | Batch 200/237 | Loss: 1244.3744\n",
      "Epoch 110/1000 complete | Avg Loss: 5089.2454\n",
      "Epoch 111/1000 | Batch 0/237 | Loss: 6948.7930\n",
      "Epoch 111/1000 | Batch 100/237 | Loss: 8543.7754\n",
      "Epoch 111/1000 | Batch 200/237 | Loss: 10525.7275\n",
      "Epoch 111/1000 complete | Avg Loss: 5150.3592\n",
      "Epoch 112/1000 | Batch 0/237 | Loss: 2091.9331\n",
      "Epoch 112/1000 | Batch 100/237 | Loss: 2253.1924\n",
      "Epoch 112/1000 | Batch 200/237 | Loss: 2306.0942\n",
      "Epoch 112/1000 complete | Avg Loss: 5089.9864\n",
      "Epoch 113/1000 | Batch 0/237 | Loss: 620.2198\n",
      "Epoch 113/1000 | Batch 100/237 | Loss: 1226.3322\n",
      "Epoch 113/1000 | Batch 200/237 | Loss: 3672.7261\n",
      "Epoch 113/1000 complete | Avg Loss: 5085.9101\n",
      "Epoch 114/1000 | Batch 0/237 | Loss: 2508.5652\n",
      "Epoch 114/1000 | Batch 100/237 | Loss: 1389.4659\n",
      "Epoch 114/1000 | Batch 200/237 | Loss: 12294.9004\n",
      "Epoch 114/1000 complete | Avg Loss: 5088.5259\n",
      "Epoch 115/1000 | Batch 0/237 | Loss: 522.1594\n",
      "Epoch 115/1000 | Batch 100/237 | Loss: 8481.1152\n",
      "Epoch 115/1000 | Batch 200/237 | Loss: 1583.4969\n",
      "Epoch 115/1000 complete | Avg Loss: 5092.3151\n",
      "Epoch 116/1000 | Batch 0/237 | Loss: 20355.8945\n",
      "Epoch 116/1000 | Batch 100/237 | Loss: 1294.6564\n",
      "Epoch 116/1000 | Batch 200/237 | Loss: 33844.2734\n",
      "Epoch 116/1000 complete | Avg Loss: 5079.4642\n",
      "Epoch 117/1000 | Batch 0/237 | Loss: 5007.6221\n",
      "Epoch 117/1000 | Batch 100/237 | Loss: 963.3923\n",
      "Epoch 117/1000 | Batch 200/237 | Loss: 2704.9641\n",
      "Epoch 117/1000 complete | Avg Loss: 5078.2462\n",
      "Epoch 118/1000 | Batch 0/237 | Loss: 859.5016\n",
      "Epoch 118/1000 | Batch 100/237 | Loss: 26855.9980\n",
      "Epoch 118/1000 | Batch 200/237 | Loss: 1979.0430\n",
      "Epoch 118/1000 complete | Avg Loss: 5081.0460\n",
      "Epoch 119/1000 | Batch 0/237 | Loss: 1151.8638\n",
      "Epoch 119/1000 | Batch 100/237 | Loss: 999.3190\n",
      "Epoch 119/1000 | Batch 200/237 | Loss: 6781.3760\n",
      "Epoch 119/1000 complete | Avg Loss: 5074.6380\n",
      "Epoch 120/1000 | Batch 0/237 | Loss: 1730.5851\n",
      "Epoch 120/1000 | Batch 100/237 | Loss: 1178.6193\n",
      "Epoch 120/1000 | Batch 200/237 | Loss: 3094.5332\n",
      "Epoch 120/1000 complete | Avg Loss: 5085.6894\n",
      "Epoch 121/1000 | Batch 0/237 | Loss: 6808.9136\n",
      "Epoch 121/1000 | Batch 100/237 | Loss: 659.4276\n",
      "Epoch 121/1000 | Batch 200/237 | Loss: 1822.8220\n",
      "Epoch 121/1000 complete | Avg Loss: 5074.1874\n",
      "Epoch 122/1000 | Batch 0/237 | Loss: 859.5510\n",
      "Epoch 122/1000 | Batch 100/237 | Loss: 1716.5251\n",
      "Epoch 122/1000 | Batch 200/237 | Loss: 7665.2842\n",
      "Epoch 122/1000 complete | Avg Loss: 5065.4612\n",
      "Epoch 123/1000 | Batch 0/237 | Loss: 6354.0703\n",
      "Epoch 123/1000 | Batch 100/237 | Loss: 3194.0017\n",
      "Epoch 123/1000 | Batch 200/237 | Loss: 12012.3447\n",
      "Epoch 123/1000 complete | Avg Loss: 5092.4784\n",
      "Epoch 124/1000 | Batch 0/237 | Loss: 2372.5435\n",
      "Epoch 124/1000 | Batch 100/237 | Loss: 1261.4866\n",
      "Epoch 124/1000 | Batch 200/237 | Loss: 1042.7310\n",
      "Epoch 124/1000 complete | Avg Loss: 5060.2551\n",
      "Epoch 125/1000 | Batch 0/237 | Loss: 1671.8491\n",
      "Epoch 125/1000 | Batch 100/237 | Loss: 832.0765\n",
      "Epoch 125/1000 | Batch 200/237 | Loss: 757.3605\n",
      "Epoch 125/1000 complete | Avg Loss: 5066.1703\n",
      "Epoch 126/1000 | Batch 0/237 | Loss: 598.8547\n",
      "Epoch 126/1000 | Batch 100/237 | Loss: 1842.3501\n",
      "Epoch 126/1000 | Batch 200/237 | Loss: 602.8992\n",
      "Epoch 126/1000 complete | Avg Loss: 5115.0012\n",
      "Epoch 127/1000 | Batch 0/237 | Loss: 1928.5753\n",
      "Epoch 127/1000 | Batch 100/237 | Loss: 1310.2521\n",
      "Epoch 127/1000 | Batch 200/237 | Loss: 1548.5973\n",
      "Epoch 127/1000 complete | Avg Loss: 5059.9766\n",
      "Epoch 128/1000 | Batch 0/237 | Loss: 5542.6118\n",
      "Epoch 128/1000 | Batch 100/237 | Loss: 1178.8813\n",
      "Epoch 128/1000 | Batch 200/237 | Loss: 3465.7798\n",
      "Epoch 128/1000 complete | Avg Loss: 5052.6010\n",
      "Epoch 129/1000 | Batch 0/237 | Loss: 2225.2190\n",
      "Epoch 129/1000 | Batch 100/237 | Loss: 7613.3721\n",
      "Epoch 129/1000 | Batch 200/237 | Loss: 5440.5571\n",
      "Epoch 129/1000 complete | Avg Loss: 5055.0229\n",
      "Epoch 130/1000 | Batch 0/237 | Loss: 1652.5557\n",
      "Epoch 130/1000 | Batch 100/237 | Loss: 1239.1271\n",
      "Epoch 130/1000 | Batch 200/237 | Loss: 807.5413\n",
      "Epoch 130/1000 complete | Avg Loss: 5054.0958\n",
      "Epoch 131/1000 | Batch 0/237 | Loss: 2721.4138\n",
      "Epoch 131/1000 | Batch 100/237 | Loss: 890.4508\n",
      "Epoch 131/1000 | Batch 200/237 | Loss: 15285.0596\n",
      "Epoch 131/1000 complete | Avg Loss: 5046.9954\n",
      "Epoch 132/1000 | Batch 0/237 | Loss: 29004.1074\n",
      "Epoch 132/1000 | Batch 100/237 | Loss: 2770.4250\n",
      "Epoch 132/1000 | Batch 200/237 | Loss: 884.8974\n",
      "Epoch 132/1000 complete | Avg Loss: 5046.2408\n",
      "Epoch 133/1000 | Batch 0/237 | Loss: 654.7130\n",
      "Epoch 133/1000 | Batch 100/237 | Loss: 935.0750\n",
      "Epoch 133/1000 | Batch 200/237 | Loss: 1782.6069\n",
      "Epoch 133/1000 complete | Avg Loss: 5048.9087\n",
      "Epoch 134/1000 | Batch 0/237 | Loss: 2534.4583\n",
      "Epoch 134/1000 | Batch 100/237 | Loss: 2347.7380\n",
      "Epoch 134/1000 | Batch 200/237 | Loss: 5393.6191\n",
      "Epoch 134/1000 complete | Avg Loss: 5044.6432\n",
      "Epoch 135/1000 | Batch 0/237 | Loss: 548.8152\n",
      "Epoch 135/1000 | Batch 100/237 | Loss: 32299.8008\n",
      "Epoch 135/1000 | Batch 200/237 | Loss: 2139.9270\n",
      "Epoch 135/1000 complete | Avg Loss: 5038.8875\n",
      "Epoch 136/1000 | Batch 0/237 | Loss: 12274.0566\n",
      "Epoch 136/1000 | Batch 100/237 | Loss: 11277.2236\n",
      "Epoch 136/1000 | Batch 200/237 | Loss: 6164.2842\n",
      "Epoch 136/1000 complete | Avg Loss: 5033.4901\n",
      "Epoch 137/1000 | Batch 0/237 | Loss: 1058.6107\n",
      "Epoch 137/1000 | Batch 100/237 | Loss: 1088.7129\n",
      "Epoch 137/1000 | Batch 200/237 | Loss: 17127.6621\n",
      "Epoch 137/1000 complete | Avg Loss: 5059.8923\n",
      "Epoch 138/1000 | Batch 0/237 | Loss: 1091.6785\n",
      "Epoch 138/1000 | Batch 100/237 | Loss: 8008.1211\n",
      "Epoch 138/1000 | Batch 200/237 | Loss: 5097.9419\n",
      "Epoch 138/1000 complete | Avg Loss: 5035.4263\n",
      "Epoch 139/1000 | Batch 0/237 | Loss: 8838.1914\n",
      "Epoch 139/1000 | Batch 100/237 | Loss: 1088.1527\n",
      "Epoch 139/1000 | Batch 200/237 | Loss: 1747.1558\n",
      "Epoch 139/1000 complete | Avg Loss: 5039.0882\n",
      "Epoch 140/1000 | Batch 0/237 | Loss: 14092.7676\n",
      "Epoch 140/1000 | Batch 100/237 | Loss: 4981.7080\n",
      "Epoch 140/1000 | Batch 200/237 | Loss: 7779.6372\n",
      "Epoch 140/1000 complete | Avg Loss: 5034.4153\n",
      "Epoch 141/1000 | Batch 0/237 | Loss: 5934.8882\n",
      "Epoch 141/1000 | Batch 100/237 | Loss: 4395.3608\n",
      "Epoch 141/1000 | Batch 200/237 | Loss: 2507.7446\n",
      "Epoch 141/1000 complete | Avg Loss: 5033.2324\n",
      "Epoch 142/1000 | Batch 0/237 | Loss: 864.7878\n",
      "Epoch 142/1000 | Batch 100/237 | Loss: 2539.6140\n",
      "Epoch 142/1000 | Batch 200/237 | Loss: 730.0490\n",
      "Epoch 142/1000 complete | Avg Loss: 5084.3823\n",
      "Epoch 143/1000 | Batch 0/237 | Loss: 2181.8347\n",
      "Epoch 143/1000 | Batch 100/237 | Loss: 13409.1553\n",
      "Epoch 143/1000 | Batch 200/237 | Loss: 6036.1836\n",
      "Epoch 143/1000 complete | Avg Loss: 5023.0887\n",
      "Epoch 144/1000 | Batch 0/237 | Loss: 17464.8105\n",
      "Epoch 144/1000 | Batch 100/237 | Loss: 9205.4111\n",
      "Epoch 144/1000 | Batch 200/237 | Loss: 17466.9219\n",
      "Epoch 144/1000 complete | Avg Loss: 5023.2257\n",
      "Epoch 145/1000 | Batch 0/237 | Loss: 3223.2881\n",
      "Epoch 145/1000 | Batch 100/237 | Loss: 545.6564\n",
      "Epoch 145/1000 | Batch 200/237 | Loss: 2679.6362\n",
      "Epoch 145/1000 complete | Avg Loss: 5017.2526\n",
      "Epoch 146/1000 | Batch 0/237 | Loss: 1473.2882\n",
      "Epoch 146/1000 | Batch 100/237 | Loss: 1340.9432\n",
      "Epoch 146/1000 | Batch 200/237 | Loss: 932.4314\n",
      "Epoch 146/1000 complete | Avg Loss: 5020.2838\n",
      "Epoch 147/1000 | Batch 0/237 | Loss: 2114.6597\n",
      "Epoch 147/1000 | Batch 100/237 | Loss: 17332.4238\n",
      "Epoch 147/1000 | Batch 200/237 | Loss: 725.3323\n",
      "Epoch 147/1000 complete | Avg Loss: 5016.2242\n",
      "Epoch 148/1000 | Batch 0/237 | Loss: 17349.2852\n",
      "Epoch 148/1000 | Batch 100/237 | Loss: 4595.5508\n",
      "Epoch 148/1000 | Batch 200/237 | Loss: 2549.9812\n",
      "Epoch 148/1000 complete | Avg Loss: 5015.7654\n",
      "Epoch 149/1000 | Batch 0/237 | Loss: 9609.2188\n",
      "Epoch 149/1000 | Batch 100/237 | Loss: 852.8760\n",
      "Epoch 149/1000 | Batch 200/237 | Loss: 752.1746\n",
      "Epoch 149/1000 complete | Avg Loss: 5006.7804\n",
      "Epoch 150/1000 | Batch 0/237 | Loss: 680.1859\n",
      "Epoch 150/1000 | Batch 100/237 | Loss: 12504.7588\n",
      "Epoch 150/1000 | Batch 200/237 | Loss: 3554.9175\n",
      "Epoch 150/1000 complete | Avg Loss: 5019.8855\n",
      "Epoch 151/1000 | Batch 0/237 | Loss: 6575.6660\n",
      "Epoch 151/1000 | Batch 100/237 | Loss: 14676.2266\n",
      "Epoch 151/1000 | Batch 200/237 | Loss: 1317.7817\n",
      "Epoch 151/1000 complete | Avg Loss: 5021.9632\n",
      "Epoch 152/1000 | Batch 0/237 | Loss: 3661.2649\n",
      "Epoch 152/1000 | Batch 100/237 | Loss: 1337.1909\n",
      "Epoch 152/1000 | Batch 200/237 | Loss: 1995.3088\n",
      "Epoch 152/1000 complete | Avg Loss: 5005.1951\n",
      "Epoch 153/1000 | Batch 0/237 | Loss: 3505.2766\n",
      "Epoch 153/1000 | Batch 100/237 | Loss: 11068.2285\n",
      "Epoch 153/1000 | Batch 200/237 | Loss: 1290.9520\n",
      "Epoch 153/1000 complete | Avg Loss: 5010.6621\n",
      "Epoch 154/1000 | Batch 0/237 | Loss: 3283.8267\n",
      "Epoch 154/1000 | Batch 100/237 | Loss: 656.4946\n",
      "Epoch 154/1000 | Batch 200/237 | Loss: 915.1671\n",
      "Epoch 154/1000 complete | Avg Loss: 5005.0701\n",
      "Epoch 155/1000 | Batch 0/237 | Loss: 534.2917\n",
      "Epoch 155/1000 | Batch 100/237 | Loss: 1718.8240\n",
      "Epoch 155/1000 | Batch 200/237 | Loss: 10662.8389\n",
      "Epoch 155/1000 complete | Avg Loss: 5000.3867\n",
      "Epoch 156/1000 | Batch 0/237 | Loss: 19706.8203\n",
      "Epoch 156/1000 | Batch 100/237 | Loss: 824.0460\n",
      "Epoch 156/1000 | Batch 200/237 | Loss: 6856.2363\n",
      "Epoch 156/1000 complete | Avg Loss: 4997.0697\n",
      "Epoch 157/1000 | Batch 0/237 | Loss: 952.4965\n",
      "Epoch 157/1000 | Batch 100/237 | Loss: 32256.6836\n",
      "Epoch 157/1000 | Batch 200/237 | Loss: 510.2617\n",
      "Epoch 157/1000 complete | Avg Loss: 4999.1907\n",
      "Epoch 158/1000 | Batch 0/237 | Loss: 2637.4856\n",
      "Epoch 158/1000 | Batch 100/237 | Loss: 826.1415\n",
      "Epoch 158/1000 | Batch 200/237 | Loss: 724.1010\n",
      "Epoch 158/1000 complete | Avg Loss: 4990.4662\n",
      "Epoch 159/1000 | Batch 0/237 | Loss: 3050.1445\n",
      "Epoch 159/1000 | Batch 100/237 | Loss: 2562.8188\n",
      "Epoch 159/1000 | Batch 200/237 | Loss: 1544.3999\n",
      "Epoch 159/1000 complete | Avg Loss: 4993.7551\n",
      "Epoch 160/1000 | Batch 0/237 | Loss: 1455.0474\n",
      "Epoch 160/1000 | Batch 100/237 | Loss: 9956.5107\n",
      "Epoch 160/1000 | Batch 200/237 | Loss: 3041.2385\n",
      "Epoch 160/1000 complete | Avg Loss: 5016.9565\n",
      "Epoch 161/1000 | Batch 0/237 | Loss: 620.9645\n",
      "Epoch 161/1000 | Batch 100/237 | Loss: 1076.7104\n",
      "Epoch 161/1000 | Batch 200/237 | Loss: 800.7480\n",
      "Epoch 161/1000 complete | Avg Loss: 4986.0131\n",
      "Epoch 162/1000 | Batch 0/237 | Loss: 4827.7168\n",
      "Epoch 162/1000 | Batch 100/237 | Loss: 4786.7651\n",
      "Epoch 162/1000 | Batch 200/237 | Loss: 550.2458\n",
      "Epoch 162/1000 complete | Avg Loss: 4996.0152\n",
      "Epoch 163/1000 | Batch 0/237 | Loss: 2692.2908\n",
      "Epoch 163/1000 | Batch 100/237 | Loss: 1068.2341\n",
      "Epoch 163/1000 | Batch 200/237 | Loss: 24671.4355\n",
      "Epoch 163/1000 complete | Avg Loss: 4988.8513\n",
      "Epoch 164/1000 | Batch 0/237 | Loss: 1992.3477\n",
      "Epoch 164/1000 | Batch 100/237 | Loss: 1371.5483\n",
      "Epoch 164/1000 | Batch 200/237 | Loss: 3851.4060\n",
      "Epoch 164/1000 complete | Avg Loss: 4979.9947\n",
      "Epoch 165/1000 | Batch 0/237 | Loss: 1611.0121\n",
      "Epoch 165/1000 | Batch 100/237 | Loss: 2400.0605\n",
      "Epoch 165/1000 | Batch 200/237 | Loss: 2264.2146\n",
      "Epoch 165/1000 complete | Avg Loss: 4985.9610\n",
      "Epoch 166/1000 | Batch 0/237 | Loss: 8435.5889\n",
      "Epoch 166/1000 | Batch 100/237 | Loss: 2084.8879\n",
      "Epoch 166/1000 | Batch 200/237 | Loss: 1016.3270\n",
      "Epoch 166/1000 complete | Avg Loss: 4977.1790\n",
      "Epoch 167/1000 | Batch 0/237 | Loss: 604.1297\n",
      "Epoch 167/1000 | Batch 100/237 | Loss: 2180.2939\n",
      "Epoch 167/1000 | Batch 200/237 | Loss: 621.4070\n",
      "Epoch 167/1000 complete | Avg Loss: 5076.1551\n",
      "Epoch 168/1000 | Batch 0/237 | Loss: 31710.7188\n",
      "Epoch 168/1000 | Batch 100/237 | Loss: 22946.8379\n",
      "Epoch 168/1000 | Batch 200/237 | Loss: 1142.8210\n",
      "Epoch 168/1000 complete | Avg Loss: 4977.9745\n",
      "Epoch 169/1000 | Batch 0/237 | Loss: 850.3497\n",
      "Epoch 169/1000 | Batch 100/237 | Loss: 2434.4124\n",
      "Epoch 169/1000 | Batch 200/237 | Loss: 4283.8179\n",
      "Epoch 169/1000 complete | Avg Loss: 4975.2136\n",
      "Epoch 170/1000 | Batch 0/237 | Loss: 1035.7195\n",
      "Epoch 170/1000 | Batch 100/237 | Loss: 2505.6355\n",
      "Epoch 170/1000 | Batch 200/237 | Loss: 548.3441\n",
      "Epoch 170/1000 complete | Avg Loss: 4969.2579\n",
      "Epoch 171/1000 | Batch 0/237 | Loss: 1121.0232\n",
      "Epoch 171/1000 | Batch 100/237 | Loss: 1814.1494\n",
      "Epoch 171/1000 | Batch 200/237 | Loss: 4418.8530\n",
      "Epoch 171/1000 complete | Avg Loss: 4970.1973\n",
      "Epoch 172/1000 | Batch 0/237 | Loss: 7880.3105\n",
      "Epoch 172/1000 | Batch 100/237 | Loss: 2038.1091\n",
      "Epoch 172/1000 | Batch 200/237 | Loss: 1781.7905\n",
      "Epoch 172/1000 complete | Avg Loss: 4972.6385\n",
      "Epoch 173/1000 | Batch 0/237 | Loss: 19202.5371\n",
      "Epoch 173/1000 | Batch 100/237 | Loss: 7740.3677\n",
      "Epoch 173/1000 | Batch 200/237 | Loss: 2245.6877\n",
      "Epoch 173/1000 complete | Avg Loss: 4966.1862\n",
      "Epoch 174/1000 | Batch 0/237 | Loss: 2998.2717\n",
      "Epoch 174/1000 | Batch 100/237 | Loss: 31859.0977\n",
      "Epoch 174/1000 | Batch 200/237 | Loss: 2560.6753\n",
      "Epoch 174/1000 complete | Avg Loss: 4971.3840\n",
      "Epoch 175/1000 | Batch 0/237 | Loss: 2898.6423\n",
      "Epoch 175/1000 | Batch 100/237 | Loss: 4961.8306\n",
      "Epoch 175/1000 | Batch 200/237 | Loss: 5445.5342\n",
      "Epoch 175/1000 complete | Avg Loss: 4961.2750\n",
      "Epoch 176/1000 | Batch 0/237 | Loss: 1152.5398\n",
      "Epoch 176/1000 | Batch 100/237 | Loss: 1741.0967\n",
      "Epoch 176/1000 | Batch 200/237 | Loss: 4232.7539\n",
      "Epoch 176/1000 complete | Avg Loss: 4969.9435\n",
      "Epoch 177/1000 | Batch 0/237 | Loss: 2965.7263\n",
      "Epoch 177/1000 | Batch 100/237 | Loss: 1192.2665\n",
      "Epoch 177/1000 | Batch 200/237 | Loss: 1114.9905\n",
      "Epoch 177/1000 complete | Avg Loss: 4992.5554\n",
      "Epoch 178/1000 | Batch 0/237 | Loss: 3642.7617\n",
      "Epoch 178/1000 | Batch 100/237 | Loss: 1631.5056\n",
      "Epoch 178/1000 | Batch 200/237 | Loss: 28132.6992\n",
      "Epoch 178/1000 complete | Avg Loss: 4965.8774\n",
      "Epoch 179/1000 | Batch 0/237 | Loss: 4373.0830\n",
      "Epoch 179/1000 | Batch 100/237 | Loss: 973.6485\n",
      "Epoch 179/1000 | Batch 200/237 | Loss: 1327.0183\n",
      "Epoch 179/1000 complete | Avg Loss: 4951.4059\n",
      "Epoch 180/1000 | Batch 0/237 | Loss: 4030.7524\n",
      "Epoch 180/1000 | Batch 100/237 | Loss: 6709.0083\n",
      "Epoch 180/1000 | Batch 200/237 | Loss: 9737.9336\n",
      "Epoch 180/1000 complete | Avg Loss: 4952.3537\n",
      "Epoch 181/1000 | Batch 0/237 | Loss: 2450.6235\n",
      "Epoch 181/1000 | Batch 100/237 | Loss: 18614.3828\n",
      "Epoch 181/1000 | Batch 200/237 | Loss: 2095.2046\n",
      "Epoch 181/1000 complete | Avg Loss: 4951.0847\n",
      "Epoch 182/1000 | Batch 0/237 | Loss: 1143.2029\n",
      "Epoch 182/1000 | Batch 100/237 | Loss: 3743.0857\n",
      "Epoch 182/1000 | Batch 200/237 | Loss: 532.8200\n",
      "Epoch 182/1000 complete | Avg Loss: 4956.8797\n",
      "Epoch 183/1000 | Batch 0/237 | Loss: 1212.2955\n",
      "Epoch 183/1000 | Batch 100/237 | Loss: 6019.9644\n",
      "Epoch 183/1000 | Batch 200/237 | Loss: 1758.5938\n",
      "Epoch 183/1000 complete | Avg Loss: 4964.2504\n",
      "Epoch 184/1000 | Batch 0/237 | Loss: 870.7271\n",
      "Epoch 184/1000 | Batch 100/237 | Loss: 1240.0209\n",
      "Epoch 184/1000 | Batch 200/237 | Loss: 2325.8638\n",
      "Epoch 184/1000 complete | Avg Loss: 4977.0117\n",
      "Epoch 185/1000 | Batch 0/237 | Loss: 2238.7961\n",
      "Epoch 185/1000 | Batch 100/237 | Loss: 2406.5176\n",
      "Epoch 185/1000 | Batch 200/237 | Loss: 733.7731\n",
      "Epoch 185/1000 complete | Avg Loss: 4945.1076\n",
      "Epoch 186/1000 | Batch 0/237 | Loss: 689.2701\n",
      "Epoch 186/1000 | Batch 100/237 | Loss: 10737.2197\n",
      "Epoch 186/1000 | Batch 200/237 | Loss: 6772.9551\n",
      "Epoch 186/1000 complete | Avg Loss: 4942.4900\n",
      "Epoch 187/1000 | Batch 0/237 | Loss: 21964.0312\n",
      "Epoch 187/1000 | Batch 100/237 | Loss: 2459.0784\n",
      "Epoch 187/1000 | Batch 200/237 | Loss: 2361.1433\n",
      "Epoch 187/1000 complete | Avg Loss: 4992.8309\n",
      "Epoch 188/1000 | Batch 0/237 | Loss: 411.7422\n",
      "Epoch 188/1000 | Batch 100/237 | Loss: 2517.6274\n",
      "Epoch 188/1000 | Batch 200/237 | Loss: 1252.5844\n",
      "Epoch 188/1000 complete | Avg Loss: 4937.2495\n",
      "Epoch 189/1000 | Batch 0/237 | Loss: 617.1107\n",
      "Epoch 189/1000 | Batch 100/237 | Loss: 5993.9717\n",
      "Epoch 189/1000 | Batch 200/237 | Loss: 572.2405\n",
      "Epoch 189/1000 complete | Avg Loss: 4939.6087\n",
      "Epoch 190/1000 | Batch 0/237 | Loss: 2939.7830\n",
      "Epoch 190/1000 | Batch 100/237 | Loss: 32400.3223\n",
      "Epoch 190/1000 | Batch 200/237 | Loss: 6041.8916\n",
      "Epoch 190/1000 complete | Avg Loss: 4934.1863\n",
      "Epoch 191/1000 | Batch 0/237 | Loss: 1413.9233\n",
      "Epoch 191/1000 | Batch 100/237 | Loss: 2172.1433\n",
      "Epoch 191/1000 | Batch 200/237 | Loss: 3988.9150\n",
      "Epoch 191/1000 complete | Avg Loss: 5112.4206\n",
      "Epoch 192/1000 | Batch 0/237 | Loss: 4601.3750\n",
      "Epoch 192/1000 | Batch 100/237 | Loss: 590.2363\n",
      "Epoch 192/1000 | Batch 200/237 | Loss: 1269.1128\n",
      "Epoch 192/1000 complete | Avg Loss: 4935.0452\n",
      "Epoch 193/1000 | Batch 0/237 | Loss: 1852.2307\n",
      "Epoch 193/1000 | Batch 100/237 | Loss: 5372.8267\n",
      "Epoch 193/1000 | Batch 200/237 | Loss: 1786.8560\n",
      "Epoch 193/1000 complete | Avg Loss: 4935.6750\n",
      "Epoch 194/1000 | Batch 0/237 | Loss: 1428.6838\n",
      "Epoch 194/1000 | Batch 100/237 | Loss: 9885.7832\n",
      "Epoch 194/1000 | Batch 200/237 | Loss: 762.8920\n",
      "Epoch 194/1000 complete | Avg Loss: 4931.2721\n",
      "Epoch 195/1000 | Batch 0/237 | Loss: 2478.9756\n",
      "Epoch 195/1000 | Batch 100/237 | Loss: 4587.0469\n",
      "Epoch 195/1000 | Batch 200/237 | Loss: 18820.8164\n",
      "Epoch 195/1000 complete | Avg Loss: 4939.7758\n",
      "Epoch 196/1000 | Batch 0/237 | Loss: 581.4041\n",
      "Epoch 196/1000 | Batch 100/237 | Loss: 774.9426\n",
      "Epoch 196/1000 | Batch 200/237 | Loss: 4309.5630\n",
      "Epoch 196/1000 complete | Avg Loss: 4944.9825\n",
      "Epoch 197/1000 | Batch 0/237 | Loss: 1388.6570\n",
      "Epoch 197/1000 | Batch 100/237 | Loss: 2981.5081\n",
      "Epoch 197/1000 | Batch 200/237 | Loss: 802.1044\n",
      "Epoch 197/1000 complete | Avg Loss: 4929.8225\n",
      "Epoch 198/1000 | Batch 0/237 | Loss: 776.4334\n",
      "Epoch 198/1000 | Batch 100/237 | Loss: 7860.2998\n",
      "Epoch 198/1000 | Batch 200/237 | Loss: 2866.3005\n",
      "Epoch 198/1000 complete | Avg Loss: 4931.9357\n",
      "Epoch 199/1000 | Batch 0/237 | Loss: 30439.8828\n",
      "Epoch 199/1000 | Batch 100/237 | Loss: 3286.6943\n",
      "Epoch 199/1000 | Batch 200/237 | Loss: 8610.3672\n",
      "Epoch 199/1000 complete | Avg Loss: 4971.1914\n",
      "Epoch 200/1000 | Batch 0/237 | Loss: 28606.4688\n",
      "Epoch 200/1000 | Batch 100/237 | Loss: 2273.1750\n",
      "Epoch 200/1000 | Batch 200/237 | Loss: 26969.0371\n",
      "Epoch 200/1000 complete | Avg Loss: 4919.4059\n",
      "Epoch 201/1000 | Batch 0/237 | Loss: 3557.2039\n",
      "Epoch 201/1000 | Batch 100/237 | Loss: 29317.1953\n",
      "Epoch 201/1000 | Batch 200/237 | Loss: 4279.0166\n",
      "Epoch 201/1000 complete | Avg Loss: 4926.6690\n",
      "Epoch 202/1000 | Batch 0/237 | Loss: 1347.0239\n",
      "Epoch 202/1000 | Batch 100/237 | Loss: 2669.7654\n",
      "Epoch 202/1000 | Batch 200/237 | Loss: 1867.8259\n",
      "Epoch 202/1000 complete | Avg Loss: 4913.9863\n",
      "Epoch 203/1000 | Batch 0/237 | Loss: 1274.8733\n",
      "Epoch 203/1000 | Batch 100/237 | Loss: 3303.4170\n",
      "Epoch 203/1000 | Batch 200/237 | Loss: 2988.2529\n",
      "Epoch 203/1000 complete | Avg Loss: 4926.1556\n",
      "Epoch 204/1000 | Batch 0/237 | Loss: 9013.9043\n",
      "Epoch 204/1000 | Batch 100/237 | Loss: 963.3511\n",
      "Epoch 204/1000 | Batch 200/237 | Loss: 1168.3575\n",
      "Epoch 204/1000 complete | Avg Loss: 4918.3088\n",
      "Epoch 205/1000 | Batch 0/237 | Loss: 841.9262\n",
      "Epoch 205/1000 | Batch 100/237 | Loss: 899.9633\n",
      "Epoch 205/1000 | Batch 200/237 | Loss: 1743.4153\n",
      "Epoch 205/1000 complete | Avg Loss: 4913.7738\n",
      "Epoch 206/1000 | Batch 0/237 | Loss: 2292.7336\n",
      "Epoch 206/1000 | Batch 100/237 | Loss: 4999.1802\n",
      "Epoch 206/1000 | Batch 200/237 | Loss: 7484.2192\n",
      "Epoch 206/1000 complete | Avg Loss: 4926.5613\n",
      "Epoch 207/1000 | Batch 0/237 | Loss: 1078.2179\n",
      "Epoch 207/1000 | Batch 100/237 | Loss: 3402.2634\n",
      "Epoch 207/1000 | Batch 200/237 | Loss: 7924.6592\n",
      "Epoch 207/1000 complete | Avg Loss: 4910.3168\n",
      "Epoch 208/1000 | Batch 0/237 | Loss: 12405.7129\n",
      "Epoch 208/1000 | Batch 100/237 | Loss: 884.4885\n",
      "Epoch 208/1000 | Batch 200/237 | Loss: 5384.5698\n",
      "Epoch 208/1000 complete | Avg Loss: 4911.8728\n",
      "Epoch 209/1000 | Batch 0/237 | Loss: 600.2794\n",
      "Epoch 209/1000 | Batch 100/237 | Loss: 4233.3770\n",
      "Epoch 209/1000 | Batch 200/237 | Loss: 4580.9863\n",
      "Epoch 209/1000 complete | Avg Loss: 4908.2456\n",
      "Epoch 210/1000 | Batch 0/237 | Loss: 1090.2690\n",
      "Epoch 210/1000 | Batch 100/237 | Loss: 838.1906\n",
      "Epoch 210/1000 | Batch 200/237 | Loss: 2556.3076\n",
      "Epoch 210/1000 complete | Avg Loss: 4908.8876\n",
      "Epoch 211/1000 | Batch 0/237 | Loss: 2078.1985\n",
      "Epoch 211/1000 | Batch 100/237 | Loss: 18194.2266\n",
      "Epoch 211/1000 | Batch 200/237 | Loss: 3360.2036\n",
      "Epoch 211/1000 complete | Avg Loss: 4919.7747\n",
      "Epoch 212/1000 | Batch 0/237 | Loss: 5942.9883\n",
      "Epoch 212/1000 | Batch 100/237 | Loss: 1999.2628\n",
      "Epoch 212/1000 | Batch 200/237 | Loss: 3315.4431\n",
      "Epoch 212/1000 complete | Avg Loss: 4903.7176\n",
      "Epoch 213/1000 | Batch 0/237 | Loss: 2184.8933\n",
      "Epoch 213/1000 | Batch 100/237 | Loss: 5007.6636\n",
      "Epoch 213/1000 | Batch 200/237 | Loss: 620.6993\n",
      "Epoch 213/1000 complete | Avg Loss: 4897.4031\n",
      "Epoch 214/1000 | Batch 0/237 | Loss: 1083.6411\n",
      "Epoch 214/1000 | Batch 100/237 | Loss: 22712.2480\n",
      "Epoch 214/1000 | Batch 200/237 | Loss: 797.8820\n",
      "Epoch 214/1000 complete | Avg Loss: 4919.1598\n",
      "Epoch 215/1000 | Batch 0/237 | Loss: 1677.6650\n",
      "Epoch 215/1000 | Batch 100/237 | Loss: 760.9059\n",
      "Epoch 215/1000 | Batch 200/237 | Loss: 2590.9368\n",
      "Epoch 215/1000 complete | Avg Loss: 4902.2632\n",
      "Epoch 216/1000 | Batch 0/237 | Loss: 1796.4092\n",
      "Epoch 216/1000 | Batch 100/237 | Loss: 614.7777\n",
      "Epoch 216/1000 | Batch 200/237 | Loss: 2743.7932\n",
      "Epoch 216/1000 complete | Avg Loss: 4924.4311\n",
      "Epoch 217/1000 | Batch 0/237 | Loss: 1450.3752\n",
      "Epoch 217/1000 | Batch 100/237 | Loss: 538.7820\n",
      "Epoch 217/1000 | Batch 200/237 | Loss: 11320.0957\n",
      "Epoch 217/1000 complete | Avg Loss: 4900.4879\n",
      "Epoch 218/1000 | Batch 0/237 | Loss: 1784.2615\n",
      "Epoch 218/1000 | Batch 100/237 | Loss: 4172.0405\n",
      "Epoch 218/1000 | Batch 200/237 | Loss: 579.6750\n",
      "Epoch 218/1000 complete | Avg Loss: 4900.9454\n",
      "Epoch 219/1000 | Batch 0/237 | Loss: 1487.9578\n",
      "Epoch 219/1000 | Batch 100/237 | Loss: 776.6558\n",
      "Epoch 219/1000 | Batch 200/237 | Loss: 691.7050\n",
      "Epoch 219/1000 complete | Avg Loss: 5008.8221\n",
      "Epoch 220/1000 | Batch 0/237 | Loss: 615.8018\n",
      "Epoch 220/1000 | Batch 100/237 | Loss: 5941.4683\n",
      "Epoch 220/1000 | Batch 200/237 | Loss: 6309.7871\n",
      "Epoch 220/1000 complete | Avg Loss: 4904.5253\n",
      "Epoch 221/1000 | Batch 0/237 | Loss: 3460.9182\n",
      "Epoch 221/1000 | Batch 100/237 | Loss: 6362.4985\n",
      "Epoch 221/1000 | Batch 200/237 | Loss: 5345.3267\n",
      "Epoch 221/1000 complete | Avg Loss: 4893.2758\n",
      "Epoch 222/1000 | Batch 0/237 | Loss: 5578.6191\n",
      "Epoch 222/1000 | Batch 100/237 | Loss: 2363.6089\n",
      "Epoch 222/1000 | Batch 200/237 | Loss: 702.7720\n",
      "Epoch 222/1000 complete | Avg Loss: 4888.4313\n",
      "Epoch 223/1000 | Batch 0/237 | Loss: 31176.1230\n",
      "Epoch 223/1000 | Batch 100/237 | Loss: 26810.2598\n",
      "Epoch 223/1000 | Batch 200/237 | Loss: 1710.5162\n",
      "Epoch 223/1000 complete | Avg Loss: 4889.8010\n",
      "Epoch 224/1000 | Batch 0/237 | Loss: 2184.2812\n",
      "Epoch 224/1000 | Batch 100/237 | Loss: 1547.5199\n",
      "Epoch 224/1000 | Batch 200/237 | Loss: 3092.6006\n",
      "Epoch 224/1000 complete | Avg Loss: 4885.9478\n",
      "Epoch 225/1000 | Batch 0/237 | Loss: 588.0320\n",
      "Epoch 225/1000 | Batch 100/237 | Loss: 4187.8550\n",
      "Epoch 225/1000 | Batch 200/237 | Loss: 4750.5459\n",
      "Epoch 225/1000 complete | Avg Loss: 4886.6524\n",
      "Epoch 226/1000 | Batch 0/237 | Loss: 3724.2812\n",
      "Epoch 226/1000 | Batch 100/237 | Loss: 721.2686\n",
      "Epoch 226/1000 | Batch 200/237 | Loss: 1266.5022\n",
      "Epoch 226/1000 complete | Avg Loss: 4925.4576\n",
      "Epoch 227/1000 | Batch 0/237 | Loss: 1618.0488\n",
      "Epoch 227/1000 | Batch 100/237 | Loss: 5861.5820\n",
      "Epoch 227/1000 | Batch 200/237 | Loss: 12363.3408\n",
      "Epoch 227/1000 complete | Avg Loss: 4883.2817\n",
      "Epoch 228/1000 | Batch 0/237 | Loss: 2032.1387\n",
      "Epoch 228/1000 | Batch 100/237 | Loss: 902.0956\n",
      "Epoch 228/1000 | Batch 200/237 | Loss: 3564.0850\n",
      "Epoch 228/1000 complete | Avg Loss: 4875.0523\n",
      "Epoch 229/1000 | Batch 0/237 | Loss: 14710.1748\n",
      "Epoch 229/1000 | Batch 100/237 | Loss: 3909.7473\n",
      "Epoch 229/1000 | Batch 200/237 | Loss: 994.2935\n",
      "Epoch 229/1000 complete | Avg Loss: 4878.7167\n",
      "Epoch 230/1000 | Batch 0/237 | Loss: 19042.8477\n",
      "Epoch 230/1000 | Batch 100/237 | Loss: 2250.6716\n",
      "Epoch 230/1000 | Batch 200/237 | Loss: 1785.5410\n",
      "Epoch 230/1000 complete | Avg Loss: 4886.1761\n",
      "Epoch 231/1000 | Batch 0/237 | Loss: 2175.8618\n",
      "Epoch 231/1000 | Batch 100/237 | Loss: 2504.1646\n",
      "Epoch 231/1000 | Batch 200/237 | Loss: 619.8182\n",
      "Epoch 231/1000 complete | Avg Loss: 4878.6364\n",
      "Epoch 232/1000 | Batch 0/237 | Loss: 7615.2998\n",
      "Epoch 232/1000 | Batch 100/237 | Loss: 2632.6580\n",
      "Epoch 232/1000 | Batch 200/237 | Loss: 2255.5393\n",
      "Epoch 232/1000 complete | Avg Loss: 4872.8315\n",
      "Epoch 233/1000 | Batch 0/237 | Loss: 4098.5610\n",
      "Epoch 233/1000 | Batch 100/237 | Loss: 3826.7432\n",
      "Epoch 233/1000 | Batch 200/237 | Loss: 1301.6337\n",
      "Epoch 233/1000 complete | Avg Loss: 4880.1317\n",
      "Epoch 234/1000 | Batch 0/237 | Loss: 17537.1250\n",
      "Epoch 234/1000 | Batch 100/237 | Loss: 607.1487\n",
      "Epoch 234/1000 | Batch 200/237 | Loss: 5605.8252\n",
      "Epoch 234/1000 complete | Avg Loss: 4877.0185\n",
      "Epoch 235/1000 | Batch 0/237 | Loss: 1229.3961\n",
      "Epoch 235/1000 | Batch 100/237 | Loss: 1463.9725\n",
      "Epoch 235/1000 | Batch 200/237 | Loss: 916.4156\n",
      "Epoch 235/1000 complete | Avg Loss: 4873.2295\n",
      "Epoch 236/1000 | Batch 0/237 | Loss: 30830.1484\n",
      "Epoch 236/1000 | Batch 100/237 | Loss: 1090.1133\n",
      "Epoch 236/1000 | Batch 200/237 | Loss: 1705.4561\n",
      "Epoch 236/1000 complete | Avg Loss: 4879.2948\n",
      "Epoch 237/1000 | Batch 0/237 | Loss: 1519.6565\n",
      "Epoch 237/1000 | Batch 100/237 | Loss: 824.1558\n",
      "Epoch 237/1000 | Batch 200/237 | Loss: 6747.5054\n",
      "Epoch 237/1000 complete | Avg Loss: 4871.3007\n",
      "Epoch 238/1000 | Batch 0/237 | Loss: 2638.8745\n",
      "Epoch 238/1000 | Batch 100/237 | Loss: 1336.8718\n",
      "Epoch 238/1000 | Batch 200/237 | Loss: 1582.5239\n",
      "Epoch 238/1000 complete | Avg Loss: 4867.2813\n",
      "Epoch 239/1000 | Batch 0/237 | Loss: 1378.8168\n",
      "Epoch 239/1000 | Batch 100/237 | Loss: 1297.4065\n",
      "Epoch 239/1000 | Batch 200/237 | Loss: 8644.5645\n",
      "Epoch 239/1000 complete | Avg Loss: 4866.8432\n",
      "Epoch 240/1000 | Batch 0/237 | Loss: 1208.9004\n",
      "Epoch 240/1000 | Batch 100/237 | Loss: 3005.6396\n",
      "Epoch 240/1000 | Batch 200/237 | Loss: 1322.8993\n",
      "Epoch 240/1000 complete | Avg Loss: 4866.0543\n",
      "Epoch 241/1000 | Batch 0/237 | Loss: 6836.3438\n",
      "Epoch 241/1000 | Batch 100/237 | Loss: 945.4401\n",
      "Epoch 241/1000 | Batch 200/237 | Loss: 886.8127\n",
      "Epoch 241/1000 complete | Avg Loss: 4861.2863\n",
      "Epoch 242/1000 | Batch 0/237 | Loss: 2949.4846\n",
      "Epoch 242/1000 | Batch 100/237 | Loss: 15496.4238\n",
      "Epoch 242/1000 | Batch 200/237 | Loss: 2889.4878\n",
      "Epoch 242/1000 complete | Avg Loss: 4860.7847\n",
      "Epoch 243/1000 | Batch 0/237 | Loss: 3765.7085\n",
      "Epoch 243/1000 | Batch 100/237 | Loss: 1746.2107\n",
      "Epoch 243/1000 | Batch 200/237 | Loss: 1357.6263\n",
      "Epoch 243/1000 complete | Avg Loss: 4875.3231\n",
      "Epoch 244/1000 | Batch 0/237 | Loss: 3202.4009\n",
      "Epoch 244/1000 | Batch 100/237 | Loss: 1891.5303\n",
      "Epoch 244/1000 | Batch 200/237 | Loss: 618.0588\n",
      "Epoch 244/1000 complete | Avg Loss: 4860.5753\n",
      "Epoch 245/1000 | Batch 0/237 | Loss: 2149.9290\n",
      "Epoch 245/1000 | Batch 100/237 | Loss: 7635.3652\n",
      "Epoch 245/1000 | Batch 200/237 | Loss: 28810.0234\n",
      "Epoch 245/1000 complete | Avg Loss: 4859.7440\n",
      "Epoch 246/1000 | Batch 0/237 | Loss: 6119.1665\n",
      "Epoch 246/1000 | Batch 100/237 | Loss: 1415.5110\n",
      "Epoch 246/1000 | Batch 200/237 | Loss: 781.5145\n",
      "Epoch 246/1000 complete | Avg Loss: 5073.4803\n",
      "Epoch 247/1000 | Batch 0/237 | Loss: 2771.4653\n",
      "Epoch 247/1000 | Batch 100/237 | Loss: 5285.1938\n",
      "Epoch 247/1000 | Batch 200/237 | Loss: 2889.5620\n",
      "Epoch 247/1000 complete | Avg Loss: 4866.5340\n",
      "Epoch 248/1000 | Batch 0/237 | Loss: 1139.4817\n",
      "Epoch 248/1000 | Batch 100/237 | Loss: 1583.8752\n",
      "Epoch 248/1000 | Batch 200/237 | Loss: 31957.7871\n",
      "Epoch 248/1000 complete | Avg Loss: 4853.6067\n",
      "Epoch 249/1000 | Batch 0/237 | Loss: 2625.4414\n",
      "Epoch 249/1000 | Batch 100/237 | Loss: 793.4049\n",
      "Epoch 249/1000 | Batch 200/237 | Loss: 1423.7217\n",
      "Epoch 249/1000 complete | Avg Loss: 4875.8455\n",
      "Epoch 250/1000 | Batch 0/237 | Loss: 904.3991\n",
      "Epoch 250/1000 | Batch 100/237 | Loss: 3781.1453\n",
      "Epoch 250/1000 | Batch 200/237 | Loss: 742.5959\n",
      "Epoch 250/1000 complete | Avg Loss: 4850.4047\n",
      "Epoch 251/1000 | Batch 0/237 | Loss: 2070.8359\n",
      "Epoch 251/1000 | Batch 100/237 | Loss: 1566.6290\n",
      "Epoch 251/1000 | Batch 200/237 | Loss: 1260.8015\n",
      "Epoch 251/1000 complete | Avg Loss: 4852.7281\n",
      "Epoch 252/1000 | Batch 0/237 | Loss: 946.6066\n",
      "Epoch 252/1000 | Batch 100/237 | Loss: 1307.2816\n",
      "Epoch 252/1000 | Batch 200/237 | Loss: 3121.6030\n",
      "Epoch 252/1000 complete | Avg Loss: 4859.0037\n",
      "Epoch 253/1000 | Batch 0/237 | Loss: 2710.6992\n",
      "Epoch 253/1000 | Batch 100/237 | Loss: 532.3973\n",
      "Epoch 253/1000 | Batch 200/237 | Loss: 1473.1477\n",
      "Epoch 253/1000 complete | Avg Loss: 4853.5506\n",
      "Epoch 254/1000 | Batch 0/237 | Loss: 6896.1318\n",
      "Epoch 254/1000 | Batch 100/237 | Loss: 16081.8789\n",
      "Epoch 254/1000 | Batch 200/237 | Loss: 2272.2927\n",
      "Epoch 254/1000 complete | Avg Loss: 4854.3543\n",
      "Epoch 255/1000 | Batch 0/237 | Loss: 971.2943\n",
      "Epoch 255/1000 | Batch 100/237 | Loss: 12433.9062\n",
      "Epoch 255/1000 | Batch 200/237 | Loss: 4393.1377\n",
      "Epoch 255/1000 complete | Avg Loss: 4850.6376\n",
      "Epoch 256/1000 | Batch 0/237 | Loss: 682.8030\n",
      "Epoch 256/1000 | Batch 100/237 | Loss: 5961.5000\n",
      "Epoch 256/1000 | Batch 200/237 | Loss: 2504.3130\n",
      "Epoch 256/1000 complete | Avg Loss: 4852.8348\n",
      "Epoch 257/1000 | Batch 0/237 | Loss: 1211.1958\n",
      "Epoch 257/1000 | Batch 100/237 | Loss: 15374.4590\n",
      "Epoch 257/1000 | Batch 200/237 | Loss: 2085.3960\n",
      "Epoch 257/1000 complete | Avg Loss: 4851.4459\n",
      "Epoch 258/1000 | Batch 0/237 | Loss: 2693.1301\n",
      "Epoch 258/1000 | Batch 100/237 | Loss: 892.5234\n",
      "Epoch 258/1000 | Batch 200/237 | Loss: 1414.2153\n",
      "Epoch 258/1000 complete | Avg Loss: 4852.8387\n",
      "Epoch 259/1000 | Batch 0/237 | Loss: 3212.5320\n",
      "Epoch 259/1000 | Batch 100/237 | Loss: 1203.2299\n",
      "Epoch 259/1000 | Batch 200/237 | Loss: 2632.5347\n",
      "Epoch 259/1000 complete | Avg Loss: 4851.5305\n",
      "Epoch 260/1000 | Batch 0/237 | Loss: 5069.9917\n",
      "Epoch 260/1000 | Batch 100/237 | Loss: 2558.6548\n",
      "Epoch 260/1000 | Batch 200/237 | Loss: 786.0261\n",
      "Epoch 260/1000 complete | Avg Loss: 4840.6706\n",
      "Epoch 261/1000 | Batch 0/237 | Loss: 23496.2812\n",
      "Epoch 261/1000 | Batch 100/237 | Loss: 3315.6365\n",
      "Epoch 261/1000 | Batch 200/237 | Loss: 2571.1553\n",
      "Epoch 261/1000 complete | Avg Loss: 4839.9373\n",
      "Epoch 262/1000 | Batch 0/237 | Loss: 865.9100\n",
      "Epoch 262/1000 | Batch 100/237 | Loss: 4993.5488\n",
      "Epoch 262/1000 | Batch 200/237 | Loss: 13625.1904\n",
      "Epoch 262/1000 complete | Avg Loss: 4841.7293\n",
      "Epoch 263/1000 | Batch 0/237 | Loss: 4265.5352\n",
      "Epoch 263/1000 | Batch 100/237 | Loss: 3525.1963\n",
      "Epoch 263/1000 | Batch 200/237 | Loss: 5300.1641\n",
      "Epoch 263/1000 complete | Avg Loss: 4841.1368\n",
      "Epoch 264/1000 | Batch 0/237 | Loss: 1245.5978\n",
      "Epoch 264/1000 | Batch 100/237 | Loss: 19291.2695\n",
      "Epoch 264/1000 | Batch 200/237 | Loss: 1067.4946\n",
      "Epoch 264/1000 complete | Avg Loss: 4838.7048\n",
      "Epoch 265/1000 | Batch 0/237 | Loss: 3904.2854\n",
      "Epoch 265/1000 | Batch 100/237 | Loss: 1992.6964\n",
      "Epoch 265/1000 | Batch 200/237 | Loss: 517.0927\n",
      "Epoch 265/1000 complete | Avg Loss: 4842.3617\n",
      "Epoch 266/1000 | Batch 0/237 | Loss: 4465.5981\n",
      "Epoch 266/1000 | Batch 100/237 | Loss: 6624.4375\n",
      "Epoch 266/1000 | Batch 200/237 | Loss: 7192.6460\n",
      "Epoch 266/1000 complete | Avg Loss: 4847.5879\n",
      "Epoch 267/1000 | Batch 0/237 | Loss: 1688.7589\n",
      "Epoch 267/1000 | Batch 100/237 | Loss: 1932.4667\n",
      "Epoch 267/1000 | Batch 200/237 | Loss: 48382.1992\n",
      "Epoch 267/1000 complete | Avg Loss: 4841.4820\n",
      "Epoch 268/1000 | Batch 0/237 | Loss: 5070.6099\n",
      "Epoch 268/1000 | Batch 100/237 | Loss: 1718.6465\n",
      "Epoch 268/1000 | Batch 200/237 | Loss: 1011.0439\n",
      "Epoch 268/1000 complete | Avg Loss: 4835.8868\n",
      "Epoch 269/1000 | Batch 0/237 | Loss: 9146.8984\n",
      "Epoch 269/1000 | Batch 100/237 | Loss: 4598.0596\n",
      "Epoch 269/1000 | Batch 200/237 | Loss: 2894.4214\n",
      "Epoch 269/1000 complete | Avg Loss: 4829.1847\n",
      "Epoch 270/1000 | Batch 0/237 | Loss: 2161.7905\n",
      "Epoch 270/1000 | Batch 100/237 | Loss: 29534.5820\n",
      "Epoch 270/1000 | Batch 200/237 | Loss: 903.6161\n",
      "Epoch 270/1000 complete | Avg Loss: 4839.9149\n",
      "Epoch 271/1000 | Batch 0/237 | Loss: 1086.0499\n",
      "Epoch 271/1000 | Batch 100/237 | Loss: 3925.2375\n",
      "Epoch 271/1000 | Batch 200/237 | Loss: 1342.7842\n",
      "Epoch 271/1000 complete | Avg Loss: 4834.3753\n",
      "Epoch 272/1000 | Batch 0/237 | Loss: 2516.6260\n",
      "Epoch 272/1000 | Batch 100/237 | Loss: 5271.4487\n",
      "Epoch 272/1000 | Batch 200/237 | Loss: 3137.3091\n",
      "Epoch 272/1000 complete | Avg Loss: 4838.6663\n",
      "Epoch 273/1000 | Batch 0/237 | Loss: 37526.8281\n",
      "Epoch 273/1000 | Batch 100/237 | Loss: 568.7120\n",
      "Epoch 273/1000 | Batch 200/237 | Loss: 5135.0244\n",
      "Epoch 273/1000 complete | Avg Loss: 4826.7455\n",
      "Epoch 274/1000 | Batch 0/237 | Loss: 1573.1702\n",
      "Epoch 274/1000 | Batch 100/237 | Loss: 1530.0212\n",
      "Epoch 274/1000 | Batch 200/237 | Loss: 1004.3572\n",
      "Epoch 274/1000 complete | Avg Loss: 4831.8631\n",
      "Epoch 275/1000 | Batch 0/237 | Loss: 1942.3208\n",
      "Epoch 275/1000 | Batch 100/237 | Loss: 2906.1062\n",
      "Epoch 275/1000 | Batch 200/237 | Loss: 2135.8879\n",
      "Epoch 275/1000 complete | Avg Loss: 4827.7407\n",
      "Epoch 276/1000 | Batch 0/237 | Loss: 1125.5265\n",
      "Epoch 276/1000 | Batch 100/237 | Loss: 3249.6504\n",
      "Epoch 276/1000 | Batch 200/237 | Loss: 2187.2249\n",
      "Epoch 276/1000 complete | Avg Loss: 4831.2002\n",
      "Epoch 277/1000 | Batch 0/237 | Loss: 3698.1409\n",
      "Epoch 277/1000 | Batch 100/237 | Loss: 3843.1211\n",
      "Epoch 277/1000 | Batch 200/237 | Loss: 4332.1006\n",
      "Epoch 277/1000 complete | Avg Loss: 4866.6399\n",
      "Epoch 278/1000 | Batch 0/237 | Loss: 1956.8842\n",
      "Epoch 278/1000 | Batch 100/237 | Loss: 1073.7020\n",
      "Epoch 278/1000 | Batch 200/237 | Loss: 605.6568\n",
      "Epoch 278/1000 complete | Avg Loss: 4838.2100\n",
      "Epoch 279/1000 | Batch 0/237 | Loss: 3197.1284\n",
      "Epoch 279/1000 | Batch 100/237 | Loss: 8136.6714\n",
      "Epoch 279/1000 | Batch 200/237 | Loss: 2071.0710\n",
      "Epoch 279/1000 complete | Avg Loss: 4824.1363\n",
      "Epoch 280/1000 | Batch 0/237 | Loss: 1026.9170\n",
      "Epoch 280/1000 | Batch 100/237 | Loss: 1399.2704\n",
      "Epoch 280/1000 | Batch 200/237 | Loss: 4381.8120\n",
      "Epoch 280/1000 complete | Avg Loss: 4826.5666\n",
      "Epoch 281/1000 | Batch 0/237 | Loss: 1011.0345\n",
      "Epoch 281/1000 | Batch 100/237 | Loss: 2041.3085\n",
      "Epoch 281/1000 | Batch 200/237 | Loss: 1481.8478\n",
      "Epoch 281/1000 complete | Avg Loss: 4824.5762\n",
      "Epoch 282/1000 | Batch 0/237 | Loss: 1651.1873\n",
      "Epoch 282/1000 | Batch 100/237 | Loss: 684.4153\n",
      "Epoch 282/1000 | Batch 200/237 | Loss: 2430.3369\n",
      "Epoch 282/1000 complete | Avg Loss: 4837.6540\n",
      "Epoch 283/1000 | Batch 0/237 | Loss: 24129.3770\n",
      "Epoch 283/1000 | Batch 100/237 | Loss: 3200.7427\n",
      "Epoch 283/1000 | Batch 200/237 | Loss: 1497.3304\n",
      "Epoch 283/1000 complete | Avg Loss: 4817.9791\n",
      "Epoch 284/1000 | Batch 0/237 | Loss: 2067.8000\n",
      "Epoch 284/1000 | Batch 100/237 | Loss: 29873.8047\n",
      "Epoch 284/1000 | Batch 200/237 | Loss: 2028.5087\n",
      "Epoch 284/1000 complete | Avg Loss: 4820.3913\n",
      "Epoch 285/1000 | Batch 0/237 | Loss: 4642.2793\n",
      "Epoch 285/1000 | Batch 100/237 | Loss: 1102.2891\n",
      "Epoch 285/1000 | Batch 200/237 | Loss: 29937.6797\n",
      "Epoch 285/1000 complete | Avg Loss: 4816.6678\n",
      "Epoch 286/1000 | Batch 0/237 | Loss: 717.7315\n",
      "Epoch 286/1000 | Batch 100/237 | Loss: 678.3466\n",
      "Epoch 286/1000 | Batch 200/237 | Loss: 1085.9210\n",
      "Epoch 286/1000 complete | Avg Loss: 4827.1563\n",
      "Epoch 287/1000 | Batch 0/237 | Loss: 1105.6631\n",
      "Epoch 287/1000 | Batch 100/237 | Loss: 1098.7792\n",
      "Epoch 287/1000 | Batch 200/237 | Loss: 2286.7744\n",
      "Epoch 287/1000 complete | Avg Loss: 4822.4677\n",
      "Epoch 288/1000 | Batch 0/237 | Loss: 1177.8538\n",
      "Epoch 288/1000 | Batch 100/237 | Loss: 1427.5568\n",
      "Epoch 288/1000 | Batch 200/237 | Loss: 1253.9958\n",
      "Epoch 288/1000 complete | Avg Loss: 4833.0585\n",
      "Epoch 289/1000 | Batch 0/237 | Loss: 34468.0234\n",
      "Epoch 289/1000 | Batch 100/237 | Loss: 6359.0308\n",
      "Epoch 289/1000 | Batch 200/237 | Loss: 8919.4365\n",
      "Epoch 289/1000 complete | Avg Loss: 4810.6579\n",
      "Epoch 290/1000 | Batch 0/237 | Loss: 932.6020\n",
      "Epoch 290/1000 | Batch 100/237 | Loss: 1309.4510\n",
      "Epoch 290/1000 | Batch 200/237 | Loss: 548.8668\n",
      "Epoch 290/1000 complete | Avg Loss: 4813.2787\n",
      "Epoch 291/1000 | Batch 0/237 | Loss: 2843.5640\n",
      "Epoch 291/1000 | Batch 100/237 | Loss: 2222.2788\n",
      "Epoch 291/1000 | Batch 200/237 | Loss: 2194.1074\n",
      "Epoch 291/1000 complete | Avg Loss: 4898.3037\n",
      "Epoch 292/1000 | Batch 0/237 | Loss: 3146.5728\n",
      "Epoch 292/1000 | Batch 100/237 | Loss: 9255.3242\n",
      "Epoch 292/1000 | Batch 200/237 | Loss: 3820.8892\n",
      "Epoch 292/1000 complete | Avg Loss: 4810.1218\n",
      "Epoch 293/1000 | Batch 0/237 | Loss: 2699.2742\n",
      "Epoch 293/1000 | Batch 100/237 | Loss: 6461.7842\n",
      "Epoch 293/1000 | Batch 200/237 | Loss: 26571.9473\n",
      "Epoch 293/1000 complete | Avg Loss: 4812.3211\n",
      "Epoch 294/1000 | Batch 0/237 | Loss: 2996.4688\n",
      "Epoch 294/1000 | Batch 100/237 | Loss: 825.7050\n",
      "Epoch 294/1000 | Batch 200/237 | Loss: 2144.4629\n",
      "Epoch 294/1000 complete | Avg Loss: 4807.6654\n",
      "Epoch 295/1000 | Batch 0/237 | Loss: 1762.6036\n",
      "Epoch 295/1000 | Batch 100/237 | Loss: 4217.0044\n",
      "Epoch 295/1000 | Batch 200/237 | Loss: 1041.1210\n",
      "Epoch 295/1000 complete | Avg Loss: 4815.3857\n",
      "Epoch 296/1000 | Batch 0/237 | Loss: 2480.8403\n",
      "Epoch 296/1000 | Batch 100/237 | Loss: 878.4321\n",
      "Epoch 296/1000 | Batch 200/237 | Loss: 1515.7683\n",
      "Epoch 296/1000 complete | Avg Loss: 4804.4676\n",
      "Epoch 297/1000 | Batch 0/237 | Loss: 5595.0103\n",
      "Epoch 297/1000 | Batch 100/237 | Loss: 1883.8059\n",
      "Epoch 297/1000 | Batch 200/237 | Loss: 2506.5840\n",
      "Epoch 297/1000 complete | Avg Loss: 4999.4564\n",
      "Epoch 298/1000 | Batch 0/237 | Loss: 1512.5294\n",
      "Epoch 298/1000 | Batch 100/237 | Loss: 884.7014\n",
      "Epoch 298/1000 | Batch 200/237 | Loss: 4778.7119\n",
      "Epoch 298/1000 complete | Avg Loss: 4845.5611\n",
      "Epoch 299/1000 | Batch 0/237 | Loss: 4541.8857\n",
      "Epoch 299/1000 | Batch 100/237 | Loss: 786.8913\n",
      "Epoch 299/1000 | Batch 200/237 | Loss: 4138.8135\n",
      "Epoch 299/1000 complete | Avg Loss: 4820.7636\n",
      "Epoch 300/1000 | Batch 0/237 | Loss: 3048.2244\n",
      "Epoch 300/1000 | Batch 100/237 | Loss: 668.1009\n",
      "Epoch 300/1000 | Batch 200/237 | Loss: 1762.4702\n",
      "Epoch 300/1000 complete | Avg Loss: 4817.7881\n",
      "Epoch 301/1000 | Batch 0/237 | Loss: 21159.9023\n",
      "Epoch 301/1000 | Batch 100/237 | Loss: 3907.8774\n",
      "Epoch 301/1000 | Batch 200/237 | Loss: 1046.0210\n",
      "Epoch 301/1000 complete | Avg Loss: 4813.9161\n",
      "Epoch 302/1000 | Batch 0/237 | Loss: 3790.5657\n",
      "Epoch 302/1000 | Batch 100/237 | Loss: 1765.3806\n",
      "Epoch 302/1000 | Batch 200/237 | Loss: 1405.7800\n",
      "Epoch 302/1000 complete | Avg Loss: 4799.0548\n",
      "Epoch 303/1000 | Batch 0/237 | Loss: 3589.5544\n",
      "Epoch 303/1000 | Batch 100/237 | Loss: 862.9790\n",
      "Epoch 303/1000 | Batch 200/237 | Loss: 18943.9277\n",
      "Epoch 303/1000 complete | Avg Loss: 4797.0132\n",
      "Epoch 304/1000 | Batch 0/237 | Loss: 1926.0706\n",
      "Epoch 304/1000 | Batch 100/237 | Loss: 1008.8140\n",
      "Epoch 304/1000 | Batch 200/237 | Loss: 2432.1929\n",
      "Epoch 304/1000 complete | Avg Loss: 4795.7145\n",
      "Epoch 305/1000 | Batch 0/237 | Loss: 2832.7317\n",
      "Epoch 305/1000 | Batch 100/237 | Loss: 1033.3457\n",
      "Epoch 305/1000 | Batch 200/237 | Loss: 1024.0455\n",
      "Epoch 305/1000 complete | Avg Loss: 4801.9983\n",
      "Epoch 306/1000 | Batch 0/237 | Loss: 17443.3711\n",
      "Epoch 306/1000 | Batch 100/237 | Loss: 8073.8101\n",
      "Epoch 306/1000 | Batch 200/237 | Loss: 2783.5386\n",
      "Epoch 306/1000 complete | Avg Loss: 4798.4789\n",
      "Epoch 307/1000 | Batch 0/237 | Loss: 2499.2051\n",
      "Epoch 307/1000 | Batch 100/237 | Loss: 5982.3086\n",
      "Epoch 307/1000 | Batch 200/237 | Loss: 681.2790\n",
      "Epoch 307/1000 complete | Avg Loss: 4798.4287\n",
      "Epoch 308/1000 | Batch 0/237 | Loss: 8799.7979\n",
      "Epoch 308/1000 | Batch 100/237 | Loss: 1147.1854\n",
      "Epoch 308/1000 | Batch 200/237 | Loss: 1257.9949\n",
      "Epoch 308/1000 complete | Avg Loss: 4794.0202\n",
      "Epoch 309/1000 | Batch 0/237 | Loss: 820.2897\n",
      "Epoch 309/1000 | Batch 100/237 | Loss: 1024.4860\n",
      "Epoch 309/1000 | Batch 200/237 | Loss: 1516.4010\n",
      "Epoch 309/1000 complete | Avg Loss: 4795.6082\n",
      "Epoch 310/1000 | Batch 0/237 | Loss: 1202.5870\n",
      "Epoch 310/1000 | Batch 100/237 | Loss: 2788.6240\n",
      "Epoch 310/1000 | Batch 200/237 | Loss: 6267.4043\n",
      "Epoch 310/1000 complete | Avg Loss: 4792.9593\n",
      "Epoch 311/1000 | Batch 0/237 | Loss: 724.2625\n",
      "Epoch 311/1000 | Batch 100/237 | Loss: 4322.4800\n",
      "Epoch 311/1000 | Batch 200/237 | Loss: 15705.4795\n",
      "Epoch 311/1000 complete | Avg Loss: 4792.9141\n",
      "Epoch 312/1000 | Batch 0/237 | Loss: 1348.5894\n",
      "Epoch 312/1000 | Batch 100/237 | Loss: 3225.6533\n",
      "Epoch 312/1000 | Batch 200/237 | Loss: 6182.0708\n",
      "Epoch 312/1000 complete | Avg Loss: 4787.0686\n",
      "Epoch 313/1000 | Batch 0/237 | Loss: 5541.5737\n",
      "Epoch 313/1000 | Batch 100/237 | Loss: 762.7582\n",
      "Epoch 313/1000 | Batch 200/237 | Loss: 1593.4496\n",
      "Epoch 313/1000 complete | Avg Loss: 4792.0664\n",
      "Epoch 314/1000 | Batch 0/237 | Loss: 2404.5349\n",
      "Epoch 314/1000 | Batch 100/237 | Loss: 2332.6143\n",
      "Epoch 314/1000 | Batch 200/237 | Loss: 2066.6948\n",
      "Epoch 314/1000 complete | Avg Loss: 4793.5929\n",
      "Epoch 315/1000 | Batch 0/237 | Loss: 2511.6284\n",
      "Epoch 315/1000 | Batch 100/237 | Loss: 1033.6112\n",
      "Epoch 315/1000 | Batch 200/237 | Loss: 1534.4952\n",
      "Epoch 315/1000 complete | Avg Loss: 4784.2344\n",
      "Epoch 316/1000 | Batch 0/237 | Loss: 895.6544\n",
      "Epoch 316/1000 | Batch 100/237 | Loss: 1206.1044\n",
      "Epoch 316/1000 | Batch 200/237 | Loss: 929.9662\n",
      "Epoch 316/1000 complete | Avg Loss: 4789.6289\n",
      "Epoch 317/1000 | Batch 0/237 | Loss: 16482.7812\n",
      "Epoch 317/1000 | Batch 100/237 | Loss: 2035.6719\n",
      "Epoch 317/1000 | Batch 200/237 | Loss: 14056.0459\n",
      "Epoch 317/1000 complete | Avg Loss: 4786.7224\n",
      "Epoch 318/1000 | Batch 0/237 | Loss: 885.3693\n",
      "Epoch 318/1000 | Batch 100/237 | Loss: 7741.1436\n",
      "Epoch 318/1000 | Batch 200/237 | Loss: 310.7513\n",
      "Epoch 318/1000 complete | Avg Loss: 4792.1546\n",
      "Epoch 319/1000 | Batch 0/237 | Loss: 28607.1895\n",
      "Epoch 319/1000 | Batch 100/237 | Loss: 2984.7830\n",
      "Epoch 319/1000 | Batch 200/237 | Loss: 614.6173\n",
      "Epoch 319/1000 complete | Avg Loss: 4790.7321\n",
      "Epoch 320/1000 | Batch 0/237 | Loss: 1258.7306\n",
      "Epoch 320/1000 | Batch 100/237 | Loss: 1600.7965\n",
      "Epoch 320/1000 | Batch 200/237 | Loss: 2232.1545\n",
      "Epoch 320/1000 complete | Avg Loss: 4941.0430\n",
      "Epoch 321/1000 | Batch 0/237 | Loss: 1390.0288\n",
      "Epoch 321/1000 | Batch 100/237 | Loss: 3521.8386\n",
      "Epoch 321/1000 | Batch 200/237 | Loss: 878.8149\n",
      "Epoch 321/1000 complete | Avg Loss: 4806.0624\n",
      "Epoch 322/1000 | Batch 0/237 | Loss: 1579.9126\n",
      "Epoch 322/1000 | Batch 100/237 | Loss: 41230.7891\n",
      "Epoch 322/1000 | Batch 200/237 | Loss: 4559.5752\n",
      "Epoch 322/1000 complete | Avg Loss: 4812.1189\n",
      "Epoch 323/1000 | Batch 0/237 | Loss: 1441.2550\n",
      "Epoch 323/1000 | Batch 100/237 | Loss: 791.7057\n",
      "Epoch 323/1000 | Batch 200/237 | Loss: 3749.5183\n",
      "Epoch 323/1000 complete | Avg Loss: 4788.1103\n",
      "Epoch 324/1000 | Batch 0/237 | Loss: 6347.9316\n",
      "Epoch 324/1000 | Batch 100/237 | Loss: 1255.2688\n",
      "Epoch 324/1000 | Batch 200/237 | Loss: 27060.3633\n",
      "Epoch 324/1000 complete | Avg Loss: 4782.4025\n",
      "Epoch 325/1000 | Batch 0/237 | Loss: 4995.5342\n",
      "Epoch 325/1000 | Batch 100/237 | Loss: 1164.4802\n",
      "Epoch 325/1000 | Batch 200/237 | Loss: 3686.8110\n",
      "Epoch 325/1000 complete | Avg Loss: 4779.5142\n",
      "Epoch 326/1000 | Batch 0/237 | Loss: 2569.3669\n",
      "Epoch 326/1000 | Batch 100/237 | Loss: 26837.0020\n",
      "Epoch 326/1000 | Batch 200/237 | Loss: 1621.5702\n",
      "Epoch 326/1000 complete | Avg Loss: 4788.2590\n",
      "Epoch 327/1000 | Batch 0/237 | Loss: 2996.3445\n",
      "Epoch 327/1000 | Batch 100/237 | Loss: 6978.7539\n",
      "Epoch 327/1000 | Batch 200/237 | Loss: 2556.8889\n",
      "Epoch 327/1000 complete | Avg Loss: 4773.3058\n",
      "Epoch 328/1000 | Batch 0/237 | Loss: 1756.1106\n",
      "Epoch 328/1000 | Batch 100/237 | Loss: 496.6757\n",
      "Epoch 328/1000 | Batch 200/237 | Loss: 4584.5981\n",
      "Epoch 328/1000 complete | Avg Loss: 4774.7170\n",
      "Epoch 329/1000 | Batch 0/237 | Loss: 7582.2314\n",
      "Epoch 329/1000 | Batch 100/237 | Loss: 3513.4453\n",
      "Epoch 329/1000 | Batch 200/237 | Loss: 6340.7031\n",
      "Epoch 329/1000 complete | Avg Loss: 4772.9286\n",
      "Epoch 330/1000 | Batch 0/237 | Loss: 582.6660\n",
      "Epoch 330/1000 | Batch 100/237 | Loss: 975.2596\n",
      "Epoch 330/1000 | Batch 200/237 | Loss: 1659.0850\n",
      "Epoch 330/1000 complete | Avg Loss: 4773.8769\n",
      "Epoch 331/1000 | Batch 0/237 | Loss: 1314.8831\n",
      "Epoch 331/1000 | Batch 100/237 | Loss: 38361.6016\n",
      "Epoch 331/1000 | Batch 200/237 | Loss: 1488.3719\n",
      "Epoch 331/1000 complete | Avg Loss: 4784.0202\n",
      "Epoch 332/1000 | Batch 0/237 | Loss: 1426.6343\n",
      "Epoch 332/1000 | Batch 100/237 | Loss: 2638.4595\n",
      "Epoch 332/1000 | Batch 200/237 | Loss: 673.4236\n",
      "Epoch 332/1000 complete | Avg Loss: 4776.6654\n",
      "Epoch 333/1000 | Batch 0/237 | Loss: 3569.6824\n",
      "Epoch 333/1000 | Batch 100/237 | Loss: 4648.7529\n",
      "Epoch 333/1000 | Batch 200/237 | Loss: 12107.9053\n",
      "Epoch 333/1000 complete | Avg Loss: 4770.5927\n",
      "Epoch 334/1000 | Batch 0/237 | Loss: 4048.6699\n",
      "Epoch 334/1000 | Batch 100/237 | Loss: 16931.1836\n",
      "Epoch 334/1000 | Batch 200/237 | Loss: 1499.6846\n",
      "Epoch 334/1000 complete | Avg Loss: 4767.0228\n",
      "Epoch 335/1000 | Batch 0/237 | Loss: 2972.7449\n",
      "Epoch 335/1000 | Batch 100/237 | Loss: 8077.3530\n",
      "Epoch 335/1000 | Batch 200/237 | Loss: 7450.6729\n",
      "Epoch 335/1000 complete | Avg Loss: 4782.4830\n",
      "Epoch 336/1000 | Batch 0/237 | Loss: 1848.1614\n",
      "Epoch 336/1000 | Batch 100/237 | Loss: 2604.6809\n",
      "Epoch 336/1000 | Batch 200/237 | Loss: 636.4568\n",
      "Epoch 336/1000 complete | Avg Loss: 4766.8641\n",
      "Epoch 337/1000 | Batch 0/237 | Loss: 4746.5146\n",
      "Epoch 337/1000 | Batch 100/237 | Loss: 8113.8105\n",
      "Epoch 337/1000 | Batch 200/237 | Loss: 815.8161\n",
      "Epoch 337/1000 complete | Avg Loss: 4768.8816\n",
      "Epoch 338/1000 | Batch 0/237 | Loss: 2365.7405\n",
      "Epoch 338/1000 | Batch 100/237 | Loss: 11938.9229\n",
      "Epoch 338/1000 | Batch 200/237 | Loss: 16913.7266\n",
      "Epoch 338/1000 complete | Avg Loss: 4762.4831\n",
      "Epoch 339/1000 | Batch 0/237 | Loss: 3305.5359\n",
      "Epoch 339/1000 | Batch 100/237 | Loss: 1649.2061\n",
      "Epoch 339/1000 | Batch 200/237 | Loss: 2911.1731\n",
      "Epoch 339/1000 complete | Avg Loss: 4772.8267\n",
      "Epoch 340/1000 | Batch 0/237 | Loss: 2042.6935\n",
      "Epoch 340/1000 | Batch 100/237 | Loss: 8839.5527\n",
      "Epoch 340/1000 | Batch 200/237 | Loss: 2458.5996\n",
      "Epoch 340/1000 complete | Avg Loss: 4757.6524\n",
      "Epoch 341/1000 | Batch 0/237 | Loss: 1074.9283\n",
      "Epoch 341/1000 | Batch 100/237 | Loss: 616.3114\n",
      "Epoch 341/1000 | Batch 200/237 | Loss: 921.7979\n",
      "Epoch 341/1000 complete | Avg Loss: 4785.6809\n",
      "Epoch 342/1000 | Batch 0/237 | Loss: 4387.8750\n",
      "Epoch 342/1000 | Batch 100/237 | Loss: 674.9131\n",
      "Epoch 342/1000 | Batch 200/237 | Loss: 2223.7251\n",
      "Epoch 342/1000 complete | Avg Loss: 4766.1266\n",
      "Epoch 343/1000 | Batch 0/237 | Loss: 23157.7832\n",
      "Epoch 343/1000 | Batch 100/237 | Loss: 5121.3091\n",
      "Epoch 343/1000 | Batch 200/237 | Loss: 4525.4233\n",
      "Epoch 343/1000 complete | Avg Loss: 4759.8293\n",
      "Epoch 344/1000 | Batch 0/237 | Loss: 1586.0571\n",
      "Epoch 344/1000 | Batch 100/237 | Loss: 1882.0315\n",
      "Epoch 344/1000 | Batch 200/237 | Loss: 2209.4663\n",
      "Epoch 344/1000 complete | Avg Loss: 4761.4436\n",
      "Epoch 345/1000 | Batch 0/237 | Loss: 2047.6771\n",
      "Epoch 345/1000 | Batch 100/237 | Loss: 2503.1777\n",
      "Epoch 345/1000 | Batch 200/237 | Loss: 1101.3131\n",
      "Epoch 345/1000 complete | Avg Loss: 4762.3190\n",
      "Epoch 346/1000 | Batch 0/237 | Loss: 3525.5806\n",
      "Epoch 346/1000 | Batch 100/237 | Loss: 13209.4072\n",
      "Epoch 346/1000 | Batch 200/237 | Loss: 1631.9592\n",
      "Epoch 346/1000 complete | Avg Loss: 4757.1026\n",
      "Epoch 347/1000 | Batch 0/237 | Loss: 2129.5483\n",
      "Epoch 347/1000 | Batch 100/237 | Loss: 1037.7705\n",
      "Epoch 347/1000 | Batch 200/237 | Loss: 1203.7891\n",
      "Epoch 347/1000 complete | Avg Loss: 4752.4626\n",
      "Epoch 348/1000 | Batch 0/237 | Loss: 993.1407\n",
      "Epoch 348/1000 | Batch 100/237 | Loss: 27042.1133\n",
      "Epoch 348/1000 | Batch 200/237 | Loss: 14020.7969\n",
      "Epoch 348/1000 complete | Avg Loss: 4755.6546\n",
      "Epoch 349/1000 | Batch 0/237 | Loss: 2576.4839\n",
      "Epoch 349/1000 | Batch 100/237 | Loss: 1258.2959\n",
      "Epoch 349/1000 | Batch 200/237 | Loss: 27258.0684\n",
      "Epoch 349/1000 complete | Avg Loss: 4757.6146\n",
      "Epoch 350/1000 | Batch 0/237 | Loss: 3296.7744\n",
      "Epoch 350/1000 | Batch 100/237 | Loss: 1896.8806\n",
      "Epoch 350/1000 | Batch 200/237 | Loss: 2989.6436\n",
      "Epoch 350/1000 complete | Avg Loss: 4758.4440\n",
      "Epoch 351/1000 | Batch 0/237 | Loss: 1933.0513\n",
      "Epoch 351/1000 | Batch 100/237 | Loss: 1945.3578\n",
      "Epoch 351/1000 | Batch 200/237 | Loss: 2210.6074\n",
      "Epoch 351/1000 complete | Avg Loss: 4783.1150\n",
      "Epoch 352/1000 | Batch 0/237 | Loss: 4268.4751\n",
      "Epoch 352/1000 | Batch 100/237 | Loss: 22039.8594\n",
      "Epoch 352/1000 | Batch 200/237 | Loss: 1030.6127\n",
      "Epoch 352/1000 complete | Avg Loss: 4808.2626\n",
      "Epoch 353/1000 | Batch 0/237 | Loss: 1823.1957\n",
      "Epoch 353/1000 | Batch 100/237 | Loss: 658.0854\n",
      "Epoch 353/1000 | Batch 200/237 | Loss: 6454.5244\n",
      "Epoch 353/1000 complete | Avg Loss: 4753.0132\n",
      "Epoch 354/1000 | Batch 0/237 | Loss: 2200.0505\n",
      "Epoch 354/1000 | Batch 100/237 | Loss: 23141.5664\n",
      "Epoch 354/1000 | Batch 200/237 | Loss: 814.7906\n",
      "Epoch 354/1000 complete | Avg Loss: 4751.5335\n",
      "Epoch 355/1000 | Batch 0/237 | Loss: 13466.1143\n",
      "Epoch 355/1000 | Batch 100/237 | Loss: 2149.5828\n",
      "Epoch 355/1000 | Batch 200/237 | Loss: 915.0811\n",
      "Epoch 355/1000 complete | Avg Loss: 4758.3387\n",
      "Epoch 356/1000 | Batch 0/237 | Loss: 4829.9038\n",
      "Epoch 356/1000 | Batch 100/237 | Loss: 852.5997\n",
      "Epoch 356/1000 | Batch 200/237 | Loss: 1319.6316\n",
      "Epoch 356/1000 complete | Avg Loss: 4746.1606\n",
      "Epoch 357/1000 | Batch 0/237 | Loss: 1130.9470\n",
      "Epoch 357/1000 | Batch 100/237 | Loss: 864.7836\n",
      "Epoch 357/1000 | Batch 200/237 | Loss: 6358.1616\n",
      "Epoch 357/1000 complete | Avg Loss: 4751.0691\n",
      "Epoch 358/1000 | Batch 0/237 | Loss: 955.3576\n",
      "Epoch 358/1000 | Batch 100/237 | Loss: 1685.9128\n",
      "Epoch 358/1000 | Batch 200/237 | Loss: 4566.6270\n",
      "Epoch 358/1000 complete | Avg Loss: 4749.4034\n",
      "Epoch 359/1000 | Batch 0/237 | Loss: 11314.8398\n",
      "Epoch 359/1000 | Batch 100/237 | Loss: 4080.8994\n",
      "Epoch 359/1000 | Batch 200/237 | Loss: 1816.9761\n",
      "Epoch 359/1000 complete | Avg Loss: 4773.5679\n",
      "Epoch 360/1000 | Batch 0/237 | Loss: 2390.9041\n",
      "Epoch 360/1000 | Batch 100/237 | Loss: 569.5927\n",
      "Epoch 360/1000 | Batch 200/237 | Loss: 1667.6321\n",
      "Epoch 360/1000 complete | Avg Loss: 4749.2174\n",
      "Epoch 361/1000 | Batch 0/237 | Loss: 8860.1621\n",
      "Epoch 361/1000 | Batch 100/237 | Loss: 2313.9448\n",
      "Epoch 361/1000 | Batch 200/237 | Loss: 4212.4722\n",
      "Epoch 361/1000 complete | Avg Loss: 4870.7629\n",
      "Epoch 362/1000 | Batch 0/237 | Loss: 2438.4829\n",
      "Epoch 362/1000 | Batch 100/237 | Loss: 1827.5010\n",
      "Epoch 362/1000 | Batch 200/237 | Loss: 3851.1790\n",
      "Epoch 362/1000 complete | Avg Loss: 4795.7863\n",
      "Epoch 363/1000 | Batch 0/237 | Loss: 2468.9214\n",
      "Epoch 363/1000 | Batch 100/237 | Loss: 5568.8423\n",
      "Epoch 363/1000 | Batch 200/237 | Loss: 1063.9092\n",
      "Epoch 363/1000 complete | Avg Loss: 4743.1976\n",
      "Epoch 364/1000 | Batch 0/237 | Loss: 917.3385\n",
      "Epoch 364/1000 | Batch 100/237 | Loss: 591.1201\n",
      "Epoch 364/1000 | Batch 200/237 | Loss: 13858.2793\n",
      "Epoch 364/1000 complete | Avg Loss: 4740.7552\n",
      "Epoch 365/1000 | Batch 0/237 | Loss: 1873.1957\n",
      "Epoch 365/1000 | Batch 100/237 | Loss: 955.3176\n",
      "Epoch 365/1000 | Batch 200/237 | Loss: 4374.5420\n",
      "Epoch 365/1000 complete | Avg Loss: 4738.2582\n",
      "Epoch 366/1000 | Batch 0/237 | Loss: 1122.4163\n",
      "Epoch 366/1000 | Batch 100/237 | Loss: 625.5215\n",
      "Epoch 366/1000 | Batch 200/237 | Loss: 1596.7632\n",
      "Epoch 366/1000 complete | Avg Loss: 4735.6364\n",
      "Epoch 367/1000 | Batch 0/237 | Loss: 717.1998\n",
      "Epoch 367/1000 | Batch 100/237 | Loss: 1599.0773\n",
      "Epoch 367/1000 | Batch 200/237 | Loss: 1587.1410\n",
      "Epoch 367/1000 complete | Avg Loss: 4802.7302\n",
      "Epoch 368/1000 | Batch 0/237 | Loss: 2551.3711\n",
      "Epoch 368/1000 | Batch 100/237 | Loss: 1818.7373\n",
      "Epoch 368/1000 | Batch 200/237 | Loss: 3398.7852\n",
      "Epoch 368/1000 complete | Avg Loss: 4734.2226\n",
      "Epoch 369/1000 | Batch 0/237 | Loss: 1617.7595\n",
      "Epoch 369/1000 | Batch 100/237 | Loss: 969.7939\n",
      "Epoch 369/1000 | Batch 200/237 | Loss: 5289.2319\n",
      "Epoch 369/1000 complete | Avg Loss: 4732.7824\n",
      "Epoch 370/1000 | Batch 0/237 | Loss: 1795.1896\n",
      "Epoch 370/1000 | Batch 100/237 | Loss: 1195.6841\n",
      "Epoch 370/1000 | Batch 200/237 | Loss: 2288.9331\n",
      "Epoch 370/1000 complete | Avg Loss: 4746.9340\n",
      "Epoch 371/1000 | Batch 0/237 | Loss: 11084.4717\n",
      "Epoch 371/1000 | Batch 100/237 | Loss: 2756.3506\n",
      "Epoch 371/1000 | Batch 200/237 | Loss: 4919.7935\n",
      "Epoch 371/1000 complete | Avg Loss: 4873.9653\n",
      "Epoch 372/1000 | Batch 0/237 | Loss: 533.2773\n",
      "Epoch 372/1000 | Batch 100/237 | Loss: 1174.3530\n",
      "Epoch 372/1000 | Batch 200/237 | Loss: 2831.9971\n",
      "Epoch 372/1000 complete | Avg Loss: 4743.2883\n",
      "Epoch 373/1000 | Batch 0/237 | Loss: 1061.3915\n",
      "Epoch 373/1000 | Batch 100/237 | Loss: 1120.0398\n",
      "Epoch 373/1000 | Batch 200/237 | Loss: 973.8832\n",
      "Epoch 373/1000 complete | Avg Loss: 4735.2408\n",
      "Epoch 374/1000 | Batch 0/237 | Loss: 4860.7222\n",
      "Epoch 374/1000 | Batch 100/237 | Loss: 826.0358\n",
      "Epoch 374/1000 | Batch 200/237 | Loss: 5264.5107\n",
      "Epoch 374/1000 complete | Avg Loss: 4744.5273\n",
      "Epoch 375/1000 | Batch 0/237 | Loss: 773.0229\n",
      "Epoch 375/1000 | Batch 100/237 | Loss: 21379.5391\n",
      "Epoch 375/1000 | Batch 200/237 | Loss: 3869.9326\n",
      "Epoch 375/1000 complete | Avg Loss: 4727.7222\n",
      "Epoch 376/1000 | Batch 0/237 | Loss: 1124.8928\n",
      "Epoch 376/1000 | Batch 100/237 | Loss: 2060.5813\n",
      "Epoch 376/1000 | Batch 200/237 | Loss: 2466.1597\n",
      "Epoch 376/1000 complete | Avg Loss: 4725.4699\n",
      "Epoch 377/1000 | Batch 0/237 | Loss: 20492.7324\n",
      "Epoch 377/1000 | Batch 100/237 | Loss: 1886.4023\n",
      "Epoch 377/1000 | Batch 200/237 | Loss: 20278.1367\n",
      "Epoch 377/1000 complete | Avg Loss: 4726.5330\n",
      "Epoch 378/1000 | Batch 0/237 | Loss: 3482.8098\n",
      "Epoch 378/1000 | Batch 100/237 | Loss: 9467.3242\n",
      "Epoch 378/1000 | Batch 200/237 | Loss: 1389.0662\n",
      "Epoch 378/1000 complete | Avg Loss: 4737.2335\n",
      "Epoch 379/1000 | Batch 0/237 | Loss: 569.9163\n",
      "Epoch 379/1000 | Batch 100/237 | Loss: 1305.0670\n",
      "Epoch 379/1000 | Batch 200/237 | Loss: 1070.4543\n",
      "Epoch 379/1000 complete | Avg Loss: 4727.4295\n",
      "Epoch 380/1000 | Batch 0/237 | Loss: 9902.2090\n",
      "Epoch 380/1000 | Batch 100/237 | Loss: 1163.4349\n",
      "Epoch 380/1000 | Batch 200/237 | Loss: 2296.2866\n",
      "Epoch 380/1000 complete | Avg Loss: 4726.6527\n",
      "Epoch 381/1000 | Batch 0/237 | Loss: 457.4634\n",
      "Epoch 381/1000 | Batch 100/237 | Loss: 12813.8643\n",
      "Epoch 381/1000 | Batch 200/237 | Loss: 970.8815\n",
      "Epoch 381/1000 complete | Avg Loss: 4720.2919\n",
      "Epoch 382/1000 | Batch 0/237 | Loss: 5908.6079\n",
      "Epoch 382/1000 | Batch 100/237 | Loss: 6260.9619\n",
      "Epoch 382/1000 | Batch 200/237 | Loss: 2010.1375\n",
      "Epoch 382/1000 complete | Avg Loss: 4721.5028\n",
      "Epoch 383/1000 | Batch 0/237 | Loss: 1557.7407\n",
      "Epoch 383/1000 | Batch 100/237 | Loss: 40397.8633\n",
      "Epoch 383/1000 | Batch 200/237 | Loss: 2181.8049\n",
      "Epoch 383/1000 complete | Avg Loss: 4717.0491\n",
      "Epoch 384/1000 | Batch 0/237 | Loss: 1330.5272\n",
      "Epoch 384/1000 | Batch 100/237 | Loss: 13099.2979\n",
      "Epoch 384/1000 | Batch 200/237 | Loss: 2629.8232\n",
      "Epoch 384/1000 complete | Avg Loss: 4720.8678\n",
      "Epoch 385/1000 | Batch 0/237 | Loss: 2520.4399\n",
      "Epoch 385/1000 | Batch 100/237 | Loss: 1035.3262\n",
      "Epoch 385/1000 | Batch 200/237 | Loss: 1425.8884\n",
      "Epoch 385/1000 complete | Avg Loss: 4714.2232\n",
      "Epoch 386/1000 | Batch 0/237 | Loss: 2693.8577\n",
      "Epoch 386/1000 | Batch 100/237 | Loss: 8140.3252\n",
      "Epoch 386/1000 | Batch 200/237 | Loss: 605.1464\n",
      "Epoch 386/1000 complete | Avg Loss: 4721.9135\n",
      "Epoch 387/1000 | Batch 0/237 | Loss: 3804.1184\n",
      "Epoch 387/1000 | Batch 100/237 | Loss: 2478.3567\n",
      "Epoch 387/1000 | Batch 200/237 | Loss: 3335.8862\n",
      "Epoch 387/1000 complete | Avg Loss: 4730.7020\n",
      "Epoch 388/1000 | Batch 0/237 | Loss: 10916.7832\n",
      "Epoch 388/1000 | Batch 100/237 | Loss: 8692.4873\n",
      "Epoch 388/1000 | Batch 200/237 | Loss: 749.8896\n",
      "Epoch 388/1000 complete | Avg Loss: 4724.5873\n",
      "Epoch 389/1000 | Batch 0/237 | Loss: 3117.9644\n",
      "Epoch 389/1000 | Batch 100/237 | Loss: 3941.0566\n",
      "Epoch 389/1000 | Batch 200/237 | Loss: 3398.0256\n",
      "Epoch 389/1000 complete | Avg Loss: 4745.7402\n",
      "Epoch 390/1000 | Batch 0/237 | Loss: 3487.5010\n",
      "Epoch 390/1000 | Batch 100/237 | Loss: 1172.6252\n",
      "Epoch 390/1000 | Batch 200/237 | Loss: 2744.0737\n",
      "Epoch 390/1000 complete | Avg Loss: 4718.0740\n",
      "Epoch 391/1000 | Batch 0/237 | Loss: 705.9008\n",
      "Epoch 391/1000 | Batch 100/237 | Loss: 1788.6545\n",
      "Epoch 391/1000 | Batch 200/237 | Loss: 8543.0664\n",
      "Epoch 391/1000 complete | Avg Loss: 4712.8843\n",
      "Epoch 392/1000 | Batch 0/237 | Loss: 4000.9797\n",
      "Epoch 392/1000 | Batch 100/237 | Loss: 3378.7456\n",
      "Epoch 392/1000 | Batch 200/237 | Loss: 1099.4418\n",
      "Epoch 392/1000 complete | Avg Loss: 4725.8302\n",
      "Epoch 393/1000 | Batch 0/237 | Loss: 1482.1614\n",
      "Epoch 393/1000 | Batch 100/237 | Loss: 3846.3096\n",
      "Epoch 393/1000 | Batch 200/237 | Loss: 10464.4248\n",
      "Epoch 393/1000 complete | Avg Loss: 4715.6907\n",
      "Epoch 394/1000 | Batch 0/237 | Loss: 30374.9043\n",
      "Epoch 394/1000 | Batch 100/237 | Loss: 1030.5271\n",
      "Epoch 394/1000 | Batch 200/237 | Loss: 10101.1582\n",
      "Epoch 394/1000 complete | Avg Loss: 4730.9252\n",
      "Epoch 395/1000 | Batch 0/237 | Loss: 18173.0859\n",
      "Epoch 395/1000 | Batch 100/237 | Loss: 1354.6119\n",
      "Epoch 395/1000 | Batch 200/237 | Loss: 1016.9286\n",
      "Epoch 395/1000 complete | Avg Loss: 4733.7264\n",
      "Epoch 396/1000 | Batch 0/237 | Loss: 1720.8904\n",
      "Epoch 396/1000 | Batch 100/237 | Loss: 8366.7402\n",
      "Epoch 396/1000 | Batch 200/237 | Loss: 1990.2802\n",
      "Epoch 396/1000 complete | Avg Loss: 4714.6538\n",
      "Epoch 397/1000 | Batch 0/237 | Loss: 1052.1624\n",
      "Epoch 397/1000 | Batch 100/237 | Loss: 1153.4386\n",
      "Epoch 397/1000 | Batch 200/237 | Loss: 591.6619\n",
      "Epoch 397/1000 complete | Avg Loss: 4711.8577\n",
      "Epoch 398/1000 | Batch 0/237 | Loss: 922.3436\n",
      "Epoch 398/1000 | Batch 100/237 | Loss: 1813.0028\n",
      "Epoch 398/1000 | Batch 200/237 | Loss: 7241.5117\n",
      "Epoch 398/1000 complete | Avg Loss: 4704.3592\n",
      "Epoch 399/1000 | Batch 0/237 | Loss: 5970.7959\n",
      "Epoch 399/1000 | Batch 100/237 | Loss: 3968.3926\n",
      "Epoch 399/1000 | Batch 200/237 | Loss: 1902.6643\n",
      "Epoch 399/1000 complete | Avg Loss: 4709.9816\n",
      "Epoch 400/1000 | Batch 0/237 | Loss: 2351.2041\n",
      "Epoch 400/1000 | Batch 100/237 | Loss: 2832.5374\n",
      "Epoch 400/1000 | Batch 200/237 | Loss: 7217.2866\n",
      "Epoch 400/1000 complete | Avg Loss: 4703.1563\n",
      "Epoch 401/1000 | Batch 0/237 | Loss: 1729.0732\n",
      "Epoch 401/1000 | Batch 100/237 | Loss: 2157.0835\n",
      "Epoch 401/1000 | Batch 200/237 | Loss: 1472.9530\n",
      "Epoch 401/1000 complete | Avg Loss: 4716.6072\n",
      "Epoch 402/1000 | Batch 0/237 | Loss: 1014.0159\n",
      "Epoch 402/1000 | Batch 100/237 | Loss: 12237.8105\n",
      "Epoch 402/1000 | Batch 200/237 | Loss: 3699.8643\n",
      "Epoch 402/1000 complete | Avg Loss: 4708.0189\n",
      "Epoch 403/1000 | Batch 0/237 | Loss: 531.1309\n",
      "Epoch 403/1000 | Batch 100/237 | Loss: 1315.7258\n",
      "Epoch 403/1000 | Batch 200/237 | Loss: 16497.5293\n",
      "Epoch 403/1000 complete | Avg Loss: 4732.2099\n",
      "Epoch 404/1000 | Batch 0/237 | Loss: 2230.1091\n",
      "Epoch 404/1000 | Batch 100/237 | Loss: 405.5234\n",
      "Epoch 404/1000 | Batch 200/237 | Loss: 2735.9214\n",
      "Epoch 404/1000 complete | Avg Loss: 4702.6913\n",
      "Epoch 405/1000 | Batch 0/237 | Loss: 1717.6310\n",
      "Epoch 405/1000 | Batch 100/237 | Loss: 8449.2461\n",
      "Epoch 405/1000 | Batch 200/237 | Loss: 4604.2002\n",
      "Epoch 405/1000 complete | Avg Loss: 4696.7332\n",
      "Epoch 406/1000 | Batch 0/237 | Loss: 841.6725\n",
      "Epoch 406/1000 | Batch 100/237 | Loss: 5564.1855\n",
      "Epoch 406/1000 | Batch 200/237 | Loss: 6263.3247\n",
      "Epoch 406/1000 complete | Avg Loss: 4711.7025\n",
      "Epoch 407/1000 | Batch 0/237 | Loss: 2416.7632\n",
      "Epoch 407/1000 | Batch 100/237 | Loss: 2798.9985\n",
      "Epoch 407/1000 | Batch 200/237 | Loss: 5223.5718\n",
      "Epoch 407/1000 complete | Avg Loss: 4696.1048\n",
      "Epoch 408/1000 | Batch 0/237 | Loss: 542.4305\n",
      "Epoch 408/1000 | Batch 100/237 | Loss: 712.2518\n",
      "Epoch 408/1000 | Batch 200/237 | Loss: 1179.5344\n",
      "Epoch 408/1000 complete | Avg Loss: 4701.6146\n",
      "Epoch 409/1000 | Batch 0/237 | Loss: 1689.5315\n",
      "Epoch 409/1000 | Batch 100/237 | Loss: 40485.3789\n",
      "Epoch 409/1000 | Batch 200/237 | Loss: 3916.6287\n",
      "Epoch 409/1000 complete | Avg Loss: 4787.0142\n",
      "Epoch 410/1000 | Batch 0/237 | Loss: 4627.8711\n",
      "Epoch 410/1000 | Batch 100/237 | Loss: 1748.5439\n",
      "Epoch 410/1000 | Batch 200/237 | Loss: 4368.9624\n",
      "Epoch 410/1000 complete | Avg Loss: 4704.5020\n",
      "Epoch 411/1000 | Batch 0/237 | Loss: 3442.4861\n",
      "Epoch 411/1000 | Batch 100/237 | Loss: 588.4962\n",
      "Epoch 411/1000 | Batch 200/237 | Loss: 4313.3701\n",
      "Epoch 411/1000 complete | Avg Loss: 4705.0157\n",
      "Epoch 412/1000 | Batch 0/237 | Loss: 887.4504\n",
      "Epoch 412/1000 | Batch 100/237 | Loss: 8088.6367\n",
      "Epoch 412/1000 | Batch 200/237 | Loss: 14528.7754\n",
      "Epoch 412/1000 complete | Avg Loss: 4704.3784\n",
      "Epoch 413/1000 | Batch 0/237 | Loss: 3128.5835\n",
      "Epoch 413/1000 | Batch 100/237 | Loss: 780.5322\n",
      "Epoch 413/1000 | Batch 200/237 | Loss: 700.5518\n",
      "Epoch 413/1000 complete | Avg Loss: 4696.9118\n",
      "Epoch 414/1000 | Batch 0/237 | Loss: 21842.7578\n",
      "Epoch 414/1000 | Batch 100/237 | Loss: 881.8571\n",
      "Epoch 414/1000 | Batch 200/237 | Loss: 1427.9103\n",
      "Epoch 414/1000 complete | Avg Loss: 4709.8869\n",
      "Epoch 415/1000 | Batch 0/237 | Loss: 1361.6272\n",
      "Epoch 415/1000 | Batch 100/237 | Loss: 36466.8320\n",
      "Epoch 415/1000 | Batch 200/237 | Loss: 1371.3402\n",
      "Epoch 415/1000 complete | Avg Loss: 4705.0019\n",
      "Epoch 416/1000 | Batch 0/237 | Loss: 7509.7954\n",
      "Epoch 416/1000 | Batch 100/237 | Loss: 2266.0496\n",
      "Epoch 416/1000 | Batch 200/237 | Loss: 15975.2549\n",
      "Epoch 416/1000 complete | Avg Loss: 4691.6325\n",
      "Epoch 417/1000 | Batch 0/237 | Loss: 1167.4310\n",
      "Epoch 417/1000 | Batch 100/237 | Loss: 2202.4043\n",
      "Epoch 417/1000 | Batch 200/237 | Loss: 8146.7471\n",
      "Epoch 417/1000 complete | Avg Loss: 4690.8501\n",
      "Epoch 418/1000 | Batch 0/237 | Loss: 5164.7334\n",
      "Epoch 418/1000 | Batch 100/237 | Loss: 8709.7305\n",
      "Epoch 418/1000 | Batch 200/237 | Loss: 1026.4125\n",
      "Epoch 418/1000 complete | Avg Loss: 4696.7507\n",
      "Epoch 419/1000 | Batch 0/237 | Loss: 791.6499\n",
      "Epoch 419/1000 | Batch 100/237 | Loss: 1323.4175\n",
      "Epoch 419/1000 | Batch 200/237 | Loss: 950.2143\n",
      "Epoch 419/1000 complete | Avg Loss: 4689.7432\n",
      "Epoch 420/1000 | Batch 0/237 | Loss: 824.1660\n",
      "Epoch 420/1000 | Batch 100/237 | Loss: 9437.9072\n",
      "Epoch 420/1000 | Batch 200/237 | Loss: 575.3196\n",
      "Epoch 420/1000 complete | Avg Loss: 4694.7871\n",
      "Epoch 421/1000 | Batch 0/237 | Loss: 7759.9834\n",
      "Epoch 421/1000 | Batch 100/237 | Loss: 19069.0000\n",
      "Epoch 421/1000 | Batch 200/237 | Loss: 6354.7998\n",
      "Epoch 421/1000 complete | Avg Loss: 4687.5806\n",
      "Epoch 422/1000 | Batch 0/237 | Loss: 1395.1023\n",
      "Epoch 422/1000 | Batch 100/237 | Loss: 6295.2671\n",
      "Epoch 422/1000 | Batch 200/237 | Loss: 1486.6490\n",
      "Epoch 422/1000 complete | Avg Loss: 4688.1486\n",
      "Epoch 423/1000 | Batch 0/237 | Loss: 966.8748\n",
      "Epoch 423/1000 | Batch 100/237 | Loss: 3735.4712\n",
      "Epoch 423/1000 | Batch 200/237 | Loss: 4005.1689\n",
      "Epoch 423/1000 complete | Avg Loss: 4689.4766\n",
      "Epoch 424/1000 | Batch 0/237 | Loss: 26769.1836\n",
      "Epoch 424/1000 | Batch 100/237 | Loss: 1015.8135\n",
      "Epoch 424/1000 | Batch 200/237 | Loss: 1956.9525\n",
      "Epoch 424/1000 complete | Avg Loss: 4741.7447\n",
      "Epoch 425/1000 | Batch 0/237 | Loss: 2952.9319\n",
      "Epoch 425/1000 | Batch 100/237 | Loss: 2369.5874\n",
      "Epoch 425/1000 | Batch 200/237 | Loss: 2180.5769\n",
      "Epoch 425/1000 complete | Avg Loss: 4696.1447\n",
      "Epoch 426/1000 | Batch 0/237 | Loss: 781.2081\n",
      "Epoch 426/1000 | Batch 100/237 | Loss: 1026.3729\n",
      "Epoch 426/1000 | Batch 200/237 | Loss: 5279.1001\n",
      "Epoch 426/1000 complete | Avg Loss: 4688.2773\n",
      "Epoch 427/1000 | Batch 0/237 | Loss: 1032.4758\n",
      "Epoch 427/1000 | Batch 100/237 | Loss: 3205.0525\n",
      "Epoch 427/1000 | Batch 200/237 | Loss: 2702.0352\n",
      "Epoch 427/1000 complete | Avg Loss: 4686.4617\n",
      "Epoch 428/1000 | Batch 0/237 | Loss: 12932.8232\n",
      "Epoch 428/1000 | Batch 100/237 | Loss: 6793.1313\n",
      "Epoch 428/1000 | Batch 200/237 | Loss: 2989.4041\n",
      "Epoch 428/1000 complete | Avg Loss: 4747.4657\n",
      "Epoch 429/1000 | Batch 0/237 | Loss: 1259.6285\n",
      "Epoch 429/1000 | Batch 100/237 | Loss: 4413.6826\n",
      "Epoch 429/1000 | Batch 200/237 | Loss: 2680.7249\n",
      "Epoch 429/1000 complete | Avg Loss: 4673.4296\n",
      "Epoch 430/1000 | Batch 0/237 | Loss: 443.9391\n",
      "Epoch 430/1000 | Batch 100/237 | Loss: 1509.8473\n",
      "Epoch 430/1000 | Batch 200/237 | Loss: 1090.6874\n",
      "Epoch 430/1000 complete | Avg Loss: 4685.2575\n",
      "Epoch 431/1000 | Batch 0/237 | Loss: 1242.2661\n",
      "Epoch 431/1000 | Batch 100/237 | Loss: 680.8002\n",
      "Epoch 431/1000 | Batch 200/237 | Loss: 806.1365\n",
      "Epoch 431/1000 complete | Avg Loss: 4681.9534\n",
      "Epoch 432/1000 | Batch 0/237 | Loss: 2003.2385\n",
      "Epoch 432/1000 | Batch 100/237 | Loss: 879.2500\n",
      "Epoch 432/1000 | Batch 200/237 | Loss: 3428.0696\n",
      "Epoch 432/1000 complete | Avg Loss: 4691.6585\n",
      "Epoch 433/1000 | Batch 0/237 | Loss: 1507.3907\n",
      "Epoch 433/1000 | Batch 100/237 | Loss: 22121.2832\n",
      "Epoch 433/1000 | Batch 200/237 | Loss: 2530.2314\n",
      "Epoch 433/1000 complete | Avg Loss: 4681.0584\n",
      "Epoch 434/1000 | Batch 0/237 | Loss: 1119.7484\n",
      "Epoch 434/1000 | Batch 100/237 | Loss: 1710.7638\n",
      "Epoch 434/1000 | Batch 200/237 | Loss: 15142.8613\n",
      "Epoch 434/1000 complete | Avg Loss: 4683.3159\n",
      "Epoch 435/1000 | Batch 0/237 | Loss: 1515.2092\n",
      "Epoch 435/1000 | Batch 100/237 | Loss: 3184.3447\n",
      "Epoch 435/1000 | Batch 200/237 | Loss: 1320.9844\n",
      "Epoch 435/1000 complete | Avg Loss: 4685.7537\n",
      "Epoch 436/1000 | Batch 0/237 | Loss: 27685.4727\n",
      "Epoch 436/1000 | Batch 100/237 | Loss: 23438.2070\n",
      "Epoch 436/1000 | Batch 200/237 | Loss: 4064.4375\n",
      "Epoch 436/1000 complete | Avg Loss: 4699.5116\n",
      "Epoch 437/1000 | Batch 0/237 | Loss: 786.8100\n",
      "Epoch 437/1000 | Batch 100/237 | Loss: 2785.1687\n",
      "Epoch 437/1000 | Batch 200/237 | Loss: 5268.8687\n",
      "Epoch 437/1000 complete | Avg Loss: 4709.0260\n",
      "Epoch 438/1000 | Batch 0/237 | Loss: 770.5747\n",
      "Epoch 438/1000 | Batch 100/237 | Loss: 3124.8816\n",
      "Epoch 438/1000 | Batch 200/237 | Loss: 1772.7916\n",
      "Epoch 438/1000 complete | Avg Loss: 4677.8846\n",
      "Epoch 439/1000 | Batch 0/237 | Loss: 5997.7280\n",
      "Epoch 439/1000 | Batch 100/237 | Loss: 3069.3687\n",
      "Epoch 439/1000 | Batch 200/237 | Loss: 7058.6123\n",
      "Epoch 439/1000 complete | Avg Loss: 4670.7785\n",
      "Epoch 440/1000 | Batch 0/237 | Loss: 1865.9154\n",
      "Epoch 440/1000 | Batch 100/237 | Loss: 2978.8467\n",
      "Epoch 440/1000 | Batch 200/237 | Loss: 1219.1790\n",
      "Epoch 440/1000 complete | Avg Loss: 4674.5445\n",
      "Epoch 441/1000 | Batch 0/237 | Loss: 1437.4354\n",
      "Epoch 441/1000 | Batch 100/237 | Loss: 1644.5319\n",
      "Epoch 441/1000 | Batch 200/237 | Loss: 3303.0913\n",
      "Epoch 441/1000 complete | Avg Loss: 4682.1045\n",
      "Epoch 442/1000 | Batch 0/237 | Loss: 2963.5579\n",
      "Epoch 442/1000 | Batch 100/237 | Loss: 1940.9932\n",
      "Epoch 442/1000 | Batch 200/237 | Loss: 2178.5369\n",
      "Epoch 442/1000 complete | Avg Loss: 4670.6685\n",
      "Epoch 443/1000 | Batch 0/237 | Loss: 1007.8544\n",
      "Epoch 443/1000 | Batch 100/237 | Loss: 4211.2905\n",
      "Epoch 443/1000 | Batch 200/237 | Loss: 1824.5304\n",
      "Epoch 443/1000 complete | Avg Loss: 4701.3829\n",
      "Epoch 444/1000 | Batch 0/237 | Loss: 8107.4087\n",
      "Epoch 444/1000 | Batch 100/237 | Loss: 1061.0488\n",
      "Epoch 444/1000 | Batch 200/237 | Loss: 3593.6089\n",
      "Epoch 444/1000 complete | Avg Loss: 4680.1291\n",
      "Epoch 445/1000 | Batch 0/237 | Loss: 2953.3198\n",
      "Epoch 445/1000 | Batch 100/237 | Loss: 12033.7578\n",
      "Epoch 445/1000 | Batch 200/237 | Loss: 1772.7395\n",
      "Epoch 445/1000 complete | Avg Loss: 4674.9786\n",
      "Epoch 446/1000 | Batch 0/237 | Loss: 1734.8806\n",
      "Epoch 446/1000 | Batch 100/237 | Loss: 2656.0286\n",
      "Epoch 446/1000 | Batch 200/237 | Loss: 25920.5742\n",
      "Epoch 446/1000 complete | Avg Loss: 4670.7807\n",
      "Epoch 447/1000 | Batch 0/237 | Loss: 23268.5234\n",
      "Epoch 447/1000 | Batch 100/237 | Loss: 2955.3320\n",
      "Epoch 447/1000 | Batch 200/237 | Loss: 1357.0599\n",
      "Epoch 447/1000 complete | Avg Loss: 4679.0529\n",
      "Epoch 448/1000 | Batch 0/237 | Loss: 9256.0996\n",
      "Epoch 448/1000 | Batch 100/237 | Loss: 1924.0640\n",
      "Epoch 448/1000 | Batch 200/237 | Loss: 1756.6664\n",
      "Epoch 448/1000 complete | Avg Loss: 4671.5768\n",
      "Epoch 449/1000 | Batch 0/237 | Loss: 5802.8691\n",
      "Epoch 449/1000 | Batch 100/237 | Loss: 1347.6783\n",
      "Epoch 449/1000 | Batch 200/237 | Loss: 5016.5996\n",
      "Epoch 449/1000 complete | Avg Loss: 4671.7809\n",
      "Epoch 450/1000 | Batch 0/237 | Loss: 5231.2998\n",
      "Epoch 450/1000 | Batch 100/237 | Loss: 17732.1543\n",
      "Epoch 450/1000 | Batch 200/237 | Loss: 1320.6216\n",
      "Epoch 450/1000 complete | Avg Loss: 4667.4404\n",
      "Epoch 451/1000 | Batch 0/237 | Loss: 6327.7412\n",
      "Epoch 451/1000 | Batch 100/237 | Loss: 927.2542\n",
      "Epoch 451/1000 | Batch 200/237 | Loss: 3938.6052\n",
      "Epoch 451/1000 complete | Avg Loss: 4729.0303\n",
      "Epoch 452/1000 | Batch 0/237 | Loss: 6914.1055\n",
      "Epoch 452/1000 | Batch 100/237 | Loss: 1737.7358\n",
      "Epoch 452/1000 | Batch 200/237 | Loss: 805.1775\n",
      "Epoch 452/1000 complete | Avg Loss: 4674.3602\n",
      "Epoch 453/1000 | Batch 0/237 | Loss: 1313.5497\n",
      "Epoch 453/1000 | Batch 100/237 | Loss: 2961.9854\n",
      "Epoch 453/1000 | Batch 200/237 | Loss: 4383.2134\n",
      "Epoch 453/1000 complete | Avg Loss: 4671.1462\n",
      "Epoch 454/1000 | Batch 0/237 | Loss: 935.7145\n",
      "Epoch 454/1000 | Batch 100/237 | Loss: 1031.7576\n",
      "Epoch 454/1000 | Batch 200/237 | Loss: 1005.7344\n",
      "Epoch 454/1000 complete | Avg Loss: 4667.8604\n",
      "Epoch 455/1000 | Batch 0/237 | Loss: 3933.2288\n",
      "Epoch 455/1000 | Batch 100/237 | Loss: 11384.9727\n",
      "Epoch 455/1000 | Batch 200/237 | Loss: 1321.9913\n",
      "Epoch 455/1000 complete | Avg Loss: 4701.6187\n",
      "Epoch 456/1000 | Batch 0/237 | Loss: 643.7679\n",
      "Epoch 456/1000 | Batch 100/237 | Loss: 2056.5398\n",
      "Epoch 456/1000 | Batch 200/237 | Loss: 4450.7817\n",
      "Epoch 456/1000 complete | Avg Loss: 4675.0318\n",
      "Epoch 457/1000 | Batch 0/237 | Loss: 1114.8009\n",
      "Epoch 457/1000 | Batch 100/237 | Loss: 1065.9934\n",
      "Epoch 457/1000 | Batch 200/237 | Loss: 1049.2413\n",
      "Epoch 457/1000 complete | Avg Loss: 4658.4891\n",
      "Epoch 458/1000 | Batch 0/237 | Loss: 1061.7535\n",
      "Epoch 458/1000 | Batch 100/237 | Loss: 18754.2363\n",
      "Epoch 458/1000 | Batch 200/237 | Loss: 3311.1128\n",
      "Epoch 458/1000 complete | Avg Loss: 4668.3464\n",
      "Epoch 459/1000 | Batch 0/237 | Loss: 2210.1746\n",
      "Epoch 459/1000 | Batch 100/237 | Loss: 1133.6343\n",
      "Epoch 459/1000 | Batch 200/237 | Loss: 1378.0808\n",
      "Epoch 459/1000 complete | Avg Loss: 4672.4788\n",
      "Epoch 460/1000 | Batch 0/237 | Loss: 2551.7673\n",
      "Epoch 460/1000 | Batch 100/237 | Loss: 1439.5857\n",
      "Epoch 460/1000 | Batch 200/237 | Loss: 2890.4897\n",
      "Epoch 460/1000 complete | Avg Loss: 4667.8201\n",
      "Epoch 461/1000 | Batch 0/237 | Loss: 2659.6836\n",
      "Epoch 461/1000 | Batch 100/237 | Loss: 2787.5981\n",
      "Epoch 461/1000 | Batch 200/237 | Loss: 3071.4351\n",
      "Epoch 461/1000 complete | Avg Loss: 4662.8117\n",
      "Epoch 462/1000 | Batch 0/237 | Loss: 1370.8263\n",
      "Epoch 462/1000 | Batch 100/237 | Loss: 2628.0618\n",
      "Epoch 462/1000 | Batch 200/237 | Loss: 786.2296\n",
      "Epoch 462/1000 complete | Avg Loss: 4661.0327\n",
      "Epoch 463/1000 | Batch 0/237 | Loss: 2319.0696\n",
      "Epoch 463/1000 | Batch 100/237 | Loss: 1297.7854\n",
      "Epoch 463/1000 | Batch 200/237 | Loss: 6808.3677\n",
      "Epoch 463/1000 complete | Avg Loss: 4660.9530\n",
      "Epoch 464/1000 | Batch 0/237 | Loss: 3993.4404\n",
      "Epoch 464/1000 | Batch 100/237 | Loss: 780.4409\n",
      "Epoch 464/1000 | Batch 200/237 | Loss: 2004.6921\n",
      "Epoch 464/1000 complete | Avg Loss: 4661.0773\n",
      "Epoch 465/1000 | Batch 0/237 | Loss: 3498.7708\n",
      "Epoch 465/1000 | Batch 100/237 | Loss: 18734.0195\n",
      "Epoch 465/1000 | Batch 200/237 | Loss: 1977.7225\n",
      "Epoch 465/1000 complete | Avg Loss: 4654.8223\n",
      "Epoch 466/1000 | Batch 0/237 | Loss: 3771.9480\n",
      "Epoch 466/1000 | Batch 100/237 | Loss: 1139.7454\n",
      "Epoch 466/1000 | Batch 200/237 | Loss: 9543.9580\n",
      "Epoch 466/1000 complete | Avg Loss: 4656.7907\n",
      "Epoch 467/1000 | Batch 0/237 | Loss: 1121.3915\n",
      "Epoch 467/1000 | Batch 100/237 | Loss: 1044.4972\n",
      "Epoch 467/1000 | Batch 200/237 | Loss: 2215.8208\n",
      "Epoch 467/1000 complete | Avg Loss: 4662.1738\n",
      "Epoch 468/1000 | Batch 0/237 | Loss: 1906.0657\n",
      "Epoch 468/1000 | Batch 100/237 | Loss: 2373.0366\n",
      "Epoch 468/1000 | Batch 200/237 | Loss: 1569.2617\n",
      "Epoch 468/1000 complete | Avg Loss: 4656.7721\n",
      "Epoch 469/1000 | Batch 0/237 | Loss: 4129.3789\n",
      "Epoch 469/1000 | Batch 100/237 | Loss: 11084.9268\n",
      "Epoch 469/1000 | Batch 200/237 | Loss: 3663.5120\n",
      "Epoch 469/1000 complete | Avg Loss: 4667.3965\n",
      "Epoch 470/1000 | Batch 0/237 | Loss: 1498.1124\n",
      "Epoch 470/1000 | Batch 100/237 | Loss: 870.7537\n",
      "Epoch 470/1000 | Batch 200/237 | Loss: 4055.1777\n",
      "Epoch 470/1000 complete | Avg Loss: 4676.6223\n",
      "Epoch 471/1000 | Batch 0/237 | Loss: 3804.4602\n",
      "Epoch 471/1000 | Batch 100/237 | Loss: 11886.2070\n",
      "Epoch 471/1000 | Batch 200/237 | Loss: 2538.2429\n",
      "Epoch 471/1000 complete | Avg Loss: 4654.0456\n",
      "Epoch 472/1000 | Batch 0/237 | Loss: 8629.5107\n",
      "Epoch 472/1000 | Batch 100/237 | Loss: 13735.7529\n",
      "Epoch 472/1000 | Batch 200/237 | Loss: 748.5439\n",
      "Epoch 472/1000 complete | Avg Loss: 4782.2733\n",
      "Epoch 473/1000 | Batch 0/237 | Loss: 1011.0566\n",
      "Epoch 473/1000 | Batch 100/237 | Loss: 1093.2079\n",
      "Epoch 473/1000 | Batch 200/237 | Loss: 3277.8723\n",
      "Epoch 473/1000 complete | Avg Loss: 4660.2261\n",
      "Epoch 474/1000 | Batch 0/237 | Loss: 13607.8438\n",
      "Epoch 474/1000 | Batch 100/237 | Loss: 11372.5557\n",
      "Epoch 474/1000 | Batch 200/237 | Loss: 1448.7664\n",
      "Epoch 474/1000 complete | Avg Loss: 4656.4704\n",
      "Epoch 475/1000 | Batch 0/237 | Loss: 1399.8766\n",
      "Epoch 475/1000 | Batch 100/237 | Loss: 2483.5254\n",
      "Epoch 475/1000 | Batch 200/237 | Loss: 1380.4078\n",
      "Epoch 475/1000 complete | Avg Loss: 4654.0989\n",
      "Epoch 476/1000 | Batch 0/237 | Loss: 842.9052\n",
      "Epoch 476/1000 | Batch 100/237 | Loss: 3869.9363\n",
      "Epoch 476/1000 | Batch 200/237 | Loss: 7672.0835\n",
      "Epoch 476/1000 complete | Avg Loss: 4650.7438\n",
      "Epoch 477/1000 | Batch 0/237 | Loss: 1586.8861\n",
      "Epoch 477/1000 | Batch 100/237 | Loss: 4138.3599\n",
      "Epoch 477/1000 | Batch 200/237 | Loss: 1350.1934\n",
      "Epoch 477/1000 complete | Avg Loss: 4646.4074\n",
      "Epoch 478/1000 | Batch 0/237 | Loss: 813.3223\n",
      "Epoch 478/1000 | Batch 100/237 | Loss: 5035.8125\n",
      "Epoch 478/1000 | Batch 200/237 | Loss: 2629.5823\n",
      "Epoch 478/1000 complete | Avg Loss: 4657.9299\n",
      "Epoch 479/1000 | Batch 0/237 | Loss: 11941.8906\n",
      "Epoch 479/1000 | Batch 100/237 | Loss: 1153.5361\n",
      "Epoch 479/1000 | Batch 200/237 | Loss: 1499.3719\n",
      "Epoch 479/1000 complete | Avg Loss: 4650.6087\n",
      "Epoch 480/1000 | Batch 0/237 | Loss: 20633.8887\n",
      "Epoch 480/1000 | Batch 100/237 | Loss: 5465.1602\n",
      "Epoch 480/1000 | Batch 200/237 | Loss: 981.2787\n",
      "Epoch 480/1000 complete | Avg Loss: 4649.0345\n",
      "Epoch 481/1000 | Batch 0/237 | Loss: 1082.3931\n",
      "Epoch 481/1000 | Batch 100/237 | Loss: 4325.7461\n",
      "Epoch 481/1000 | Batch 200/237 | Loss: 41242.3633\n",
      "Epoch 481/1000 complete | Avg Loss: 4648.9808\n",
      "Epoch 482/1000 | Batch 0/237 | Loss: 4021.5303\n",
      "Epoch 482/1000 | Batch 100/237 | Loss: 1794.0901\n",
      "Epoch 482/1000 | Batch 200/237 | Loss: 25933.6953\n",
      "Epoch 482/1000 complete | Avg Loss: 4676.9226\n",
      "Epoch 483/1000 | Batch 0/237 | Loss: 6111.0967\n",
      "Epoch 483/1000 | Batch 100/237 | Loss: 1944.5499\n",
      "Epoch 483/1000 | Batch 200/237 | Loss: 726.5192\n",
      "Epoch 483/1000 complete | Avg Loss: 4653.0520\n",
      "Epoch 484/1000 | Batch 0/237 | Loss: 476.8196\n",
      "Epoch 484/1000 | Batch 100/237 | Loss: 1853.1787\n",
      "Epoch 484/1000 | Batch 200/237 | Loss: 25446.4727\n",
      "Epoch 484/1000 complete | Avg Loss: 4644.4719\n",
      "Epoch 485/1000 | Batch 0/237 | Loss: 1791.6902\n",
      "Epoch 485/1000 | Batch 100/237 | Loss: 4672.0391\n",
      "Epoch 485/1000 | Batch 200/237 | Loss: 1177.8964\n",
      "Epoch 485/1000 complete | Avg Loss: 4645.0942\n",
      "Epoch 486/1000 | Batch 0/237 | Loss: 17433.1719\n",
      "Epoch 486/1000 | Batch 100/237 | Loss: 3509.0732\n",
      "Epoch 486/1000 | Batch 200/237 | Loss: 2242.9253\n",
      "Epoch 486/1000 complete | Avg Loss: 4656.6458\n",
      "Epoch 487/1000 | Batch 0/237 | Loss: 2791.3750\n",
      "Epoch 487/1000 | Batch 100/237 | Loss: 657.7741\n",
      "Epoch 487/1000 | Batch 200/237 | Loss: 4307.9736\n",
      "Epoch 487/1000 complete | Avg Loss: 4651.3748\n",
      "Epoch 488/1000 | Batch 0/237 | Loss: 11881.6133\n",
      "Epoch 488/1000 | Batch 100/237 | Loss: 1743.6671\n",
      "Epoch 488/1000 | Batch 200/237 | Loss: 883.8884\n",
      "Epoch 488/1000 complete | Avg Loss: 4640.0453\n",
      "Epoch 489/1000 | Batch 0/237 | Loss: 1034.6407\n",
      "Epoch 489/1000 | Batch 100/237 | Loss: 881.0701\n",
      "Epoch 489/1000 | Batch 200/237 | Loss: 989.1348\n",
      "Epoch 489/1000 complete | Avg Loss: 4638.7904\n",
      "Epoch 490/1000 | Batch 0/237 | Loss: 4139.6626\n",
      "Epoch 490/1000 | Batch 100/237 | Loss: 16435.5430\n",
      "Epoch 490/1000 | Batch 200/237 | Loss: 745.4536\n",
      "Epoch 490/1000 complete | Avg Loss: 4645.1189\n",
      "Epoch 491/1000 | Batch 0/237 | Loss: 16446.6523\n",
      "Epoch 491/1000 | Batch 100/237 | Loss: 1701.8475\n",
      "Epoch 491/1000 | Batch 200/237 | Loss: 1039.3013\n",
      "Epoch 491/1000 complete | Avg Loss: 4643.7206\n",
      "Epoch 492/1000 | Batch 0/237 | Loss: 2143.2749\n",
      "Epoch 492/1000 | Batch 100/237 | Loss: 3929.7676\n",
      "Epoch 492/1000 | Batch 200/237 | Loss: 2290.4448\n",
      "Epoch 492/1000 complete | Avg Loss: 4641.7921\n",
      "Epoch 493/1000 | Batch 0/237 | Loss: 3754.6694\n",
      "Epoch 493/1000 | Batch 100/237 | Loss: 4478.8442\n",
      "Epoch 493/1000 | Batch 200/237 | Loss: 2825.5017\n",
      "Epoch 493/1000 complete | Avg Loss: 4643.5157\n",
      "Epoch 494/1000 | Batch 0/237 | Loss: 2531.4543\n",
      "Epoch 494/1000 | Batch 100/237 | Loss: 3237.7322\n",
      "Epoch 494/1000 | Batch 200/237 | Loss: 26682.9258\n",
      "Epoch 494/1000 complete | Avg Loss: 4641.0597\n",
      "Epoch 495/1000 | Batch 0/237 | Loss: 5033.8594\n",
      "Epoch 495/1000 | Batch 100/237 | Loss: 869.0667\n",
      "Epoch 495/1000 | Batch 200/237 | Loss: 3468.9426\n",
      "Epoch 495/1000 complete | Avg Loss: 4640.4490\n",
      "Epoch 496/1000 | Batch 0/237 | Loss: 14469.8867\n",
      "Epoch 496/1000 | Batch 100/237 | Loss: 1718.6143\n",
      "Epoch 496/1000 | Batch 200/237 | Loss: 1060.9368\n",
      "Epoch 496/1000 complete | Avg Loss: 4646.6519\n",
      "Epoch 497/1000 | Batch 0/237 | Loss: 1292.8944\n",
      "Epoch 497/1000 | Batch 100/237 | Loss: 1503.0880\n",
      "Epoch 497/1000 | Batch 200/237 | Loss: 1018.2804\n",
      "Epoch 497/1000 complete | Avg Loss: 4637.9749\n",
      "Epoch 498/1000 | Batch 0/237 | Loss: 2432.7808\n",
      "Epoch 498/1000 | Batch 100/237 | Loss: 2524.8298\n",
      "Epoch 498/1000 | Batch 200/237 | Loss: 1902.9403\n",
      "Epoch 498/1000 complete | Avg Loss: 4654.2463\n",
      "Epoch 499/1000 | Batch 0/237 | Loss: 7065.0010\n",
      "Epoch 499/1000 | Batch 100/237 | Loss: 2017.3966\n",
      "Epoch 499/1000 | Batch 200/237 | Loss: 7095.6621\n",
      "Epoch 499/1000 complete | Avg Loss: 4639.9949\n",
      "Epoch 500/1000 | Batch 0/237 | Loss: 39409.1953\n",
      "Epoch 500/1000 | Batch 100/237 | Loss: 733.9844\n",
      "Epoch 500/1000 | Batch 200/237 | Loss: 2174.7336\n",
      "Epoch 500/1000 complete | Avg Loss: 4634.4761\n",
      "Epoch 501/1000 | Batch 0/237 | Loss: 1113.0129\n",
      "Epoch 501/1000 | Batch 100/237 | Loss: 4109.4453\n",
      "Epoch 501/1000 | Batch 200/237 | Loss: 2245.7654\n",
      "Epoch 501/1000 complete | Avg Loss: 4642.4412\n",
      "Epoch 502/1000 | Batch 0/237 | Loss: 3788.6729\n",
      "Epoch 502/1000 | Batch 100/237 | Loss: 32026.1797\n",
      "Epoch 502/1000 | Batch 200/237 | Loss: 6542.7461\n",
      "Epoch 502/1000 complete | Avg Loss: 4630.8046\n",
      "Epoch 503/1000 | Batch 0/237 | Loss: 1119.7670\n",
      "Epoch 503/1000 | Batch 100/237 | Loss: 1814.2122\n",
      "Epoch 503/1000 | Batch 200/237 | Loss: 4796.9326\n",
      "Epoch 503/1000 complete | Avg Loss: 4642.9087\n",
      "Epoch 504/1000 | Batch 0/237 | Loss: 1203.6902\n",
      "Epoch 504/1000 | Batch 100/237 | Loss: 507.8200\n",
      "Epoch 504/1000 | Batch 200/237 | Loss: 1962.6538\n",
      "Epoch 504/1000 complete | Avg Loss: 4631.5616\n",
      "Epoch 505/1000 | Batch 0/237 | Loss: 32965.4648\n",
      "Epoch 505/1000 | Batch 100/237 | Loss: 2901.1187\n",
      "Epoch 505/1000 | Batch 200/237 | Loss: 1036.9669\n",
      "Epoch 505/1000 complete | Avg Loss: 4634.1206\n",
      "Epoch 506/1000 | Batch 0/237 | Loss: 8130.2290\n",
      "Epoch 506/1000 | Batch 100/237 | Loss: 29206.3711\n",
      "Epoch 506/1000 | Batch 200/237 | Loss: 1797.6006\n",
      "Epoch 506/1000 complete | Avg Loss: 4640.9966\n",
      "Epoch 507/1000 | Batch 0/237 | Loss: 2033.7080\n",
      "Epoch 507/1000 | Batch 100/237 | Loss: 3974.8110\n",
      "Epoch 507/1000 | Batch 200/237 | Loss: 21652.7344\n",
      "Epoch 507/1000 complete | Avg Loss: 4630.8627\n",
      "Epoch 508/1000 | Batch 0/237 | Loss: 1494.3413\n",
      "Epoch 508/1000 | Batch 100/237 | Loss: 3870.0288\n",
      "Epoch 508/1000 | Batch 200/237 | Loss: 1348.6345\n",
      "Epoch 508/1000 complete | Avg Loss: 4631.4668\n",
      "Epoch 509/1000 | Batch 0/237 | Loss: 809.5644\n",
      "Epoch 509/1000 | Batch 100/237 | Loss: 1897.9154\n",
      "Epoch 509/1000 | Batch 200/237 | Loss: 2156.8569\n",
      "Epoch 509/1000 complete | Avg Loss: 4630.5259\n",
      "Epoch 510/1000 | Batch 0/237 | Loss: 1792.3352\n",
      "Epoch 510/1000 | Batch 100/237 | Loss: 4974.6680\n",
      "Epoch 510/1000 | Batch 200/237 | Loss: 933.8162\n",
      "Epoch 510/1000 complete | Avg Loss: 4640.3804\n",
      "Epoch 511/1000 | Batch 0/237 | Loss: 3895.4561\n",
      "Epoch 511/1000 | Batch 100/237 | Loss: 1249.8936\n",
      "Epoch 511/1000 | Batch 200/237 | Loss: 1906.1925\n",
      "Epoch 511/1000 complete | Avg Loss: 4621.6950\n",
      "Epoch 512/1000 | Batch 0/237 | Loss: 5958.2690\n",
      "Epoch 512/1000 | Batch 100/237 | Loss: 841.0911\n",
      "Epoch 512/1000 | Batch 200/237 | Loss: 2701.5725\n",
      "Epoch 512/1000 complete | Avg Loss: 4652.1381\n",
      "Epoch 513/1000 | Batch 0/237 | Loss: 1054.5035\n",
      "Epoch 513/1000 | Batch 100/237 | Loss: 1093.0090\n",
      "Epoch 513/1000 | Batch 200/237 | Loss: 1301.1854\n",
      "Epoch 513/1000 complete | Avg Loss: 4632.3442\n",
      "Epoch 514/1000 | Batch 0/237 | Loss: 2097.6638\n",
      "Epoch 514/1000 | Batch 100/237 | Loss: 10192.4678\n",
      "Epoch 514/1000 | Batch 200/237 | Loss: 2994.4141\n",
      "Epoch 514/1000 complete | Avg Loss: 4653.2893\n",
      "Epoch 515/1000 | Batch 0/237 | Loss: 4964.0469\n",
      "Epoch 515/1000 | Batch 100/237 | Loss: 1059.1432\n",
      "Epoch 515/1000 | Batch 200/237 | Loss: 1698.3718\n",
      "Epoch 515/1000 complete | Avg Loss: 4627.7519\n",
      "Epoch 516/1000 | Batch 0/237 | Loss: 866.0630\n",
      "Epoch 516/1000 | Batch 100/237 | Loss: 6478.7173\n",
      "Epoch 516/1000 | Batch 200/237 | Loss: 769.6746\n",
      "Epoch 516/1000 complete | Avg Loss: 4629.2952\n",
      "Epoch 517/1000 | Batch 0/237 | Loss: 2456.8459\n",
      "Epoch 517/1000 | Batch 100/237 | Loss: 870.1024\n",
      "Epoch 517/1000 | Batch 200/237 | Loss: 1199.0299\n",
      "Epoch 517/1000 complete | Avg Loss: 4622.5397\n",
      "Epoch 518/1000 | Batch 0/237 | Loss: 1399.4996\n",
      "Epoch 518/1000 | Batch 100/237 | Loss: 2455.5657\n",
      "Epoch 518/1000 | Batch 200/237 | Loss: 8920.6826\n",
      "Epoch 518/1000 complete | Avg Loss: 4626.0507\n",
      "Epoch 519/1000 | Batch 0/237 | Loss: 7788.6807\n",
      "Epoch 519/1000 | Batch 100/237 | Loss: 8660.7061\n",
      "Epoch 519/1000 | Batch 200/237 | Loss: 2200.2161\n",
      "Epoch 519/1000 complete | Avg Loss: 4660.0844\n",
      "Epoch 520/1000 | Batch 0/237 | Loss: 12145.8828\n",
      "Epoch 520/1000 | Batch 100/237 | Loss: 4699.9946\n",
      "Epoch 520/1000 | Batch 200/237 | Loss: 1872.5736\n",
      "Epoch 520/1000 complete | Avg Loss: 4623.7994\n",
      "Epoch 521/1000 | Batch 0/237 | Loss: 2029.3889\n",
      "Epoch 521/1000 | Batch 100/237 | Loss: 438.1868\n",
      "Epoch 521/1000 | Batch 200/237 | Loss: 4428.8789\n",
      "Epoch 521/1000 complete | Avg Loss: 4633.9798\n",
      "Epoch 522/1000 | Batch 0/237 | Loss: 13148.7188\n",
      "Epoch 522/1000 | Batch 100/237 | Loss: 1642.0127\n",
      "Epoch 522/1000 | Batch 200/237 | Loss: 1460.0493\n",
      "Epoch 522/1000 complete | Avg Loss: 4706.3431\n",
      "Epoch 523/1000 | Batch 0/237 | Loss: 18915.5566\n",
      "Epoch 523/1000 | Batch 100/237 | Loss: 2208.5591\n",
      "Epoch 523/1000 | Batch 200/237 | Loss: 3966.9609\n",
      "Epoch 523/1000 complete | Avg Loss: 4626.6451\n",
      "Epoch 524/1000 | Batch 0/237 | Loss: 2777.8381\n",
      "Epoch 524/1000 | Batch 100/237 | Loss: 26063.5078\n",
      "Epoch 524/1000 | Batch 200/237 | Loss: 5523.7686\n",
      "Epoch 524/1000 complete | Avg Loss: 4626.4980\n",
      "Epoch 525/1000 | Batch 0/237 | Loss: 3111.7375\n",
      "Epoch 525/1000 | Batch 100/237 | Loss: 2377.6643\n",
      "Epoch 525/1000 | Batch 200/237 | Loss: 6541.4844\n",
      "Epoch 525/1000 complete | Avg Loss: 4626.7847\n",
      "Epoch 526/1000 | Batch 0/237 | Loss: 10057.6865\n",
      "Epoch 526/1000 | Batch 100/237 | Loss: 1521.2026\n",
      "Epoch 526/1000 | Batch 200/237 | Loss: 1852.5120\n",
      "Epoch 526/1000 complete | Avg Loss: 4628.5989\n",
      "Epoch 527/1000 | Batch 0/237 | Loss: 1354.0015\n",
      "Epoch 527/1000 | Batch 100/237 | Loss: 1981.1692\n",
      "Epoch 527/1000 | Batch 200/237 | Loss: 2651.6782\n",
      "Epoch 527/1000 complete | Avg Loss: 4622.0424\n",
      "Epoch 528/1000 | Batch 0/237 | Loss: 1558.3029\n",
      "Epoch 528/1000 | Batch 100/237 | Loss: 4017.0225\n",
      "Epoch 528/1000 | Batch 200/237 | Loss: 6988.8369\n",
      "Epoch 528/1000 complete | Avg Loss: 4622.2308\n",
      "Epoch 529/1000 | Batch 0/237 | Loss: 7878.9375\n",
      "Epoch 529/1000 | Batch 100/237 | Loss: 3237.8582\n",
      "Epoch 529/1000 | Batch 200/237 | Loss: 10841.8428\n",
      "Epoch 529/1000 complete | Avg Loss: 4618.9964\n",
      "Epoch 530/1000 | Batch 0/237 | Loss: 1619.8154\n",
      "Epoch 530/1000 | Batch 100/237 | Loss: 1218.2367\n",
      "Epoch 530/1000 | Batch 200/237 | Loss: 4399.3657\n",
      "Epoch 530/1000 complete | Avg Loss: 4620.3479\n",
      "Epoch 531/1000 | Batch 0/237 | Loss: 2064.7903\n",
      "Epoch 531/1000 | Batch 100/237 | Loss: 9024.9375\n",
      "Epoch 531/1000 | Batch 200/237 | Loss: 2769.0312\n",
      "Epoch 531/1000 complete | Avg Loss: 4617.8579\n",
      "Epoch 532/1000 | Batch 0/237 | Loss: 10476.1035\n",
      "Epoch 532/1000 | Batch 100/237 | Loss: 3590.6504\n",
      "Epoch 532/1000 | Batch 200/237 | Loss: 3795.5576\n",
      "Epoch 532/1000 complete | Avg Loss: 4612.7084\n",
      "Epoch 533/1000 | Batch 0/237 | Loss: 1044.2257\n",
      "Epoch 533/1000 | Batch 100/237 | Loss: 24539.4805\n",
      "Epoch 533/1000 | Batch 200/237 | Loss: 869.5203\n",
      "Epoch 533/1000 complete | Avg Loss: 4686.2308\n",
      "Epoch 534/1000 | Batch 0/237 | Loss: 6546.4229\n",
      "Epoch 534/1000 | Batch 100/237 | Loss: 3144.7231\n",
      "Epoch 534/1000 | Batch 200/237 | Loss: 9159.8066\n",
      "Epoch 534/1000 complete | Avg Loss: 4618.2238\n",
      "Epoch 535/1000 | Batch 0/237 | Loss: 3601.8022\n",
      "Epoch 535/1000 | Batch 100/237 | Loss: 802.6149\n",
      "Epoch 535/1000 | Batch 200/237 | Loss: 3848.8767\n",
      "Epoch 535/1000 complete | Avg Loss: 4613.9127\n",
      "Epoch 536/1000 | Batch 0/237 | Loss: 848.3615\n",
      "Epoch 536/1000 | Batch 100/237 | Loss: 5301.5610\n",
      "Epoch 536/1000 | Batch 200/237 | Loss: 20086.1328\n",
      "Epoch 536/1000 complete | Avg Loss: 4617.3561\n",
      "Epoch 537/1000 | Batch 0/237 | Loss: 2894.4009\n",
      "Epoch 537/1000 | Batch 100/237 | Loss: 6969.9575\n",
      "Epoch 537/1000 | Batch 200/237 | Loss: 1914.1577\n",
      "Epoch 537/1000 complete | Avg Loss: 4652.6088\n",
      "Epoch 538/1000 | Batch 0/237 | Loss: 2042.4009\n",
      "Epoch 538/1000 | Batch 100/237 | Loss: 3389.5217\n",
      "Epoch 538/1000 | Batch 200/237 | Loss: 3274.7383\n",
      "Epoch 538/1000 complete | Avg Loss: 4624.9728\n",
      "Epoch 539/1000 | Batch 0/237 | Loss: 3138.6013\n",
      "Epoch 539/1000 | Batch 100/237 | Loss: 6109.6904\n",
      "Epoch 539/1000 | Batch 200/237 | Loss: 1139.1689\n",
      "Epoch 539/1000 complete | Avg Loss: 4614.4444\n",
      "Epoch 540/1000 | Batch 0/237 | Loss: 1534.3792\n",
      "Epoch 540/1000 | Batch 100/237 | Loss: 1990.0774\n",
      "Epoch 540/1000 | Batch 200/237 | Loss: 7996.7002\n",
      "Epoch 540/1000 complete | Avg Loss: 4616.3079\n",
      "Epoch 541/1000 | Batch 0/237 | Loss: 3300.2573\n",
      "Epoch 541/1000 | Batch 100/237 | Loss: 4470.9326\n",
      "Epoch 541/1000 | Batch 200/237 | Loss: 9208.4629\n",
      "Epoch 541/1000 complete | Avg Loss: 4620.4840\n",
      "Epoch 542/1000 | Batch 0/237 | Loss: 554.8879\n",
      "Epoch 542/1000 | Batch 100/237 | Loss: 944.7900\n",
      "Epoch 542/1000 | Batch 200/237 | Loss: 4010.6968\n",
      "Epoch 542/1000 complete | Avg Loss: 4615.8879\n",
      "Epoch 543/1000 | Batch 0/237 | Loss: 1013.0354\n",
      "Epoch 543/1000 | Batch 100/237 | Loss: 989.7699\n",
      "Epoch 543/1000 | Batch 200/237 | Loss: 1501.3287\n",
      "Epoch 543/1000 complete | Avg Loss: 4610.8008\n",
      "Epoch 544/1000 | Batch 0/237 | Loss: 8251.9678\n",
      "Epoch 544/1000 | Batch 100/237 | Loss: 5518.0425\n",
      "Epoch 544/1000 | Batch 200/237 | Loss: 16655.1836\n",
      "Epoch 544/1000 complete | Avg Loss: 4612.0079\n",
      "Epoch 545/1000 | Batch 0/237 | Loss: 3162.5474\n",
      "Epoch 545/1000 | Batch 100/237 | Loss: 1458.7504\n",
      "Epoch 545/1000 | Batch 200/237 | Loss: 1379.5447\n",
      "Epoch 545/1000 complete | Avg Loss: 4611.7225\n",
      "Epoch 546/1000 | Batch 0/237 | Loss: 1725.0507\n",
      "Epoch 546/1000 | Batch 100/237 | Loss: 3247.7524\n",
      "Epoch 546/1000 | Batch 200/237 | Loss: 1871.6361\n",
      "Epoch 546/1000 complete | Avg Loss: 4612.4827\n",
      "Epoch 547/1000 | Batch 0/237 | Loss: 924.9910\n",
      "Epoch 547/1000 | Batch 100/237 | Loss: 2060.6711\n",
      "Epoch 547/1000 | Batch 200/237 | Loss: 635.2358\n",
      "Epoch 547/1000 complete | Avg Loss: 4613.2815\n",
      "Epoch 548/1000 | Batch 0/237 | Loss: 2996.3167\n",
      "Epoch 548/1000 | Batch 100/237 | Loss: 1771.1425\n",
      "Epoch 548/1000 | Batch 200/237 | Loss: 10658.1123\n",
      "Epoch 548/1000 complete | Avg Loss: 4625.7554\n",
      "Epoch 549/1000 | Batch 0/237 | Loss: 1418.7089\n",
      "Epoch 549/1000 | Batch 100/237 | Loss: 5049.7334\n",
      "Epoch 549/1000 | Batch 200/237 | Loss: 6726.3672\n",
      "Epoch 549/1000 complete | Avg Loss: 4621.1254\n",
      "Epoch 550/1000 | Batch 0/237 | Loss: 1770.7990\n",
      "Epoch 550/1000 | Batch 100/237 | Loss: 1324.3572\n",
      "Epoch 550/1000 | Batch 200/237 | Loss: 802.0585\n",
      "Epoch 550/1000 complete | Avg Loss: 4617.1298\n",
      "Epoch 551/1000 | Batch 0/237 | Loss: 3355.8220\n",
      "Epoch 551/1000 | Batch 100/237 | Loss: 844.4803\n",
      "Epoch 551/1000 | Batch 200/237 | Loss: 803.4901\n",
      "Epoch 551/1000 complete | Avg Loss: 4607.2079\n",
      "Epoch 552/1000 | Batch 0/237 | Loss: 485.4474\n",
      "Epoch 552/1000 | Batch 100/237 | Loss: 593.9396\n",
      "Epoch 552/1000 | Batch 200/237 | Loss: 8374.3691\n",
      "Epoch 552/1000 complete | Avg Loss: 4608.9369\n",
      "Epoch 553/1000 | Batch 0/237 | Loss: 3074.5024\n",
      "Epoch 553/1000 | Batch 100/237 | Loss: 990.3083\n",
      "Epoch 553/1000 | Batch 200/237 | Loss: 1582.6770\n",
      "Epoch 553/1000 complete | Avg Loss: 4615.1587\n",
      "Epoch 554/1000 | Batch 0/237 | Loss: 2930.6035\n",
      "Epoch 554/1000 | Batch 100/237 | Loss: 12606.4062\n",
      "Epoch 554/1000 | Batch 200/237 | Loss: 1013.1387\n",
      "Epoch 554/1000 complete | Avg Loss: 4662.0350\n",
      "Epoch 555/1000 | Batch 0/237 | Loss: 2018.3767\n",
      "Epoch 555/1000 | Batch 100/237 | Loss: 1611.4326\n",
      "Epoch 555/1000 | Batch 200/237 | Loss: 4974.2998\n",
      "Epoch 555/1000 complete | Avg Loss: 4637.1598\n",
      "Epoch 556/1000 | Batch 0/237 | Loss: 9412.1943\n",
      "Epoch 556/1000 | Batch 100/237 | Loss: 14512.9824\n",
      "Epoch 556/1000 | Batch 200/237 | Loss: 1115.3105\n",
      "Epoch 556/1000 complete | Avg Loss: 4613.6172\n",
      "Epoch 557/1000 | Batch 0/237 | Loss: 2321.7747\n",
      "Epoch 557/1000 | Batch 100/237 | Loss: 10892.7109\n",
      "Epoch 557/1000 | Batch 200/237 | Loss: 20702.6484\n",
      "Epoch 557/1000 complete | Avg Loss: 4613.6406\n",
      "Epoch 558/1000 | Batch 0/237 | Loss: 957.0557\n",
      "Epoch 558/1000 | Batch 100/237 | Loss: 1162.8993\n",
      "Epoch 558/1000 | Batch 200/237 | Loss: 1690.1614\n",
      "Epoch 558/1000 complete | Avg Loss: 4602.9788\n",
      "Epoch 559/1000 | Batch 0/237 | Loss: 1133.2585\n",
      "Epoch 559/1000 | Batch 100/237 | Loss: 1052.2739\n",
      "Epoch 559/1000 | Batch 200/237 | Loss: 1601.3160\n",
      "Epoch 559/1000 complete | Avg Loss: 4662.3722\n",
      "Epoch 560/1000 | Batch 0/237 | Loss: 35008.3203\n",
      "Epoch 560/1000 | Batch 100/237 | Loss: 593.6131\n",
      "Epoch 560/1000 | Batch 200/237 | Loss: 2934.2727\n",
      "Epoch 560/1000 complete | Avg Loss: 4612.8251\n",
      "Epoch 561/1000 | Batch 0/237 | Loss: 1052.3335\n",
      "Epoch 561/1000 | Batch 100/237 | Loss: 490.4820\n",
      "Epoch 561/1000 | Batch 200/237 | Loss: 1748.1233\n",
      "Epoch 561/1000 complete | Avg Loss: 4609.5428\n",
      "Epoch 562/1000 | Batch 0/237 | Loss: 36140.2500\n",
      "Epoch 562/1000 | Batch 100/237 | Loss: 4295.5669\n",
      "Epoch 562/1000 | Batch 200/237 | Loss: 4771.9917\n",
      "Epoch 562/1000 complete | Avg Loss: 4605.7809\n",
      "Epoch 563/1000 | Batch 0/237 | Loss: 1842.3436\n",
      "Epoch 563/1000 | Batch 100/237 | Loss: 2010.2943\n",
      "Epoch 563/1000 | Batch 200/237 | Loss: 1083.5178\n",
      "Epoch 563/1000 complete | Avg Loss: 4609.7874\n",
      "Epoch 564/1000 | Batch 0/237 | Loss: 1345.4807\n",
      "Epoch 564/1000 | Batch 100/237 | Loss: 2379.5679\n",
      "Epoch 564/1000 | Batch 200/237 | Loss: 4385.4375\n",
      "Epoch 564/1000 complete | Avg Loss: 4606.2797\n",
      "Epoch 565/1000 | Batch 0/237 | Loss: 3859.6755\n",
      "Epoch 565/1000 | Batch 100/237 | Loss: 3527.7117\n",
      "Epoch 565/1000 | Batch 200/237 | Loss: 784.4061\n",
      "Epoch 565/1000 complete | Avg Loss: 4599.9549\n",
      "Epoch 566/1000 | Batch 0/237 | Loss: 1461.9130\n",
      "Epoch 566/1000 | Batch 100/237 | Loss: 4806.6851\n",
      "Epoch 566/1000 | Batch 200/237 | Loss: 1586.7136\n",
      "Epoch 566/1000 complete | Avg Loss: 4603.0757\n",
      "Epoch 567/1000 | Batch 0/237 | Loss: 6066.9946\n",
      "Epoch 567/1000 | Batch 100/237 | Loss: 822.4233\n",
      "Epoch 567/1000 | Batch 200/237 | Loss: 1294.7036\n",
      "Epoch 567/1000 complete | Avg Loss: 4607.5679\n",
      "Epoch 568/1000 | Batch 0/237 | Loss: 650.9536\n",
      "Epoch 568/1000 | Batch 100/237 | Loss: 3479.6726\n",
      "Epoch 568/1000 | Batch 200/237 | Loss: 6089.9292\n",
      "Epoch 568/1000 complete | Avg Loss: 4600.7935\n",
      "Epoch 569/1000 | Batch 0/237 | Loss: 29544.4727\n",
      "Epoch 569/1000 | Batch 100/237 | Loss: 1610.6970\n",
      "Epoch 569/1000 | Batch 200/237 | Loss: 984.3132\n",
      "Epoch 569/1000 complete | Avg Loss: 4598.7727\n",
      "Epoch 570/1000 | Batch 0/237 | Loss: 3443.9094\n",
      "Epoch 570/1000 | Batch 100/237 | Loss: 2829.8516\n",
      "Epoch 570/1000 | Batch 200/237 | Loss: 2215.2480\n",
      "Epoch 570/1000 complete | Avg Loss: 4610.3304\n",
      "Epoch 571/1000 | Batch 0/237 | Loss: 3603.6313\n",
      "Epoch 571/1000 | Batch 100/237 | Loss: 23922.2500\n",
      "Epoch 571/1000 | Batch 200/237 | Loss: 9568.7061\n",
      "Epoch 571/1000 complete | Avg Loss: 4601.2750\n",
      "Epoch 572/1000 | Batch 0/237 | Loss: 763.4285\n",
      "Epoch 572/1000 | Batch 100/237 | Loss: 2664.6443\n",
      "Epoch 572/1000 | Batch 200/237 | Loss: 2184.0647\n",
      "Epoch 572/1000 complete | Avg Loss: 4600.5972\n",
      "Epoch 573/1000 | Batch 0/237 | Loss: 5056.9482\n",
      "Epoch 573/1000 | Batch 100/237 | Loss: 5081.6094\n",
      "Epoch 573/1000 | Batch 200/237 | Loss: 1567.3003\n",
      "Epoch 573/1000 complete | Avg Loss: 4603.1107\n",
      "Epoch 574/1000 | Batch 0/237 | Loss: 877.6079\n",
      "Epoch 574/1000 | Batch 100/237 | Loss: 19176.4062\n",
      "Epoch 574/1000 | Batch 200/237 | Loss: 2037.5121\n",
      "Epoch 574/1000 complete | Avg Loss: 4616.6611\n",
      "Epoch 575/1000 | Batch 0/237 | Loss: 652.5146\n",
      "Epoch 575/1000 | Batch 100/237 | Loss: 4118.8774\n",
      "Epoch 575/1000 | Batch 200/237 | Loss: 8083.0835\n",
      "Epoch 575/1000 complete | Avg Loss: 4600.6485\n",
      "Epoch 576/1000 | Batch 0/237 | Loss: 1627.8279\n",
      "Epoch 576/1000 | Batch 100/237 | Loss: 6096.4370\n",
      "Epoch 576/1000 | Batch 200/237 | Loss: 2394.5615\n",
      "Epoch 576/1000 complete | Avg Loss: 4622.2291\n",
      "Epoch 577/1000 | Batch 0/237 | Loss: 1219.4019\n",
      "Epoch 577/1000 | Batch 100/237 | Loss: 2456.9500\n",
      "Epoch 577/1000 | Batch 200/237 | Loss: 735.7389\n",
      "Epoch 577/1000 complete | Avg Loss: 4602.5256\n",
      "Epoch 578/1000 | Batch 0/237 | Loss: 1684.5974\n",
      "Epoch 578/1000 | Batch 100/237 | Loss: 3079.7544\n",
      "Epoch 578/1000 | Batch 200/237 | Loss: 3074.4846\n",
      "Epoch 578/1000 complete | Avg Loss: 4694.2649\n",
      "Epoch 579/1000 | Batch 0/237 | Loss: 3567.8154\n",
      "Epoch 579/1000 | Batch 100/237 | Loss: 3761.4578\n",
      "Epoch 579/1000 | Batch 200/237 | Loss: 3622.0105\n",
      "Epoch 579/1000 complete | Avg Loss: 4606.0704\n",
      "Epoch 580/1000 | Batch 0/237 | Loss: 920.8469\n",
      "Epoch 580/1000 | Batch 100/237 | Loss: 4387.8398\n",
      "Epoch 580/1000 | Batch 200/237 | Loss: 6206.0342\n",
      "Epoch 580/1000 complete | Avg Loss: 4608.6805\n",
      "Epoch 581/1000 | Batch 0/237 | Loss: 665.7684\n",
      "Epoch 581/1000 | Batch 100/237 | Loss: 831.5903\n",
      "Epoch 581/1000 | Batch 200/237 | Loss: 856.4878\n",
      "Epoch 581/1000 complete | Avg Loss: 4602.2946\n",
      "Epoch 582/1000 | Batch 0/237 | Loss: 7353.2959\n",
      "Epoch 582/1000 | Batch 100/237 | Loss: 2747.5139\n",
      "Epoch 582/1000 | Batch 200/237 | Loss: 4962.1777\n",
      "Epoch 582/1000 complete | Avg Loss: 4599.8544\n",
      "Epoch 583/1000 | Batch 0/237 | Loss: 3078.9097\n",
      "Epoch 583/1000 | Batch 100/237 | Loss: 1272.4315\n",
      "Epoch 583/1000 | Batch 200/237 | Loss: 8504.4170\n",
      "Epoch 583/1000 complete | Avg Loss: 4598.3447\n",
      "Epoch 584/1000 | Batch 0/237 | Loss: 6565.3286\n",
      "Epoch 584/1000 | Batch 100/237 | Loss: 2281.9314\n",
      "Epoch 584/1000 | Batch 200/237 | Loss: 13044.0068\n",
      "Epoch 584/1000 complete | Avg Loss: 4597.3433\n",
      "Epoch 585/1000 | Batch 0/237 | Loss: 2556.5833\n",
      "Epoch 585/1000 | Batch 100/237 | Loss: 9031.0430\n",
      "Epoch 585/1000 | Batch 200/237 | Loss: 23946.7617\n",
      "Epoch 585/1000 complete | Avg Loss: 4595.9775\n",
      "Epoch 586/1000 | Batch 0/237 | Loss: 741.3047\n",
      "Epoch 586/1000 | Batch 100/237 | Loss: 6898.7266\n",
      "Epoch 586/1000 | Batch 200/237 | Loss: 4405.9961\n",
      "Epoch 586/1000 complete | Avg Loss: 4595.7931\n",
      "Epoch 587/1000 | Batch 0/237 | Loss: 3762.7944\n",
      "Epoch 587/1000 | Batch 100/237 | Loss: 1925.6510\n",
      "Epoch 587/1000 | Batch 200/237 | Loss: 480.3401\n",
      "Epoch 587/1000 complete | Avg Loss: 4591.1766\n",
      "Epoch 588/1000 | Batch 0/237 | Loss: 3388.8242\n",
      "Epoch 588/1000 | Batch 100/237 | Loss: 6674.1177\n",
      "Epoch 588/1000 | Batch 200/237 | Loss: 820.7079\n",
      "Epoch 588/1000 complete | Avg Loss: 4597.7763\n",
      "Epoch 589/1000 | Batch 0/237 | Loss: 1193.6721\n",
      "Epoch 589/1000 | Batch 100/237 | Loss: 1388.9890\n",
      "Epoch 589/1000 | Batch 200/237 | Loss: 913.0048\n",
      "Epoch 589/1000 complete | Avg Loss: 4595.9345\n",
      "Epoch 590/1000 | Batch 0/237 | Loss: 742.7221\n",
      "Epoch 590/1000 | Batch 100/237 | Loss: 1098.6809\n",
      "Epoch 590/1000 | Batch 200/237 | Loss: 6399.9111\n",
      "Epoch 590/1000 complete | Avg Loss: 4595.0056\n",
      "Epoch 591/1000 | Batch 0/237 | Loss: 471.0086\n",
      "Epoch 591/1000 | Batch 100/237 | Loss: 2183.3335\n",
      "Epoch 591/1000 | Batch 200/237 | Loss: 17777.6758\n",
      "Epoch 591/1000 complete | Avg Loss: 4588.4159\n",
      "Epoch 592/1000 | Batch 0/237 | Loss: 3419.0281\n",
      "Epoch 592/1000 | Batch 100/237 | Loss: 4077.4175\n",
      "Epoch 592/1000 | Batch 200/237 | Loss: 2924.4229\n",
      "Epoch 592/1000 complete | Avg Loss: 4594.0048\n",
      "Epoch 593/1000 | Batch 0/237 | Loss: 1640.8342\n",
      "Epoch 593/1000 | Batch 100/237 | Loss: 2232.0591\n",
      "Epoch 593/1000 | Batch 200/237 | Loss: 2523.1128\n",
      "Epoch 593/1000 complete | Avg Loss: 4595.8356\n",
      "Epoch 594/1000 | Batch 0/237 | Loss: 2086.1953\n",
      "Epoch 594/1000 | Batch 100/237 | Loss: 738.6106\n",
      "Epoch 594/1000 | Batch 200/237 | Loss: 1310.6343\n",
      "Epoch 594/1000 complete | Avg Loss: 4588.7172\n",
      "Epoch 595/1000 | Batch 0/237 | Loss: 1491.7639\n",
      "Epoch 595/1000 | Batch 100/237 | Loss: 2280.1416\n",
      "Epoch 595/1000 | Batch 200/237 | Loss: 3458.5901\n",
      "Epoch 595/1000 complete | Avg Loss: 4598.0432\n",
      "Epoch 596/1000 | Batch 0/237 | Loss: 3244.7417\n",
      "Epoch 596/1000 | Batch 100/237 | Loss: 33474.7070\n",
      "Epoch 596/1000 | Batch 200/237 | Loss: 1443.4717\n",
      "Epoch 596/1000 complete | Avg Loss: 4589.6676\n",
      "Epoch 597/1000 | Batch 0/237 | Loss: 2252.9619\n",
      "Epoch 597/1000 | Batch 100/237 | Loss: 2045.3975\n",
      "Epoch 597/1000 | Batch 200/237 | Loss: 1783.7850\n",
      "Epoch 597/1000 complete | Avg Loss: 4599.4034\n",
      "Epoch 598/1000 | Batch 0/237 | Loss: 1699.0911\n",
      "Epoch 598/1000 | Batch 100/237 | Loss: 3204.0891\n",
      "Epoch 598/1000 | Batch 200/237 | Loss: 675.3807\n",
      "Epoch 598/1000 complete | Avg Loss: 4593.8460\n",
      "Epoch 599/1000 | Batch 0/237 | Loss: 5301.9492\n",
      "Epoch 599/1000 | Batch 100/237 | Loss: 798.7009\n",
      "Epoch 599/1000 | Batch 200/237 | Loss: 8706.2627\n",
      "Epoch 599/1000 complete | Avg Loss: 4591.0404\n",
      "Epoch 600/1000 | Batch 0/237 | Loss: 40928.0078\n",
      "Epoch 600/1000 | Batch 100/237 | Loss: 1142.5481\n",
      "Epoch 600/1000 | Batch 200/237 | Loss: 1015.3898\n",
      "Epoch 600/1000 complete | Avg Loss: 4592.6747\n",
      "Epoch 601/1000 | Batch 0/237 | Loss: 1642.6890\n",
      "Epoch 601/1000 | Batch 100/237 | Loss: 1887.4850\n",
      "Epoch 601/1000 | Batch 200/237 | Loss: 7904.6509\n",
      "Epoch 601/1000 complete | Avg Loss: 4582.9967\n",
      "Epoch 602/1000 | Batch 0/237 | Loss: 1172.5479\n",
      "Epoch 602/1000 | Batch 100/237 | Loss: 2579.4871\n",
      "Epoch 602/1000 | Batch 200/237 | Loss: 9882.5713\n",
      "Epoch 602/1000 complete | Avg Loss: 4609.3073\n",
      "Epoch 603/1000 | Batch 0/237 | Loss: 12460.6523\n",
      "Epoch 603/1000 | Batch 100/237 | Loss: 31228.2266\n",
      "Epoch 603/1000 | Batch 200/237 | Loss: 1733.0945\n",
      "Epoch 603/1000 complete | Avg Loss: 4586.7788\n",
      "Epoch 604/1000 | Batch 0/237 | Loss: 654.6658\n",
      "Epoch 604/1000 | Batch 100/237 | Loss: 2765.8035\n",
      "Epoch 604/1000 | Batch 200/237 | Loss: 1738.2887\n",
      "Epoch 604/1000 complete | Avg Loss: 4585.7030\n",
      "Epoch 605/1000 | Batch 0/237 | Loss: 4027.2979\n",
      "Epoch 605/1000 | Batch 100/237 | Loss: 9777.7930\n",
      "Epoch 605/1000 | Batch 200/237 | Loss: 2582.7207\n",
      "Epoch 605/1000 complete | Avg Loss: 4590.4705\n",
      "Epoch 606/1000 | Batch 0/237 | Loss: 1328.6525\n",
      "Epoch 606/1000 | Batch 100/237 | Loss: 886.5520\n",
      "Epoch 606/1000 | Batch 200/237 | Loss: 644.4568\n",
      "Epoch 606/1000 complete | Avg Loss: 4582.4165\n",
      "Epoch 607/1000 | Batch 0/237 | Loss: 873.8596\n",
      "Epoch 607/1000 | Batch 100/237 | Loss: 1184.3071\n",
      "Epoch 607/1000 | Batch 200/237 | Loss: 4541.8853\n",
      "Epoch 607/1000 complete | Avg Loss: 4600.9927\n",
      "Epoch 608/1000 | Batch 0/237 | Loss: 1781.9226\n",
      "Epoch 608/1000 | Batch 100/237 | Loss: 1208.1865\n",
      "Epoch 608/1000 | Batch 200/237 | Loss: 6892.9917\n",
      "Epoch 608/1000 complete | Avg Loss: 4584.2044\n",
      "Epoch 609/1000 | Batch 0/237 | Loss: 710.6754\n",
      "Epoch 609/1000 | Batch 100/237 | Loss: 29060.2461\n",
      "Epoch 609/1000 | Batch 200/237 | Loss: 2016.4248\n",
      "Epoch 609/1000 complete | Avg Loss: 4588.9906\n",
      "Epoch 610/1000 | Batch 0/237 | Loss: 1290.8611\n",
      "Epoch 610/1000 | Batch 100/237 | Loss: 2094.3374\n",
      "Epoch 610/1000 | Batch 200/237 | Loss: 4619.8330\n",
      "Epoch 610/1000 complete | Avg Loss: 4585.3337\n",
      "Epoch 611/1000 | Batch 0/237 | Loss: 2323.4119\n",
      "Epoch 611/1000 | Batch 100/237 | Loss: 1077.5820\n",
      "Epoch 611/1000 | Batch 200/237 | Loss: 3654.8274\n",
      "Epoch 611/1000 complete | Avg Loss: 4581.5729\n",
      "Epoch 612/1000 | Batch 0/237 | Loss: 12299.0195\n",
      "Epoch 612/1000 | Batch 100/237 | Loss: 1220.5944\n",
      "Epoch 612/1000 | Batch 200/237 | Loss: 12491.2070\n",
      "Epoch 612/1000 complete | Avg Loss: 4579.0364\n",
      "Epoch 613/1000 | Batch 0/237 | Loss: 2807.2549\n",
      "Epoch 613/1000 | Batch 100/237 | Loss: 850.8092\n",
      "Epoch 613/1000 | Batch 200/237 | Loss: 714.7126\n",
      "Epoch 613/1000 complete | Avg Loss: 4584.1507\n",
      "Epoch 614/1000 | Batch 0/237 | Loss: 2402.3804\n",
      "Epoch 614/1000 | Batch 100/237 | Loss: 1150.2054\n",
      "Epoch 614/1000 | Batch 200/237 | Loss: 1169.8289\n",
      "Epoch 614/1000 complete | Avg Loss: 4573.4190\n",
      "Epoch 615/1000 | Batch 0/237 | Loss: 1565.3695\n",
      "Epoch 615/1000 | Batch 100/237 | Loss: 1984.2219\n",
      "Epoch 615/1000 | Batch 200/237 | Loss: 2533.8071\n",
      "Epoch 615/1000 complete | Avg Loss: 4589.3969\n",
      "Epoch 616/1000 | Batch 0/237 | Loss: 1033.2335\n",
      "Epoch 616/1000 | Batch 100/237 | Loss: 10972.0352\n",
      "Epoch 616/1000 | Batch 200/237 | Loss: 565.2904\n",
      "Epoch 616/1000 complete | Avg Loss: 4579.0286\n",
      "Epoch 617/1000 | Batch 0/237 | Loss: 707.6378\n",
      "Epoch 617/1000 | Batch 100/237 | Loss: 3391.9766\n",
      "Epoch 617/1000 | Batch 200/237 | Loss: 1368.2015\n",
      "Epoch 617/1000 complete | Avg Loss: 4584.6213\n",
      "Epoch 618/1000 | Batch 0/237 | Loss: 17981.1504\n",
      "Epoch 618/1000 | Batch 100/237 | Loss: 14920.7012\n",
      "Epoch 618/1000 | Batch 200/237 | Loss: 3133.7920\n",
      "Epoch 618/1000 complete | Avg Loss: 4587.7557\n",
      "Epoch 619/1000 | Batch 0/237 | Loss: 12427.5820\n",
      "Epoch 619/1000 | Batch 100/237 | Loss: 1324.1982\n",
      "Epoch 619/1000 | Batch 200/237 | Loss: 7751.0283\n",
      "Epoch 619/1000 complete | Avg Loss: 4579.7665\n",
      "Epoch 620/1000 | Batch 0/237 | Loss: 443.6863\n",
      "Epoch 620/1000 | Batch 100/237 | Loss: 745.1000\n",
      "Epoch 620/1000 | Batch 200/237 | Loss: 9250.3350\n",
      "Epoch 620/1000 complete | Avg Loss: 4597.0764\n",
      "Epoch 621/1000 | Batch 0/237 | Loss: 1125.4928\n",
      "Epoch 621/1000 | Batch 100/237 | Loss: 2803.6548\n",
      "Epoch 621/1000 | Batch 200/237 | Loss: 32706.0723\n",
      "Epoch 621/1000 complete | Avg Loss: 4589.3537\n",
      "Epoch 622/1000 | Batch 0/237 | Loss: 2328.4448\n",
      "Epoch 622/1000 | Batch 100/237 | Loss: 10188.5195\n",
      "Epoch 622/1000 | Batch 200/237 | Loss: 1242.6888\n",
      "Epoch 622/1000 complete | Avg Loss: 4696.1980\n",
      "Epoch 623/1000 | Batch 0/237 | Loss: 1771.1520\n",
      "Epoch 623/1000 | Batch 100/237 | Loss: 586.5920\n",
      "Epoch 623/1000 | Batch 200/237 | Loss: 1430.6011\n",
      "Epoch 623/1000 complete | Avg Loss: 4584.9089\n",
      "Epoch 624/1000 | Batch 0/237 | Loss: 3401.1982\n",
      "Epoch 624/1000 | Batch 100/237 | Loss: 1793.4240\n",
      "Epoch 624/1000 | Batch 200/237 | Loss: 2914.2231\n",
      "Epoch 624/1000 complete | Avg Loss: 4574.7783\n",
      "Epoch 625/1000 | Batch 0/237 | Loss: 3380.5425\n",
      "Epoch 625/1000 | Batch 100/237 | Loss: 1705.1611\n",
      "Epoch 625/1000 | Batch 200/237 | Loss: 3667.8723\n",
      "Epoch 625/1000 complete | Avg Loss: 4577.9958\n",
      "Epoch 626/1000 | Batch 0/237 | Loss: 7738.6587\n",
      "Epoch 626/1000 | Batch 100/237 | Loss: 1056.0532\n",
      "Epoch 626/1000 | Batch 200/237 | Loss: 2626.8621\n",
      "Epoch 626/1000 complete | Avg Loss: 4576.2140\n",
      "Epoch 627/1000 | Batch 0/237 | Loss: 6547.9409\n",
      "Epoch 627/1000 | Batch 100/237 | Loss: 1436.9891\n",
      "Epoch 627/1000 | Batch 200/237 | Loss: 858.8412\n",
      "Epoch 627/1000 complete | Avg Loss: 4572.9756\n",
      "Epoch 628/1000 | Batch 0/237 | Loss: 9970.2178\n",
      "Epoch 628/1000 | Batch 100/237 | Loss: 3576.1189\n",
      "Epoch 628/1000 | Batch 200/237 | Loss: 5948.5630\n",
      "Epoch 628/1000 complete | Avg Loss: 4591.3100\n",
      "Epoch 629/1000 | Batch 0/237 | Loss: 4013.4473\n",
      "Epoch 629/1000 | Batch 100/237 | Loss: 1253.6683\n",
      "Epoch 629/1000 | Batch 200/237 | Loss: 9270.5254\n",
      "Epoch 629/1000 complete | Avg Loss: 4578.8993\n",
      "Epoch 630/1000 | Batch 0/237 | Loss: 1211.0717\n",
      "Epoch 630/1000 | Batch 100/237 | Loss: 26983.9180\n",
      "Epoch 630/1000 | Batch 200/237 | Loss: 754.4126\n",
      "Epoch 630/1000 complete | Avg Loss: 4582.9324\n",
      "Epoch 631/1000 | Batch 0/237 | Loss: 1365.0933\n",
      "Epoch 631/1000 | Batch 100/237 | Loss: 2508.9829\n",
      "Epoch 631/1000 | Batch 200/237 | Loss: 8295.0234\n",
      "Epoch 631/1000 complete | Avg Loss: 4572.5220\n",
      "Epoch 632/1000 | Batch 0/237 | Loss: 2925.2505\n",
      "Epoch 632/1000 | Batch 100/237 | Loss: 9853.0078\n",
      "Epoch 632/1000 | Batch 200/237 | Loss: 3802.5081\n",
      "Epoch 632/1000 complete | Avg Loss: 4569.9580\n",
      "Epoch 633/1000 | Batch 0/237 | Loss: 3382.4414\n",
      "Epoch 633/1000 | Batch 100/237 | Loss: 3340.4102\n",
      "Epoch 633/1000 | Batch 200/237 | Loss: 11517.1699\n",
      "Epoch 633/1000 complete | Avg Loss: 4572.5680\n",
      "Epoch 634/1000 | Batch 0/237 | Loss: 3567.4348\n",
      "Epoch 634/1000 | Batch 100/237 | Loss: 1133.3347\n",
      "Epoch 634/1000 | Batch 200/237 | Loss: 1137.2433\n",
      "Epoch 634/1000 complete | Avg Loss: 4575.3247\n",
      "Epoch 635/1000 | Batch 0/237 | Loss: 2112.9131\n",
      "Epoch 635/1000 | Batch 100/237 | Loss: 2273.4375\n",
      "Epoch 635/1000 | Batch 200/237 | Loss: 6645.6519\n",
      "Epoch 635/1000 complete | Avg Loss: 4572.4679\n",
      "Epoch 636/1000 | Batch 0/237 | Loss: 2270.7927\n",
      "Epoch 636/1000 | Batch 100/237 | Loss: 1414.1322\n",
      "Epoch 636/1000 | Batch 200/237 | Loss: 2346.4009\n",
      "Epoch 636/1000 complete | Avg Loss: 4571.3453\n",
      "Epoch 637/1000 | Batch 0/237 | Loss: 4968.1030\n",
      "Epoch 637/1000 | Batch 100/237 | Loss: 2217.6814\n",
      "Epoch 637/1000 | Batch 200/237 | Loss: 3370.3477\n",
      "Epoch 637/1000 complete | Avg Loss: 4619.7105\n",
      "Epoch 638/1000 | Batch 0/237 | Loss: 2391.1309\n",
      "Epoch 638/1000 | Batch 100/237 | Loss: 2178.3184\n",
      "Epoch 638/1000 | Batch 200/237 | Loss: 1094.5253\n",
      "Epoch 638/1000 complete | Avg Loss: 4585.1477\n",
      "Epoch 639/1000 | Batch 0/237 | Loss: 4424.5239\n",
      "Epoch 639/1000 | Batch 100/237 | Loss: 2100.6895\n",
      "Epoch 639/1000 | Batch 200/237 | Loss: 2757.8042\n",
      "Epoch 639/1000 complete | Avg Loss: 4610.1150\n",
      "Epoch 640/1000 | Batch 0/237 | Loss: 910.2424\n",
      "Epoch 640/1000 | Batch 100/237 | Loss: 1246.2909\n",
      "Epoch 640/1000 | Batch 200/237 | Loss: 2600.5532\n",
      "Epoch 640/1000 complete | Avg Loss: 4571.3309\n",
      "Epoch 641/1000 | Batch 0/237 | Loss: 8367.7334\n",
      "Epoch 641/1000 | Batch 100/237 | Loss: 2244.3823\n",
      "Epoch 641/1000 | Batch 200/237 | Loss: 8631.7139\n",
      "Epoch 641/1000 complete | Avg Loss: 4570.5858\n",
      "Epoch 642/1000 | Batch 0/237 | Loss: 5362.1963\n",
      "Epoch 642/1000 | Batch 100/237 | Loss: 4248.2915\n",
      "Epoch 642/1000 | Batch 200/237 | Loss: 3677.0840\n",
      "Epoch 642/1000 complete | Avg Loss: 4563.4943\n",
      "Epoch 643/1000 | Batch 0/237 | Loss: 32905.0273\n",
      "Epoch 643/1000 | Batch 100/237 | Loss: 708.2842\n",
      "Epoch 643/1000 | Batch 200/237 | Loss: 644.2592\n",
      "Epoch 643/1000 complete | Avg Loss: 4566.8322\n",
      "Epoch 644/1000 | Batch 0/237 | Loss: 602.9315\n",
      "Epoch 644/1000 | Batch 100/237 | Loss: 1466.9348\n",
      "Epoch 644/1000 | Batch 200/237 | Loss: 1270.9661\n",
      "Epoch 644/1000 complete | Avg Loss: 4612.6555\n",
      "Epoch 645/1000 | Batch 0/237 | Loss: 1147.4584\n",
      "Epoch 645/1000 | Batch 100/237 | Loss: 8294.1133\n",
      "Epoch 645/1000 | Batch 200/237 | Loss: 45386.7266\n",
      "Epoch 645/1000 complete | Avg Loss: 4567.7106\n",
      "Epoch 646/1000 | Batch 0/237 | Loss: 1569.7009\n",
      "Epoch 646/1000 | Batch 100/237 | Loss: 992.6212\n",
      "Epoch 646/1000 | Batch 200/237 | Loss: 15824.2266\n",
      "Epoch 646/1000 complete | Avg Loss: 4560.4924\n",
      "Epoch 647/1000 | Batch 0/237 | Loss: 1725.5416\n",
      "Epoch 647/1000 | Batch 100/237 | Loss: 4310.8115\n",
      "Epoch 647/1000 | Batch 200/237 | Loss: 3849.5122\n",
      "Epoch 647/1000 complete | Avg Loss: 4604.2260\n",
      "Epoch 648/1000 | Batch 0/237 | Loss: 1233.7354\n",
      "Epoch 648/1000 | Batch 100/237 | Loss: 12964.6289\n",
      "Epoch 648/1000 | Batch 200/237 | Loss: 1223.1357\n",
      "Epoch 648/1000 complete | Avg Loss: 4562.3698\n",
      "Epoch 649/1000 | Batch 0/237 | Loss: 439.6396\n",
      "Epoch 649/1000 | Batch 100/237 | Loss: 8360.4463\n",
      "Epoch 649/1000 | Batch 200/237 | Loss: 3520.4644\n",
      "Epoch 649/1000 complete | Avg Loss: 4571.0233\n",
      "Epoch 650/1000 | Batch 0/237 | Loss: 3755.4136\n",
      "Epoch 650/1000 | Batch 100/237 | Loss: 881.6401\n",
      "Epoch 650/1000 | Batch 200/237 | Loss: 1526.6498\n",
      "Epoch 650/1000 complete | Avg Loss: 4637.6091\n",
      "Epoch 651/1000 | Batch 0/237 | Loss: 1120.6038\n",
      "Epoch 651/1000 | Batch 100/237 | Loss: 857.7743\n",
      "Epoch 651/1000 | Batch 200/237 | Loss: 3983.8816\n",
      "Epoch 651/1000 complete | Avg Loss: 4563.9908\n",
      "Epoch 652/1000 | Batch 0/237 | Loss: 1271.1940\n",
      "Epoch 652/1000 | Batch 100/237 | Loss: 1482.8596\n",
      "Epoch 652/1000 | Batch 200/237 | Loss: 2903.8179\n",
      "Epoch 652/1000 complete | Avg Loss: 4574.1061\n",
      "Epoch 653/1000 | Batch 0/237 | Loss: 2136.8096\n",
      "Epoch 653/1000 | Batch 100/237 | Loss: 1361.5154\n",
      "Epoch 653/1000 | Batch 200/237 | Loss: 1451.6343\n",
      "Epoch 653/1000 complete | Avg Loss: 4562.7255\n",
      "Epoch 654/1000 | Batch 0/237 | Loss: 2310.7136\n",
      "Epoch 654/1000 | Batch 100/237 | Loss: 5314.5195\n",
      "Epoch 654/1000 | Batch 200/237 | Loss: 6957.6240\n",
      "Epoch 654/1000 complete | Avg Loss: 4572.4989\n",
      "Epoch 655/1000 | Batch 0/237 | Loss: 3277.3613\n",
      "Epoch 655/1000 | Batch 100/237 | Loss: 995.2172\n",
      "Epoch 655/1000 | Batch 200/237 | Loss: 19291.8887\n",
      "Epoch 655/1000 complete | Avg Loss: 4565.1449\n",
      "Epoch 656/1000 | Batch 0/237 | Loss: 1016.0009\n",
      "Epoch 656/1000 | Batch 100/237 | Loss: 953.7681\n",
      "Epoch 656/1000 | Batch 200/237 | Loss: 2693.5928\n",
      "Epoch 656/1000 complete | Avg Loss: 4569.5666\n",
      "Epoch 657/1000 | Batch 0/237 | Loss: 593.2460\n",
      "Epoch 657/1000 | Batch 100/237 | Loss: 2217.9585\n",
      "Epoch 657/1000 | Batch 200/237 | Loss: 2773.8374\n",
      "Epoch 657/1000 complete | Avg Loss: 4575.6521\n",
      "Epoch 658/1000 | Batch 0/237 | Loss: 2828.7429\n",
      "Epoch 658/1000 | Batch 100/237 | Loss: 956.2878\n",
      "Epoch 658/1000 | Batch 200/237 | Loss: 2882.1790\n",
      "Epoch 658/1000 complete | Avg Loss: 4563.7412\n",
      "Epoch 659/1000 | Batch 0/237 | Loss: 2943.5413\n",
      "Epoch 659/1000 | Batch 100/237 | Loss: 2453.8359\n",
      "Epoch 659/1000 | Batch 200/237 | Loss: 2346.5542\n",
      "Epoch 659/1000 complete | Avg Loss: 4557.0088\n",
      "Epoch 660/1000 | Batch 0/237 | Loss: 17503.2285\n",
      "Epoch 660/1000 | Batch 100/237 | Loss: 1784.2700\n",
      "Epoch 660/1000 | Batch 200/237 | Loss: 927.7828\n",
      "Epoch 660/1000 complete | Avg Loss: 4558.7479\n",
      "Epoch 661/1000 | Batch 0/237 | Loss: 1590.4839\n",
      "Epoch 661/1000 | Batch 100/237 | Loss: 1045.2102\n",
      "Epoch 661/1000 | Batch 200/237 | Loss: 2722.2466\n",
      "Epoch 661/1000 complete | Avg Loss: 4566.7069\n",
      "Epoch 662/1000 | Batch 0/237 | Loss: 8036.3149\n",
      "Epoch 662/1000 | Batch 100/237 | Loss: 1006.3254\n",
      "Epoch 662/1000 | Batch 200/237 | Loss: 967.3026\n",
      "Epoch 662/1000 complete | Avg Loss: 4562.0864\n",
      "Epoch 663/1000 | Batch 0/237 | Loss: 1395.0557\n",
      "Epoch 663/1000 | Batch 100/237 | Loss: 2058.0417\n",
      "Epoch 663/1000 | Batch 200/237 | Loss: 2871.7827\n",
      "Epoch 663/1000 complete | Avg Loss: 4583.5537\n",
      "Epoch 664/1000 | Batch 0/237 | Loss: 7462.9458\n",
      "Epoch 664/1000 | Batch 100/237 | Loss: 988.3526\n",
      "Epoch 664/1000 | Batch 200/237 | Loss: 1133.2018\n",
      "Epoch 664/1000 complete | Avg Loss: 4565.1468\n",
      "Epoch 665/1000 | Batch 0/237 | Loss: 1189.0303\n",
      "Epoch 665/1000 | Batch 100/237 | Loss: 798.0938\n",
      "Epoch 665/1000 | Batch 200/237 | Loss: 1868.3496\n",
      "Epoch 665/1000 complete | Avg Loss: 4609.6082\n",
      "Epoch 666/1000 | Batch 0/237 | Loss: 919.0959\n",
      "Epoch 666/1000 | Batch 100/237 | Loss: 5129.3457\n",
      "Epoch 666/1000 | Batch 200/237 | Loss: 4037.1809\n",
      "Epoch 666/1000 complete | Avg Loss: 4558.2839\n",
      "Epoch 667/1000 | Batch 0/237 | Loss: 2937.1487\n",
      "Epoch 667/1000 | Batch 100/237 | Loss: 7915.0498\n",
      "Epoch 667/1000 | Batch 200/237 | Loss: 890.7919\n",
      "Epoch 667/1000 complete | Avg Loss: 4557.1292\n",
      "Epoch 668/1000 | Batch 0/237 | Loss: 818.7297\n",
      "Epoch 668/1000 | Batch 100/237 | Loss: 1996.6654\n",
      "Epoch 668/1000 | Batch 200/237 | Loss: 6291.4639\n",
      "Epoch 668/1000 complete | Avg Loss: 4556.5962\n",
      "Epoch 669/1000 | Batch 0/237 | Loss: 2448.0129\n",
      "Epoch 669/1000 | Batch 100/237 | Loss: 1349.0231\n",
      "Epoch 669/1000 | Batch 200/237 | Loss: 722.5102\n",
      "Epoch 669/1000 complete | Avg Loss: 4573.3497\n",
      "Epoch 670/1000 | Batch 0/237 | Loss: 12966.3457\n",
      "Epoch 670/1000 | Batch 100/237 | Loss: 669.7252\n",
      "Epoch 670/1000 | Batch 200/237 | Loss: 2101.9314\n",
      "Epoch 670/1000 complete | Avg Loss: 4560.8277\n",
      "Epoch 671/1000 | Batch 0/237 | Loss: 3941.2407\n",
      "Epoch 671/1000 | Batch 100/237 | Loss: 1015.6144\n",
      "Epoch 671/1000 | Batch 200/237 | Loss: 1916.3330\n",
      "Epoch 671/1000 complete | Avg Loss: 4556.9643\n",
      "Epoch 672/1000 | Batch 0/237 | Loss: 4015.2090\n",
      "Epoch 672/1000 | Batch 100/237 | Loss: 5299.1377\n",
      "Epoch 672/1000 | Batch 200/237 | Loss: 999.9810\n",
      "Epoch 672/1000 complete | Avg Loss: 4552.0729\n",
      "Epoch 673/1000 | Batch 0/237 | Loss: 1385.9940\n",
      "Epoch 673/1000 | Batch 100/237 | Loss: 5292.9766\n",
      "Epoch 673/1000 | Batch 200/237 | Loss: 2001.5973\n",
      "Epoch 673/1000 complete | Avg Loss: 4558.6244\n",
      "Epoch 674/1000 | Batch 0/237 | Loss: 4200.4795\n",
      "Epoch 674/1000 | Batch 100/237 | Loss: 1406.7445\n",
      "Epoch 674/1000 | Batch 200/237 | Loss: 1503.3065\n",
      "Epoch 674/1000 complete | Avg Loss: 4552.6381\n",
      "Epoch 675/1000 | Batch 0/237 | Loss: 1153.1005\n",
      "Epoch 675/1000 | Batch 100/237 | Loss: 1175.3047\n",
      "Epoch 675/1000 | Batch 200/237 | Loss: 850.8462\n",
      "Epoch 675/1000 complete | Avg Loss: 4553.5525\n",
      "Epoch 676/1000 | Batch 0/237 | Loss: 767.4319\n",
      "Epoch 676/1000 | Batch 100/237 | Loss: 2679.1201\n",
      "Epoch 676/1000 | Batch 200/237 | Loss: 3522.1587\n",
      "Epoch 676/1000 complete | Avg Loss: 4554.5758\n",
      "Epoch 677/1000 | Batch 0/237 | Loss: 5541.2524\n",
      "Epoch 677/1000 | Batch 100/237 | Loss: 2975.0181\n",
      "Epoch 677/1000 | Batch 200/237 | Loss: 873.1180\n",
      "Epoch 677/1000 complete | Avg Loss: 4552.4558\n",
      "Epoch 678/1000 | Batch 0/237 | Loss: 3429.2390\n",
      "Epoch 678/1000 | Batch 100/237 | Loss: 3412.8025\n",
      "Epoch 678/1000 | Batch 200/237 | Loss: 662.5161\n",
      "Epoch 678/1000 complete | Avg Loss: 4555.8362\n",
      "Epoch 679/1000 | Batch 0/237 | Loss: 1273.1478\n",
      "Epoch 679/1000 | Batch 100/237 | Loss: 9644.1904\n",
      "Epoch 679/1000 | Batch 200/237 | Loss: 1814.1517\n",
      "Epoch 679/1000 complete | Avg Loss: 4553.6957\n",
      "Epoch 680/1000 | Batch 0/237 | Loss: 4038.5645\n",
      "Epoch 680/1000 | Batch 100/237 | Loss: 1848.0253\n",
      "Epoch 680/1000 | Batch 200/237 | Loss: 2494.3398\n",
      "Epoch 680/1000 complete | Avg Loss: 4553.9286\n",
      "Epoch 681/1000 | Batch 0/237 | Loss: 982.9484\n",
      "Epoch 681/1000 | Batch 100/237 | Loss: 1502.3667\n",
      "Epoch 681/1000 | Batch 200/237 | Loss: 1307.3427\n",
      "Epoch 681/1000 complete | Avg Loss: 4552.2536\n",
      "Epoch 682/1000 | Batch 0/237 | Loss: 990.7964\n",
      "Epoch 682/1000 | Batch 100/237 | Loss: 1224.3943\n",
      "Epoch 682/1000 | Batch 200/237 | Loss: 1497.6011\n",
      "Epoch 682/1000 complete | Avg Loss: 4552.9925\n",
      "Epoch 683/1000 | Batch 0/237 | Loss: 1669.9977\n",
      "Epoch 683/1000 | Batch 100/237 | Loss: 2545.0098\n",
      "Epoch 683/1000 | Batch 200/237 | Loss: 2998.1389\n",
      "Epoch 683/1000 complete | Avg Loss: 4556.4447\n",
      "Epoch 684/1000 | Batch 0/237 | Loss: 23311.7031\n",
      "Epoch 684/1000 | Batch 100/237 | Loss: 2779.8718\n",
      "Epoch 684/1000 | Batch 200/237 | Loss: 2691.7693\n",
      "Epoch 684/1000 complete | Avg Loss: 4579.9889\n",
      "Epoch 685/1000 | Batch 0/237 | Loss: 2634.4668\n",
      "Epoch 685/1000 | Batch 100/237 | Loss: 2144.1096\n",
      "Epoch 685/1000 | Batch 200/237 | Loss: 2063.5437\n",
      "Epoch 685/1000 complete | Avg Loss: 4552.3671\n",
      "Epoch 686/1000 | Batch 0/237 | Loss: 596.8353\n",
      "Epoch 686/1000 | Batch 100/237 | Loss: 1531.6119\n",
      "Epoch 686/1000 | Batch 200/237 | Loss: 13676.6621\n",
      "Epoch 686/1000 complete | Avg Loss: 4551.0470\n",
      "Epoch 687/1000 | Batch 0/237 | Loss: 1639.6024\n",
      "Epoch 687/1000 | Batch 100/237 | Loss: 2497.2881\n",
      "Epoch 687/1000 | Batch 200/237 | Loss: 1511.2859\n",
      "Epoch 687/1000 complete | Avg Loss: 4557.2769\n",
      "Epoch 688/1000 | Batch 0/237 | Loss: 987.4086\n",
      "Epoch 688/1000 | Batch 100/237 | Loss: 653.5730\n",
      "Epoch 688/1000 | Batch 200/237 | Loss: 9208.9307\n",
      "Epoch 688/1000 complete | Avg Loss: 4549.1537\n",
      "Epoch 689/1000 | Batch 0/237 | Loss: 1803.1482\n",
      "Epoch 689/1000 | Batch 100/237 | Loss: 2270.6741\n",
      "Epoch 689/1000 | Batch 200/237 | Loss: 4183.5205\n",
      "Epoch 689/1000 complete | Avg Loss: 4554.0737\n",
      "Epoch 690/1000 | Batch 0/237 | Loss: 2773.8096\n",
      "Epoch 690/1000 | Batch 100/237 | Loss: 2661.4023\n",
      "Epoch 690/1000 | Batch 200/237 | Loss: 8236.2949\n",
      "Epoch 690/1000 complete | Avg Loss: 4547.7539\n",
      "Epoch 691/1000 | Batch 0/237 | Loss: 4838.0430\n",
      "Epoch 691/1000 | Batch 100/237 | Loss: 956.2349\n",
      "Epoch 691/1000 | Batch 200/237 | Loss: 1056.2753\n",
      "Epoch 691/1000 complete | Avg Loss: 4545.3418\n",
      "Epoch 692/1000 | Batch 0/237 | Loss: 1299.6274\n",
      "Epoch 692/1000 | Batch 100/237 | Loss: 1934.8253\n",
      "Epoch 692/1000 | Batch 200/237 | Loss: 3789.9612\n",
      "Epoch 692/1000 complete | Avg Loss: 4558.9315\n",
      "Epoch 693/1000 | Batch 0/237 | Loss: 626.6934\n",
      "Epoch 693/1000 | Batch 100/237 | Loss: 2613.0784\n",
      "Epoch 693/1000 | Batch 200/237 | Loss: 2404.6169\n",
      "Epoch 693/1000 complete | Avg Loss: 4544.5483\n",
      "Epoch 694/1000 | Batch 0/237 | Loss: 3536.3423\n",
      "Epoch 694/1000 | Batch 100/237 | Loss: 860.3057\n",
      "Epoch 694/1000 | Batch 200/237 | Loss: 15813.2227\n",
      "Epoch 694/1000 complete | Avg Loss: 4541.2776\n",
      "Epoch 695/1000 | Batch 0/237 | Loss: 25048.6836\n",
      "Epoch 695/1000 | Batch 100/237 | Loss: 1445.9315\n",
      "Epoch 695/1000 | Batch 200/237 | Loss: 5264.4146\n",
      "Epoch 695/1000 complete | Avg Loss: 4554.3478\n",
      "Epoch 696/1000 | Batch 0/237 | Loss: 5449.8994\n",
      "Epoch 696/1000 | Batch 100/237 | Loss: 892.0217\n",
      "Epoch 696/1000 | Batch 200/237 | Loss: 1099.7615\n",
      "Epoch 696/1000 complete | Avg Loss: 4540.8764\n",
      "Epoch 697/1000 | Batch 0/237 | Loss: 1752.2468\n",
      "Epoch 697/1000 | Batch 100/237 | Loss: 5418.1772\n",
      "Epoch 697/1000 | Batch 200/237 | Loss: 1570.9993\n",
      "Epoch 697/1000 complete | Avg Loss: 4551.3692\n",
      "Epoch 698/1000 | Batch 0/237 | Loss: 589.6348\n",
      "Epoch 698/1000 | Batch 100/237 | Loss: 1193.0055\n",
      "Epoch 698/1000 | Batch 200/237 | Loss: 7139.1362\n",
      "Epoch 698/1000 complete | Avg Loss: 4542.1515\n",
      "Epoch 699/1000 | Batch 0/237 | Loss: 3988.9072\n",
      "Epoch 699/1000 | Batch 100/237 | Loss: 1048.2998\n",
      "Epoch 699/1000 | Batch 200/237 | Loss: 1300.2305\n",
      "Epoch 699/1000 complete | Avg Loss: 4587.2528\n",
      "Epoch 700/1000 | Batch 0/237 | Loss: 892.5466\n",
      "Epoch 700/1000 | Batch 100/237 | Loss: 1640.7230\n",
      "Epoch 700/1000 | Batch 200/237 | Loss: 2604.1863\n",
      "Epoch 700/1000 complete | Avg Loss: 4541.8310\n",
      "Epoch 701/1000 | Batch 0/237 | Loss: 808.8541\n",
      "Epoch 701/1000 | Batch 100/237 | Loss: 749.4669\n",
      "Epoch 701/1000 | Batch 200/237 | Loss: 3145.9834\n",
      "Epoch 701/1000 complete | Avg Loss: 4533.5627\n",
      "Epoch 702/1000 | Batch 0/237 | Loss: 5830.3560\n",
      "Epoch 702/1000 | Batch 100/237 | Loss: 7021.4390\n",
      "Epoch 702/1000 | Batch 200/237 | Loss: 5289.4062\n",
      "Epoch 702/1000 complete | Avg Loss: 4555.1825\n",
      "Epoch 703/1000 | Batch 0/237 | Loss: 2169.4116\n",
      "Epoch 703/1000 | Batch 100/237 | Loss: 1675.8442\n",
      "Epoch 703/1000 | Batch 200/237 | Loss: 13094.0312\n",
      "Epoch 703/1000 complete | Avg Loss: 4556.9977\n",
      "Epoch 704/1000 | Batch 0/237 | Loss: 2239.4128\n",
      "Epoch 704/1000 | Batch 100/237 | Loss: 843.4827\n",
      "Epoch 704/1000 | Batch 200/237 | Loss: 8196.5088\n",
      "Epoch 704/1000 complete | Avg Loss: 4549.0176\n",
      "Epoch 705/1000 | Batch 0/237 | Loss: 1198.0552\n",
      "Epoch 705/1000 | Batch 100/237 | Loss: 6147.2021\n",
      "Epoch 705/1000 | Batch 200/237 | Loss: 961.2522\n",
      "Epoch 705/1000 complete | Avg Loss: 4551.6039\n",
      "Epoch 706/1000 | Batch 0/237 | Loss: 937.3913\n",
      "Epoch 706/1000 | Batch 100/237 | Loss: 987.5049\n",
      "Epoch 706/1000 | Batch 200/237 | Loss: 2144.2900\n",
      "Epoch 706/1000 complete | Avg Loss: 4546.5808\n",
      "Epoch 707/1000 | Batch 0/237 | Loss: 8186.6289\n",
      "Epoch 707/1000 | Batch 100/237 | Loss: 1918.4165\n",
      "Epoch 707/1000 | Batch 200/237 | Loss: 1411.0625\n",
      "Epoch 707/1000 complete | Avg Loss: 4541.0533\n",
      "Epoch 708/1000 | Batch 0/237 | Loss: 727.5258\n",
      "Epoch 708/1000 | Batch 100/237 | Loss: 3148.2837\n",
      "Epoch 708/1000 | Batch 200/237 | Loss: 6373.3262\n",
      "Epoch 708/1000 complete | Avg Loss: 4539.6262\n",
      "Epoch 709/1000 | Batch 0/237 | Loss: 3031.6086\n",
      "Epoch 709/1000 | Batch 100/237 | Loss: 7032.4961\n",
      "Epoch 709/1000 | Batch 200/237 | Loss: 640.6816\n",
      "Epoch 709/1000 complete | Avg Loss: 4538.8567\n",
      "Epoch 710/1000 | Batch 0/237 | Loss: 18822.0566\n",
      "Epoch 710/1000 | Batch 100/237 | Loss: 891.0072\n",
      "Epoch 710/1000 | Batch 200/237 | Loss: 1969.6843\n",
      "Epoch 710/1000 complete | Avg Loss: 4542.5171\n",
      "Epoch 711/1000 | Batch 0/237 | Loss: 4567.7949\n",
      "Epoch 711/1000 | Batch 100/237 | Loss: 2592.6943\n",
      "Epoch 711/1000 | Batch 200/237 | Loss: 22878.8633\n",
      "Epoch 711/1000 complete | Avg Loss: 4533.7572\n",
      "Epoch 712/1000 | Batch 0/237 | Loss: 815.7535\n",
      "Epoch 712/1000 | Batch 100/237 | Loss: 1078.5845\n",
      "Epoch 712/1000 | Batch 200/237 | Loss: 45224.3438\n",
      "Epoch 712/1000 complete | Avg Loss: 4541.4099\n",
      "Epoch 713/1000 | Batch 0/237 | Loss: 4698.2607\n",
      "Epoch 713/1000 | Batch 100/237 | Loss: 3594.0117\n",
      "Epoch 713/1000 | Batch 200/237 | Loss: 8690.8867\n",
      "Epoch 713/1000 complete | Avg Loss: 4539.1085\n",
      "Epoch 714/1000 | Batch 0/237 | Loss: 1623.1049\n",
      "Epoch 714/1000 | Batch 100/237 | Loss: 2246.5862\n",
      "Epoch 714/1000 | Batch 200/237 | Loss: 3177.2227\n",
      "Epoch 714/1000 complete | Avg Loss: 4535.5084\n",
      "Epoch 715/1000 | Batch 0/237 | Loss: 2485.5852\n",
      "Epoch 715/1000 | Batch 100/237 | Loss: 1641.2251\n",
      "Epoch 715/1000 | Batch 200/237 | Loss: 4293.9365\n",
      "Epoch 715/1000 complete | Avg Loss: 4536.6757\n",
      "Epoch 716/1000 | Batch 0/237 | Loss: 3171.1541\n",
      "Epoch 716/1000 | Batch 100/237 | Loss: 1329.2885\n",
      "Epoch 716/1000 | Batch 200/237 | Loss: 37602.9766\n",
      "Epoch 716/1000 complete | Avg Loss: 4585.3518\n",
      "Epoch 717/1000 | Batch 0/237 | Loss: 4241.8457\n",
      "Epoch 717/1000 | Batch 100/237 | Loss: 6817.7329\n",
      "Epoch 717/1000 | Batch 200/237 | Loss: 762.4738\n",
      "Epoch 717/1000 complete | Avg Loss: 4534.2096\n",
      "Epoch 718/1000 | Batch 0/237 | Loss: 3354.6724\n",
      "Epoch 718/1000 | Batch 100/237 | Loss: 2371.4470\n",
      "Epoch 718/1000 | Batch 200/237 | Loss: 60509.0547\n",
      "Epoch 718/1000 complete | Avg Loss: 4546.8617\n",
      "Epoch 719/1000 | Batch 0/237 | Loss: 15051.5254\n",
      "Epoch 719/1000 | Batch 100/237 | Loss: 33280.1914\n",
      "Epoch 719/1000 | Batch 200/237 | Loss: 6137.6987\n",
      "Epoch 719/1000 complete | Avg Loss: 4535.4870\n",
      "Epoch 720/1000 | Batch 0/237 | Loss: 1326.9897\n",
      "Epoch 720/1000 | Batch 100/237 | Loss: 1096.1866\n",
      "Epoch 720/1000 | Batch 200/237 | Loss: 1178.8148\n",
      "Epoch 720/1000 complete | Avg Loss: 4535.8824\n",
      "Epoch 721/1000 | Batch 0/237 | Loss: 6544.1245\n",
      "Epoch 721/1000 | Batch 100/237 | Loss: 2626.1636\n",
      "Epoch 721/1000 | Batch 200/237 | Loss: 2133.1365\n",
      "Epoch 721/1000 complete | Avg Loss: 4537.6567\n",
      "Epoch 722/1000 | Batch 0/237 | Loss: 1094.8158\n",
      "Epoch 722/1000 | Batch 100/237 | Loss: 3545.2034\n",
      "Epoch 722/1000 | Batch 200/237 | Loss: 6863.7583\n",
      "Epoch 722/1000 complete | Avg Loss: 4544.1022\n",
      "Epoch 723/1000 | Batch 0/237 | Loss: 913.1555\n",
      "Epoch 723/1000 | Batch 100/237 | Loss: 844.8058\n",
      "Epoch 723/1000 | Batch 200/237 | Loss: 1140.3325\n",
      "Epoch 723/1000 complete | Avg Loss: 4530.6739\n",
      "Epoch 724/1000 | Batch 0/237 | Loss: 1233.7194\n",
      "Epoch 724/1000 | Batch 100/237 | Loss: 2124.1624\n",
      "Epoch 724/1000 | Batch 200/237 | Loss: 978.7520\n",
      "Epoch 724/1000 complete | Avg Loss: 4533.9274\n",
      "Epoch 725/1000 | Batch 0/237 | Loss: 1050.0105\n",
      "Epoch 725/1000 | Batch 100/237 | Loss: 3437.1575\n",
      "Epoch 725/1000 | Batch 200/237 | Loss: 2429.7954\n",
      "Epoch 725/1000 complete | Avg Loss: 4536.7705\n",
      "Epoch 726/1000 | Batch 0/237 | Loss: 2259.9414\n",
      "Epoch 726/1000 | Batch 100/237 | Loss: 10543.7871\n",
      "Epoch 726/1000 | Batch 200/237 | Loss: 1642.3167\n",
      "Epoch 726/1000 complete | Avg Loss: 4530.3946\n",
      "Epoch 727/1000 | Batch 0/237 | Loss: 2284.0959\n",
      "Epoch 727/1000 | Batch 100/237 | Loss: 3359.5806\n",
      "Epoch 727/1000 | Batch 200/237 | Loss: 31478.9551\n",
      "Epoch 727/1000 complete | Avg Loss: 4532.7043\n",
      "Epoch 728/1000 | Batch 0/237 | Loss: 8271.6211\n",
      "Epoch 728/1000 | Batch 100/237 | Loss: 3383.9832\n",
      "Epoch 728/1000 | Batch 200/237 | Loss: 2754.8796\n",
      "Epoch 728/1000 complete | Avg Loss: 4528.2362\n",
      "Epoch 729/1000 | Batch 0/237 | Loss: 18718.1621\n",
      "Epoch 729/1000 | Batch 100/237 | Loss: 1586.6017\n",
      "Epoch 729/1000 | Batch 200/237 | Loss: 1536.2544\n",
      "Epoch 729/1000 complete | Avg Loss: 4530.7545\n",
      "Epoch 730/1000 | Batch 0/237 | Loss: 6949.3442\n",
      "Epoch 730/1000 | Batch 100/237 | Loss: 1907.5852\n",
      "Epoch 730/1000 | Batch 200/237 | Loss: 2437.9980\n",
      "Epoch 730/1000 complete | Avg Loss: 4578.5774\n",
      "Epoch 731/1000 | Batch 0/237 | Loss: 2522.1252\n",
      "Epoch 731/1000 | Batch 100/237 | Loss: 1563.6809\n",
      "Epoch 731/1000 | Batch 200/237 | Loss: 978.1623\n",
      "Epoch 731/1000 complete | Avg Loss: 4528.5798\n",
      "Epoch 732/1000 | Batch 0/237 | Loss: 5452.6357\n",
      "Epoch 732/1000 | Batch 100/237 | Loss: 2365.5217\n",
      "Epoch 732/1000 | Batch 200/237 | Loss: 3103.3347\n",
      "Epoch 732/1000 complete | Avg Loss: 4533.3033\n",
      "Epoch 733/1000 | Batch 0/237 | Loss: 4254.8770\n",
      "Epoch 733/1000 | Batch 100/237 | Loss: 2548.4561\n",
      "Epoch 733/1000 | Batch 200/237 | Loss: 3139.9795\n",
      "Epoch 733/1000 complete | Avg Loss: 4534.7081\n",
      "Epoch 734/1000 | Batch 0/237 | Loss: 2380.1665\n",
      "Epoch 734/1000 | Batch 100/237 | Loss: 1265.4099\n",
      "Epoch 734/1000 | Batch 200/237 | Loss: 1586.6166\n",
      "Epoch 734/1000 complete | Avg Loss: 4597.2449\n",
      "Epoch 735/1000 | Batch 0/237 | Loss: 1420.4553\n",
      "Epoch 735/1000 | Batch 100/237 | Loss: 7945.6152\n",
      "Epoch 735/1000 | Batch 200/237 | Loss: 3213.2808\n",
      "Epoch 735/1000 complete | Avg Loss: 4524.8896\n",
      "Epoch 736/1000 | Batch 0/237 | Loss: 4076.3989\n",
      "Epoch 736/1000 | Batch 100/237 | Loss: 1217.4830\n",
      "Epoch 736/1000 | Batch 200/237 | Loss: 1782.0803\n",
      "Epoch 736/1000 complete | Avg Loss: 4530.2600\n",
      "Epoch 737/1000 | Batch 0/237 | Loss: 4572.1147\n",
      "Epoch 737/1000 | Batch 100/237 | Loss: 7501.0938\n",
      "Epoch 737/1000 | Batch 200/237 | Loss: 26893.6797\n",
      "Epoch 737/1000 complete | Avg Loss: 4524.0892\n",
      "Epoch 738/1000 | Batch 0/237 | Loss: 4517.2314\n",
      "Epoch 738/1000 | Batch 100/237 | Loss: 2363.5229\n",
      "Epoch 738/1000 | Batch 200/237 | Loss: 1546.3306\n",
      "Epoch 738/1000 complete | Avg Loss: 4531.9415\n",
      "Epoch 739/1000 | Batch 0/237 | Loss: 2046.3396\n",
      "Epoch 739/1000 | Batch 100/237 | Loss: 3120.5781\n",
      "Epoch 739/1000 | Batch 200/237 | Loss: 604.9159\n",
      "Epoch 739/1000 complete | Avg Loss: 4530.0535\n",
      "Epoch 740/1000 | Batch 0/237 | Loss: 4141.7852\n",
      "Epoch 740/1000 | Batch 100/237 | Loss: 696.4787\n",
      "Epoch 740/1000 | Batch 200/237 | Loss: 1468.1378\n",
      "Epoch 740/1000 complete | Avg Loss: 4532.4548\n",
      "Epoch 741/1000 | Batch 0/237 | Loss: 523.0948\n",
      "Epoch 741/1000 | Batch 100/237 | Loss: 919.9081\n",
      "Epoch 741/1000 | Batch 200/237 | Loss: 1916.0901\n",
      "Epoch 741/1000 complete | Avg Loss: 4526.8962\n",
      "Epoch 742/1000 | Batch 0/237 | Loss: 1674.0487\n",
      "Epoch 742/1000 | Batch 100/237 | Loss: 1163.5062\n",
      "Epoch 742/1000 | Batch 200/237 | Loss: 3680.4446\n",
      "Epoch 742/1000 complete | Avg Loss: 4519.8827\n",
      "Epoch 743/1000 | Batch 0/237 | Loss: 1613.9126\n",
      "Epoch 743/1000 | Batch 100/237 | Loss: 782.1890\n",
      "Epoch 743/1000 | Batch 200/237 | Loss: 2885.2410\n",
      "Epoch 743/1000 complete | Avg Loss: 4526.3436\n",
      "Epoch 744/1000 | Batch 0/237 | Loss: 1271.1794\n",
      "Epoch 744/1000 | Batch 100/237 | Loss: 10381.1797\n",
      "Epoch 744/1000 | Batch 200/237 | Loss: 2480.5347\n",
      "Epoch 744/1000 complete | Avg Loss: 4527.1793\n",
      "Epoch 745/1000 | Batch 0/237 | Loss: 1034.7029\n",
      "Epoch 745/1000 | Batch 100/237 | Loss: 2680.2712\n",
      "Epoch 745/1000 | Batch 200/237 | Loss: 19825.8965\n",
      "Epoch 745/1000 complete | Avg Loss: 4527.4505\n",
      "Epoch 746/1000 | Batch 0/237 | Loss: 1195.0430\n",
      "Epoch 746/1000 | Batch 100/237 | Loss: 3809.5769\n",
      "Epoch 746/1000 | Batch 200/237 | Loss: 856.8638\n",
      "Epoch 746/1000 complete | Avg Loss: 4534.3450\n",
      "Epoch 747/1000 | Batch 0/237 | Loss: 4827.0083\n",
      "Epoch 747/1000 | Batch 100/237 | Loss: 1848.9707\n",
      "Epoch 747/1000 | Batch 200/237 | Loss: 1094.9998\n",
      "Epoch 747/1000 complete | Avg Loss: 4526.3447\n",
      "Epoch 748/1000 | Batch 0/237 | Loss: 2739.6826\n",
      "Epoch 748/1000 | Batch 100/237 | Loss: 5928.3652\n",
      "Epoch 748/1000 | Batch 200/237 | Loss: 1738.7437\n",
      "Epoch 748/1000 complete | Avg Loss: 4520.0846\n",
      "Epoch 749/1000 | Batch 0/237 | Loss: 2761.0681\n",
      "Epoch 749/1000 | Batch 100/237 | Loss: 4663.7720\n",
      "Epoch 749/1000 | Batch 200/237 | Loss: 1444.3280\n",
      "Epoch 749/1000 complete | Avg Loss: 4522.8484\n",
      "Epoch 750/1000 | Batch 0/237 | Loss: 3424.0520\n",
      "Epoch 750/1000 | Batch 100/237 | Loss: 1253.8083\n",
      "Epoch 750/1000 | Batch 200/237 | Loss: 953.3500\n",
      "Epoch 750/1000 complete | Avg Loss: 4516.4834\n",
      "Epoch 751/1000 | Batch 0/237 | Loss: 3242.9355\n",
      "Epoch 751/1000 | Batch 100/237 | Loss: 3161.2366\n",
      "Epoch 751/1000 | Batch 200/237 | Loss: 3049.5574\n",
      "Epoch 751/1000 complete | Avg Loss: 4529.3536\n",
      "Epoch 752/1000 | Batch 0/237 | Loss: 29602.5645\n",
      "Epoch 752/1000 | Batch 100/237 | Loss: 1060.3611\n",
      "Epoch 752/1000 | Batch 200/237 | Loss: 29683.6289\n",
      "Epoch 752/1000 complete | Avg Loss: 4524.2131\n",
      "Epoch 753/1000 | Batch 0/237 | Loss: 1825.7251\n",
      "Epoch 753/1000 | Batch 100/237 | Loss: 920.1140\n",
      "Epoch 753/1000 | Batch 200/237 | Loss: 853.9802\n",
      "Epoch 753/1000 complete | Avg Loss: 4521.7333\n",
      "Epoch 754/1000 | Batch 0/237 | Loss: 2119.6416\n",
      "Epoch 754/1000 | Batch 100/237 | Loss: 1922.2771\n",
      "Epoch 754/1000 | Batch 200/237 | Loss: 1336.9485\n",
      "Epoch 754/1000 complete | Avg Loss: 4522.8901\n",
      "Epoch 755/1000 | Batch 0/237 | Loss: 1231.5093\n",
      "Epoch 755/1000 | Batch 100/237 | Loss: 1757.2913\n",
      "Epoch 755/1000 | Batch 200/237 | Loss: 896.8723\n",
      "Epoch 755/1000 complete | Avg Loss: 4522.6632\n",
      "Epoch 756/1000 | Batch 0/237 | Loss: 8171.3979\n",
      "Epoch 756/1000 | Batch 100/237 | Loss: 6113.6689\n",
      "Epoch 756/1000 | Batch 200/237 | Loss: 2093.7046\n",
      "Epoch 756/1000 complete | Avg Loss: 4530.8384\n",
      "Epoch 757/1000 | Batch 0/237 | Loss: 909.0352\n",
      "Epoch 757/1000 | Batch 100/237 | Loss: 824.1148\n",
      "Epoch 757/1000 | Batch 200/237 | Loss: 2250.6895\n",
      "Epoch 757/1000 complete | Avg Loss: 4517.6266\n",
      "Epoch 758/1000 | Batch 0/237 | Loss: 1414.7344\n",
      "Epoch 758/1000 | Batch 100/237 | Loss: 4307.9985\n",
      "Epoch 758/1000 | Batch 200/237 | Loss: 1970.4216\n",
      "Epoch 758/1000 complete | Avg Loss: 4526.3326\n",
      "Epoch 759/1000 | Batch 0/237 | Loss: 2462.4580\n",
      "Epoch 759/1000 | Batch 100/237 | Loss: 3505.7480\n",
      "Epoch 759/1000 | Batch 200/237 | Loss: 1509.4232\n",
      "Epoch 759/1000 complete | Avg Loss: 4522.5067\n",
      "Epoch 760/1000 | Batch 0/237 | Loss: 708.8871\n",
      "Epoch 760/1000 | Batch 100/237 | Loss: 1074.4501\n",
      "Epoch 760/1000 | Batch 200/237 | Loss: 6936.9316\n",
      "Epoch 760/1000 complete | Avg Loss: 4515.7399\n",
      "Epoch 761/1000 | Batch 0/237 | Loss: 2273.2742\n",
      "Epoch 761/1000 | Batch 100/237 | Loss: 595.6411\n",
      "Epoch 761/1000 | Batch 200/237 | Loss: 1733.6240\n",
      "Epoch 761/1000 complete | Avg Loss: 4523.5644\n",
      "Epoch 762/1000 | Batch 0/237 | Loss: 1068.6134\n",
      "Epoch 762/1000 | Batch 100/237 | Loss: 1620.6207\n",
      "Epoch 762/1000 | Batch 200/237 | Loss: 37711.8672\n",
      "Epoch 762/1000 complete | Avg Loss: 4525.8779\n",
      "Epoch 763/1000 | Batch 0/237 | Loss: 1571.0851\n",
      "Epoch 763/1000 | Batch 100/237 | Loss: 29099.9746\n",
      "Epoch 763/1000 | Batch 200/237 | Loss: 5318.5410\n",
      "Epoch 763/1000 complete | Avg Loss: 4552.4124\n",
      "Epoch 764/1000 | Batch 0/237 | Loss: 1277.0706\n",
      "Epoch 764/1000 | Batch 100/237 | Loss: 18790.0000\n",
      "Epoch 764/1000 | Batch 200/237 | Loss: 3029.3972\n",
      "Epoch 764/1000 complete | Avg Loss: 4527.5487\n",
      "Epoch 765/1000 | Batch 0/237 | Loss: 2360.6072\n",
      "Epoch 765/1000 | Batch 100/237 | Loss: 10573.9834\n",
      "Epoch 765/1000 | Batch 200/237 | Loss: 1159.8511\n",
      "Epoch 765/1000 complete | Avg Loss: 4514.7251\n",
      "Epoch 766/1000 | Batch 0/237 | Loss: 1827.5455\n",
      "Epoch 766/1000 | Batch 100/237 | Loss: 15220.1924\n",
      "Epoch 766/1000 | Batch 200/237 | Loss: 1509.6547\n",
      "Epoch 766/1000 complete | Avg Loss: 4671.2442\n",
      "Epoch 767/1000 | Batch 0/237 | Loss: 2214.0095\n",
      "Epoch 767/1000 | Batch 100/237 | Loss: 5370.2803\n",
      "Epoch 767/1000 | Batch 200/237 | Loss: 2695.4458\n",
      "Epoch 767/1000 complete | Avg Loss: 4539.8384\n",
      "Epoch 768/1000 | Batch 0/237 | Loss: 1651.5951\n",
      "Epoch 768/1000 | Batch 100/237 | Loss: 797.5122\n",
      "Epoch 768/1000 | Batch 200/237 | Loss: 4988.8481\n",
      "Epoch 768/1000 complete | Avg Loss: 4546.5126\n",
      "Epoch 769/1000 | Batch 0/237 | Loss: 11904.1494\n",
      "Epoch 769/1000 | Batch 100/237 | Loss: 1524.7725\n",
      "Epoch 769/1000 | Batch 200/237 | Loss: 26525.4727\n",
      "Epoch 769/1000 complete | Avg Loss: 4521.1496\n",
      "Epoch 770/1000 | Batch 0/237 | Loss: 1633.7786\n",
      "Epoch 770/1000 | Batch 100/237 | Loss: 16077.5898\n",
      "Epoch 770/1000 | Batch 200/237 | Loss: 1319.7529\n",
      "Epoch 770/1000 complete | Avg Loss: 4545.1262\n",
      "Epoch 771/1000 | Batch 0/237 | Loss: 2156.8884\n",
      "Epoch 771/1000 | Batch 100/237 | Loss: 1860.6599\n",
      "Epoch 771/1000 | Batch 200/237 | Loss: 12439.4756\n",
      "Epoch 771/1000 complete | Avg Loss: 4520.5917\n",
      "Epoch 772/1000 | Batch 0/237 | Loss: 3441.7808\n",
      "Epoch 772/1000 | Batch 100/237 | Loss: 3268.4429\n",
      "Epoch 772/1000 | Batch 200/237 | Loss: 1934.8224\n",
      "Epoch 772/1000 complete | Avg Loss: 4519.2740\n",
      "Epoch 773/1000 | Batch 0/237 | Loss: 4528.5010\n",
      "Epoch 773/1000 | Batch 100/237 | Loss: 1855.4557\n",
      "Epoch 773/1000 | Batch 200/237 | Loss: 29185.2969\n",
      "Epoch 773/1000 complete | Avg Loss: 4511.7348\n",
      "Epoch 774/1000 | Batch 0/237 | Loss: 1754.0270\n",
      "Epoch 774/1000 | Batch 100/237 | Loss: 1227.8560\n",
      "Epoch 774/1000 | Batch 200/237 | Loss: 1797.2877\n",
      "Epoch 774/1000 complete | Avg Loss: 4511.7891\n",
      "Epoch 775/1000 | Batch 0/237 | Loss: 680.8715\n",
      "Epoch 775/1000 | Batch 100/237 | Loss: 972.7482\n",
      "Epoch 775/1000 | Batch 200/237 | Loss: 20804.7363\n",
      "Epoch 775/1000 complete | Avg Loss: 4512.8676\n",
      "Epoch 776/1000 | Batch 0/237 | Loss: 2002.4001\n",
      "Epoch 776/1000 | Batch 100/237 | Loss: 1088.6068\n",
      "Epoch 776/1000 | Batch 200/237 | Loss: 7457.6484\n",
      "Epoch 776/1000 complete | Avg Loss: 4512.9031\n",
      "Epoch 777/1000 | Batch 0/237 | Loss: 1739.8907\n",
      "Epoch 777/1000 | Batch 100/237 | Loss: 2027.6333\n",
      "Epoch 777/1000 | Batch 200/237 | Loss: 2252.9578\n",
      "Epoch 777/1000 complete | Avg Loss: 4516.0525\n",
      "Epoch 778/1000 | Batch 0/237 | Loss: 3563.3379\n",
      "Epoch 778/1000 | Batch 100/237 | Loss: 8636.4805\n",
      "Epoch 778/1000 | Batch 200/237 | Loss: 3006.3721\n",
      "Epoch 778/1000 complete | Avg Loss: 4514.5244\n",
      "Epoch 779/1000 | Batch 0/237 | Loss: 2429.2673\n",
      "Epoch 779/1000 | Batch 100/237 | Loss: 4068.8105\n",
      "Epoch 779/1000 | Batch 200/237 | Loss: 1167.3418\n",
      "Epoch 779/1000 complete | Avg Loss: 4512.9532\n",
      "Epoch 780/1000 | Batch 0/237 | Loss: 1048.1486\n",
      "Epoch 780/1000 | Batch 100/237 | Loss: 5806.0591\n",
      "Epoch 780/1000 | Batch 200/237 | Loss: 2060.7771\n",
      "Epoch 780/1000 complete | Avg Loss: 4524.7671\n",
      "Epoch 781/1000 | Batch 0/237 | Loss: 859.8253\n",
      "Epoch 781/1000 | Batch 100/237 | Loss: 1978.0975\n",
      "Epoch 781/1000 | Batch 200/237 | Loss: 1772.0155\n",
      "Epoch 781/1000 complete | Avg Loss: 4517.7715\n",
      "Epoch 782/1000 | Batch 0/237 | Loss: 1842.9966\n",
      "Epoch 782/1000 | Batch 100/237 | Loss: 1250.9109\n",
      "Epoch 782/1000 | Batch 200/237 | Loss: 1963.6212\n",
      "Epoch 782/1000 complete | Avg Loss: 4511.7329\n",
      "Epoch 783/1000 | Batch 0/237 | Loss: 865.7111\n",
      "Epoch 783/1000 | Batch 100/237 | Loss: 2595.3760\n",
      "Epoch 783/1000 | Batch 200/237 | Loss: 4907.6323\n",
      "Epoch 783/1000 complete | Avg Loss: 4507.2574\n",
      "Epoch 784/1000 | Batch 0/237 | Loss: 7291.4341\n",
      "Epoch 784/1000 | Batch 100/237 | Loss: 1963.3883\n",
      "Epoch 784/1000 | Batch 200/237 | Loss: 28075.3320\n",
      "Epoch 784/1000 complete | Avg Loss: 4507.4818\n",
      "Epoch 785/1000 | Batch 0/237 | Loss: 1775.8313\n",
      "Epoch 785/1000 | Batch 100/237 | Loss: 1136.5682\n",
      "Epoch 785/1000 | Batch 200/237 | Loss: 1761.6250\n",
      "Epoch 785/1000 complete | Avg Loss: 4521.4457\n",
      "Epoch 786/1000 | Batch 0/237 | Loss: 806.6975\n",
      "Epoch 786/1000 | Batch 100/237 | Loss: 1722.6204\n",
      "Epoch 786/1000 | Batch 200/237 | Loss: 786.2432\n",
      "Epoch 786/1000 complete | Avg Loss: 4511.0071\n",
      "Epoch 787/1000 | Batch 0/237 | Loss: 4627.3169\n",
      "Epoch 787/1000 | Batch 100/237 | Loss: 21500.1797\n",
      "Epoch 787/1000 | Batch 200/237 | Loss: 29525.2344\n",
      "Epoch 787/1000 complete | Avg Loss: 4513.2538\n",
      "Epoch 788/1000 | Batch 0/237 | Loss: 8504.6240\n",
      "Epoch 788/1000 | Batch 100/237 | Loss: 707.8842\n",
      "Epoch 788/1000 | Batch 200/237 | Loss: 9920.8477\n",
      "Epoch 788/1000 complete | Avg Loss: 4511.7593\n",
      "Epoch 789/1000 | Batch 0/237 | Loss: 7199.5371\n",
      "Epoch 789/1000 | Batch 100/237 | Loss: 859.2655\n",
      "Epoch 789/1000 | Batch 200/237 | Loss: 2788.4360\n",
      "Epoch 789/1000 complete | Avg Loss: 4509.4510\n",
      "Epoch 790/1000 | Batch 0/237 | Loss: 9934.1934\n",
      "Epoch 790/1000 | Batch 100/237 | Loss: 3939.2112\n",
      "Epoch 790/1000 | Batch 200/237 | Loss: 13553.8955\n",
      "Epoch 790/1000 complete | Avg Loss: 4513.2945\n",
      "Epoch 791/1000 | Batch 0/237 | Loss: 2694.9646\n",
      "Epoch 791/1000 | Batch 100/237 | Loss: 3837.4104\n",
      "Epoch 791/1000 | Batch 200/237 | Loss: 13441.4355\n",
      "Epoch 791/1000 complete | Avg Loss: 4508.8098\n",
      "Epoch 792/1000 | Batch 0/237 | Loss: 600.4635\n",
      "Epoch 792/1000 | Batch 100/237 | Loss: 1104.9144\n",
      "Epoch 792/1000 | Batch 200/237 | Loss: 6606.2720\n",
      "Epoch 792/1000 complete | Avg Loss: 4506.0651\n",
      "Epoch 793/1000 | Batch 0/237 | Loss: 5723.3403\n",
      "Epoch 793/1000 | Batch 100/237 | Loss: 1414.9177\n",
      "Epoch 793/1000 | Batch 200/237 | Loss: 3776.4197\n",
      "Epoch 793/1000 complete | Avg Loss: 4518.1870\n",
      "Epoch 794/1000 | Batch 0/237 | Loss: 2077.7456\n",
      "Epoch 794/1000 | Batch 100/237 | Loss: 2603.8230\n",
      "Epoch 794/1000 | Batch 200/237 | Loss: 550.9337\n",
      "Epoch 794/1000 complete | Avg Loss: 4509.7247\n",
      "Epoch 795/1000 | Batch 0/237 | Loss: 1844.2456\n",
      "Epoch 795/1000 | Batch 100/237 | Loss: 29131.6973\n",
      "Epoch 795/1000 | Batch 200/237 | Loss: 8706.9160\n",
      "Epoch 795/1000 complete | Avg Loss: 4511.5867\n",
      "Epoch 796/1000 | Batch 0/237 | Loss: 3655.3340\n",
      "Epoch 796/1000 | Batch 100/237 | Loss: 2858.9124\n",
      "Epoch 796/1000 | Batch 200/237 | Loss: 1041.7734\n",
      "Epoch 796/1000 complete | Avg Loss: 4506.4301\n",
      "Epoch 797/1000 | Batch 0/237 | Loss: 9185.4395\n",
      "Epoch 797/1000 | Batch 100/237 | Loss: 1884.4688\n",
      "Epoch 797/1000 | Batch 200/237 | Loss: 5067.5161\n",
      "Epoch 797/1000 complete | Avg Loss: 4511.1586\n",
      "Epoch 798/1000 | Batch 0/237 | Loss: 1646.1211\n",
      "Epoch 798/1000 | Batch 100/237 | Loss: 1540.7140\n",
      "Epoch 798/1000 | Batch 200/237 | Loss: 3543.6870\n",
      "Epoch 798/1000 complete | Avg Loss: 4508.7080\n",
      "Epoch 799/1000 | Batch 0/237 | Loss: 2511.4275\n",
      "Epoch 799/1000 | Batch 100/237 | Loss: 29304.2520\n",
      "Epoch 799/1000 | Batch 200/237 | Loss: 3850.6235\n",
      "Epoch 799/1000 complete | Avg Loss: 4508.2609\n",
      "Epoch 800/1000 | Batch 0/237 | Loss: 1162.7648\n",
      "Epoch 800/1000 | Batch 100/237 | Loss: 2119.1316\n",
      "Epoch 800/1000 | Batch 200/237 | Loss: 1596.9827\n",
      "Epoch 800/1000 complete | Avg Loss: 4513.4325\n",
      "Epoch 801/1000 | Batch 0/237 | Loss: 3956.3784\n",
      "Epoch 801/1000 | Batch 100/237 | Loss: 4127.9590\n",
      "Epoch 801/1000 | Batch 200/237 | Loss: 4638.4907\n",
      "Epoch 801/1000 complete | Avg Loss: 4501.6820\n",
      "Epoch 802/1000 | Batch 0/237 | Loss: 689.6240\n",
      "Epoch 802/1000 | Batch 100/237 | Loss: 2241.0515\n",
      "Epoch 802/1000 | Batch 200/237 | Loss: 1023.4169\n",
      "Epoch 802/1000 complete | Avg Loss: 4504.6344\n",
      "Epoch 803/1000 | Batch 0/237 | Loss: 7790.3672\n",
      "Epoch 803/1000 | Batch 100/237 | Loss: 20323.8223\n",
      "Epoch 803/1000 | Batch 200/237 | Loss: 2831.6777\n",
      "Epoch 803/1000 complete | Avg Loss: 4501.8307\n",
      "Epoch 804/1000 | Batch 0/237 | Loss: 4023.6516\n",
      "Epoch 804/1000 | Batch 100/237 | Loss: 23457.8555\n",
      "Epoch 804/1000 | Batch 200/237 | Loss: 2436.8042\n",
      "Epoch 804/1000 complete | Avg Loss: 4504.0901\n",
      "Epoch 805/1000 | Batch 0/237 | Loss: 7595.6167\n",
      "Epoch 805/1000 | Batch 100/237 | Loss: 896.3531\n",
      "Epoch 805/1000 | Batch 200/237 | Loss: 2524.3594\n",
      "Epoch 805/1000 complete | Avg Loss: 4498.1134\n",
      "Epoch 806/1000 | Batch 0/237 | Loss: 1574.8838\n",
      "Epoch 806/1000 | Batch 100/237 | Loss: 1707.4935\n",
      "Epoch 806/1000 | Batch 200/237 | Loss: 2286.5876\n",
      "Epoch 806/1000 complete | Avg Loss: 4514.5811\n",
      "Epoch 807/1000 | Batch 0/237 | Loss: 753.8887\n",
      "Epoch 807/1000 | Batch 100/237 | Loss: 613.2072\n",
      "Epoch 807/1000 | Batch 200/237 | Loss: 24856.8691\n",
      "Epoch 807/1000 complete | Avg Loss: 4505.7203\n",
      "Epoch 808/1000 | Batch 0/237 | Loss: 1382.5618\n",
      "Epoch 808/1000 | Batch 100/237 | Loss: 7720.2637\n",
      "Epoch 808/1000 | Batch 200/237 | Loss: 8170.0244\n",
      "Epoch 808/1000 complete | Avg Loss: 4500.4533\n",
      "Epoch 809/1000 | Batch 0/237 | Loss: 1534.1578\n",
      "Epoch 809/1000 | Batch 100/237 | Loss: 12270.9707\n",
      "Epoch 809/1000 | Batch 200/237 | Loss: 19830.2520\n",
      "Epoch 809/1000 complete | Avg Loss: 4505.7977\n",
      "Epoch 810/1000 | Batch 0/237 | Loss: 1096.9004\n",
      "Epoch 810/1000 | Batch 100/237 | Loss: 4538.9873\n",
      "Epoch 810/1000 | Batch 200/237 | Loss: 6094.8594\n",
      "Epoch 810/1000 complete | Avg Loss: 4504.4339\n",
      "Epoch 811/1000 | Batch 0/237 | Loss: 16224.1680\n",
      "Epoch 811/1000 | Batch 100/237 | Loss: 8236.0527\n",
      "Epoch 811/1000 | Batch 200/237 | Loss: 3853.3801\n",
      "Epoch 811/1000 complete | Avg Loss: 4500.7918\n",
      "Epoch 812/1000 | Batch 0/237 | Loss: 1624.6321\n",
      "Epoch 812/1000 | Batch 100/237 | Loss: 8281.1172\n",
      "Epoch 812/1000 | Batch 200/237 | Loss: 947.3937\n",
      "Epoch 812/1000 complete | Avg Loss: 4509.2586\n",
      "Epoch 813/1000 | Batch 0/237 | Loss: 1427.4550\n",
      "Epoch 813/1000 | Batch 100/237 | Loss: 2526.8386\n",
      "Epoch 813/1000 | Batch 200/237 | Loss: 2054.0293\n",
      "Epoch 813/1000 complete | Avg Loss: 4523.6836\n",
      "Epoch 814/1000 | Batch 0/237 | Loss: 3715.2896\n",
      "Epoch 814/1000 | Batch 100/237 | Loss: 2962.5813\n",
      "Epoch 814/1000 | Batch 200/237 | Loss: 2791.7913\n",
      "Epoch 814/1000 complete | Avg Loss: 4502.7532\n",
      "Epoch 815/1000 | Batch 0/237 | Loss: 3271.1887\n",
      "Epoch 815/1000 | Batch 100/237 | Loss: 1541.2527\n",
      "Epoch 815/1000 | Batch 200/237 | Loss: 1311.5521\n",
      "Epoch 815/1000 complete | Avg Loss: 4510.3328\n",
      "Epoch 816/1000 | Batch 0/237 | Loss: 1970.4338\n",
      "Epoch 816/1000 | Batch 100/237 | Loss: 784.3118\n",
      "Epoch 816/1000 | Batch 200/237 | Loss: 1279.0790\n",
      "Epoch 816/1000 complete | Avg Loss: 4494.5725\n",
      "Epoch 817/1000 | Batch 0/237 | Loss: 8414.8584\n",
      "Epoch 817/1000 | Batch 100/237 | Loss: 1844.8396\n",
      "Epoch 817/1000 | Batch 200/237 | Loss: 1965.8503\n",
      "Epoch 817/1000 complete | Avg Loss: 4505.0087\n",
      "Epoch 818/1000 | Batch 0/237 | Loss: 851.1684\n",
      "Epoch 818/1000 | Batch 100/237 | Loss: 15110.1006\n",
      "Epoch 818/1000 | Batch 200/237 | Loss: 2106.1089\n",
      "Epoch 818/1000 complete | Avg Loss: 4508.2531\n",
      "Epoch 819/1000 | Batch 0/237 | Loss: 1331.9933\n",
      "Epoch 819/1000 | Batch 100/237 | Loss: 2541.1509\n",
      "Epoch 819/1000 | Batch 200/237 | Loss: 5252.6982\n",
      "Epoch 819/1000 complete | Avg Loss: 4492.1059\n",
      "Epoch 820/1000 | Batch 0/237 | Loss: 2883.6809\n",
      "Epoch 820/1000 | Batch 100/237 | Loss: 1291.3251\n",
      "Epoch 820/1000 | Batch 200/237 | Loss: 2912.3660\n",
      "Epoch 820/1000 complete | Avg Loss: 4499.1014\n",
      "Epoch 821/1000 | Batch 0/237 | Loss: 546.0409\n",
      "Epoch 821/1000 | Batch 100/237 | Loss: 1467.3326\n",
      "Epoch 821/1000 | Batch 200/237 | Loss: 1793.9220\n",
      "Epoch 821/1000 complete | Avg Loss: 4501.8806\n",
      "Epoch 822/1000 | Batch 0/237 | Loss: 13824.3887\n",
      "Epoch 822/1000 | Batch 100/237 | Loss: 1085.3024\n",
      "Epoch 822/1000 | Batch 200/237 | Loss: 949.9675\n",
      "Epoch 822/1000 complete | Avg Loss: 4500.7390\n",
      "Epoch 823/1000 | Batch 0/237 | Loss: 1894.0817\n",
      "Epoch 823/1000 | Batch 100/237 | Loss: 7046.0039\n",
      "Epoch 823/1000 | Batch 200/237 | Loss: 1230.4005\n",
      "Epoch 823/1000 complete | Avg Loss: 4497.3084\n",
      "Epoch 824/1000 | Batch 0/237 | Loss: 935.3072\n",
      "Epoch 824/1000 | Batch 100/237 | Loss: 679.4217\n",
      "Epoch 824/1000 | Batch 200/237 | Loss: 2670.1042\n",
      "Epoch 824/1000 complete | Avg Loss: 4513.1050\n",
      "Epoch 825/1000 | Batch 0/237 | Loss: 7420.6396\n",
      "Epoch 825/1000 | Batch 100/237 | Loss: 1301.6796\n",
      "Epoch 825/1000 | Batch 200/237 | Loss: 2054.1299\n",
      "Epoch 825/1000 complete | Avg Loss: 4497.8537\n",
      "Epoch 826/1000 | Batch 0/237 | Loss: 1825.3016\n",
      "Epoch 826/1000 | Batch 100/237 | Loss: 4624.4956\n",
      "Epoch 826/1000 | Batch 200/237 | Loss: 959.3438\n",
      "Epoch 826/1000 complete | Avg Loss: 4494.9662\n",
      "Epoch 827/1000 | Batch 0/237 | Loss: 9300.4980\n",
      "Epoch 827/1000 | Batch 100/237 | Loss: 2400.2107\n",
      "Epoch 827/1000 | Batch 200/237 | Loss: 945.3542\n",
      "Epoch 827/1000 complete | Avg Loss: 4500.1422\n",
      "Epoch 828/1000 | Batch 0/237 | Loss: 9737.3350\n",
      "Epoch 828/1000 | Batch 100/237 | Loss: 894.1231\n",
      "Epoch 828/1000 | Batch 200/237 | Loss: 2793.8037\n",
      "Epoch 828/1000 complete | Avg Loss: 4497.3569\n",
      "Epoch 829/1000 | Batch 0/237 | Loss: 2080.7515\n",
      "Epoch 829/1000 | Batch 100/237 | Loss: 9372.8994\n",
      "Epoch 829/1000 | Batch 200/237 | Loss: 1344.7319\n",
      "Epoch 829/1000 complete | Avg Loss: 4529.2804\n",
      "Epoch 830/1000 | Batch 0/237 | Loss: 2922.0894\n",
      "Epoch 830/1000 | Batch 100/237 | Loss: 1759.7242\n",
      "Epoch 830/1000 | Batch 200/237 | Loss: 1715.7317\n",
      "Epoch 830/1000 complete | Avg Loss: 4495.4679\n",
      "Epoch 831/1000 | Batch 0/237 | Loss: 14268.0303\n",
      "Epoch 831/1000 | Batch 100/237 | Loss: 1254.4692\n",
      "Epoch 831/1000 | Batch 200/237 | Loss: 2573.6326\n",
      "Epoch 831/1000 complete | Avg Loss: 4497.6864\n",
      "Epoch 832/1000 | Batch 0/237 | Loss: 13144.5400\n",
      "Epoch 832/1000 | Batch 100/237 | Loss: 1653.2579\n",
      "Epoch 832/1000 | Batch 200/237 | Loss: 602.9236\n",
      "Epoch 832/1000 complete | Avg Loss: 4501.7346\n",
      "Epoch 833/1000 | Batch 0/237 | Loss: 1280.9285\n",
      "Epoch 833/1000 | Batch 100/237 | Loss: 990.6151\n",
      "Epoch 833/1000 | Batch 200/237 | Loss: 14120.5186\n",
      "Epoch 833/1000 complete | Avg Loss: 4489.2920\n",
      "Epoch 834/1000 | Batch 0/237 | Loss: 1717.3931\n",
      "Epoch 834/1000 | Batch 100/237 | Loss: 1987.7937\n",
      "Epoch 834/1000 | Batch 200/237 | Loss: 1811.2810\n",
      "Epoch 834/1000 complete | Avg Loss: 4497.7002\n",
      "Epoch 835/1000 | Batch 0/237 | Loss: 2673.2166\n",
      "Epoch 835/1000 | Batch 100/237 | Loss: 955.6650\n",
      "Epoch 835/1000 | Batch 200/237 | Loss: 1636.7734\n",
      "Epoch 835/1000 complete | Avg Loss: 4492.4313\n",
      "Epoch 836/1000 | Batch 0/237 | Loss: 1114.0851\n",
      "Epoch 836/1000 | Batch 100/237 | Loss: 1519.8186\n",
      "Epoch 836/1000 | Batch 200/237 | Loss: 8311.1240\n",
      "Epoch 836/1000 complete | Avg Loss: 4500.4565\n",
      "Epoch 837/1000 | Batch 0/237 | Loss: 2574.1982\n",
      "Epoch 837/1000 | Batch 100/237 | Loss: 786.7469\n",
      "Epoch 837/1000 | Batch 200/237 | Loss: 6394.3467\n",
      "Epoch 837/1000 complete | Avg Loss: 4489.3516\n",
      "Epoch 838/1000 | Batch 0/237 | Loss: 4911.8037\n",
      "Epoch 838/1000 | Batch 100/237 | Loss: 545.2198\n",
      "Epoch 838/1000 | Batch 200/237 | Loss: 1097.8391\n",
      "Epoch 838/1000 complete | Avg Loss: 4505.5875\n",
      "Epoch 839/1000 | Batch 0/237 | Loss: 4107.8027\n",
      "Epoch 839/1000 | Batch 100/237 | Loss: 2591.3616\n",
      "Epoch 839/1000 | Batch 200/237 | Loss: 756.3973\n",
      "Epoch 839/1000 complete | Avg Loss: 4490.3431\n",
      "Epoch 840/1000 | Batch 0/237 | Loss: 5237.4634\n",
      "Epoch 840/1000 | Batch 100/237 | Loss: 2291.1538\n",
      "Epoch 840/1000 | Batch 200/237 | Loss: 843.3132\n",
      "Epoch 840/1000 complete | Avg Loss: 4491.4502\n",
      "Epoch 841/1000 | Batch 0/237 | Loss: 1618.5103\n",
      "Epoch 841/1000 | Batch 100/237 | Loss: 2284.3467\n",
      "Epoch 841/1000 | Batch 200/237 | Loss: 1041.4612\n",
      "Epoch 841/1000 complete | Avg Loss: 4485.9747\n",
      "Epoch 842/1000 | Batch 0/237 | Loss: 6976.7788\n",
      "Epoch 842/1000 | Batch 100/237 | Loss: 3125.9287\n",
      "Epoch 842/1000 | Batch 200/237 | Loss: 706.1909\n",
      "Epoch 842/1000 complete | Avg Loss: 4492.4284\n",
      "Epoch 843/1000 | Batch 0/237 | Loss: 1752.3070\n",
      "Epoch 843/1000 | Batch 100/237 | Loss: 3568.2461\n",
      "Epoch 843/1000 | Batch 200/237 | Loss: 23533.1270\n",
      "Epoch 843/1000 complete | Avg Loss: 4488.4942\n",
      "Epoch 844/1000 | Batch 0/237 | Loss: 1215.2380\n",
      "Epoch 844/1000 | Batch 100/237 | Loss: 939.8398\n",
      "Epoch 844/1000 | Batch 200/237 | Loss: 3174.9509\n",
      "Epoch 844/1000 complete | Avg Loss: 4486.2652\n",
      "Epoch 845/1000 | Batch 0/237 | Loss: 3485.5984\n",
      "Epoch 845/1000 | Batch 100/237 | Loss: 1198.3777\n",
      "Epoch 845/1000 | Batch 200/237 | Loss: 2110.0415\n",
      "Epoch 845/1000 complete | Avg Loss: 4542.8089\n",
      "Epoch 846/1000 | Batch 0/237 | Loss: 1413.8356\n",
      "Epoch 846/1000 | Batch 100/237 | Loss: 2668.5605\n",
      "Epoch 846/1000 | Batch 200/237 | Loss: 10675.3154\n",
      "Epoch 846/1000 complete | Avg Loss: 4489.7058\n",
      "Epoch 847/1000 | Batch 0/237 | Loss: 39164.9727\n",
      "Epoch 847/1000 | Batch 100/237 | Loss: 2694.6328\n",
      "Epoch 847/1000 | Batch 200/237 | Loss: 1182.0479\n",
      "Epoch 847/1000 complete | Avg Loss: 4489.6860\n",
      "Epoch 848/1000 | Batch 0/237 | Loss: 1370.6534\n",
      "Epoch 848/1000 | Batch 100/237 | Loss: 1803.9612\n",
      "Epoch 848/1000 | Batch 200/237 | Loss: 1269.6772\n",
      "Epoch 848/1000 complete | Avg Loss: 4500.3940\n",
      "Epoch 849/1000 | Batch 0/237 | Loss: 1956.3131\n",
      "Epoch 849/1000 | Batch 100/237 | Loss: 825.8142\n",
      "Epoch 849/1000 | Batch 200/237 | Loss: 4019.0386\n",
      "Epoch 849/1000 complete | Avg Loss: 4488.0204\n",
      "Epoch 850/1000 | Batch 0/237 | Loss: 1673.5769\n",
      "Epoch 850/1000 | Batch 100/237 | Loss: 2406.2881\n",
      "Epoch 850/1000 | Batch 200/237 | Loss: 1159.2959\n",
      "Epoch 850/1000 complete | Avg Loss: 4484.6403\n",
      "Epoch 851/1000 | Batch 0/237 | Loss: 1827.0133\n",
      "Epoch 851/1000 | Batch 100/237 | Loss: 2390.0852\n",
      "Epoch 851/1000 | Batch 200/237 | Loss: 2420.1047\n",
      "Epoch 851/1000 complete | Avg Loss: 4526.4754\n",
      "Epoch 852/1000 | Batch 0/237 | Loss: 6623.4092\n",
      "Epoch 852/1000 | Batch 100/237 | Loss: 2497.8030\n",
      "Epoch 852/1000 | Batch 200/237 | Loss: 1838.8687\n",
      "Epoch 852/1000 complete | Avg Loss: 4538.5344\n",
      "Epoch 853/1000 | Batch 0/237 | Loss: 1166.7264\n",
      "Epoch 853/1000 | Batch 100/237 | Loss: 739.7438\n",
      "Epoch 853/1000 | Batch 200/237 | Loss: 7353.3662\n",
      "Epoch 853/1000 complete | Avg Loss: 4487.5457\n",
      "Epoch 854/1000 | Batch 0/237 | Loss: 10933.8652\n",
      "Epoch 854/1000 | Batch 100/237 | Loss: 2948.1113\n",
      "Epoch 854/1000 | Batch 200/237 | Loss: 3003.4978\n",
      "Epoch 854/1000 complete | Avg Loss: 4482.8361\n",
      "Epoch 855/1000 | Batch 0/237 | Loss: 3609.2578\n",
      "Epoch 855/1000 | Batch 100/237 | Loss: 1052.6768\n",
      "Epoch 855/1000 | Batch 200/237 | Loss: 17211.5566\n",
      "Epoch 855/1000 complete | Avg Loss: 4490.2715\n",
      "Epoch 856/1000 | Batch 0/237 | Loss: 12143.3750\n",
      "Epoch 856/1000 | Batch 100/237 | Loss: 2061.6218\n",
      "Epoch 856/1000 | Batch 200/237 | Loss: 4968.0044\n",
      "Epoch 856/1000 complete | Avg Loss: 4492.2240\n",
      "Epoch 857/1000 | Batch 0/237 | Loss: 1464.5405\n",
      "Epoch 857/1000 | Batch 100/237 | Loss: 3329.1309\n",
      "Epoch 857/1000 | Batch 200/237 | Loss: 3176.4587\n",
      "Epoch 857/1000 complete | Avg Loss: 4556.9194\n",
      "Epoch 858/1000 | Batch 0/237 | Loss: 2007.0981\n",
      "Epoch 858/1000 | Batch 100/237 | Loss: 872.9577\n",
      "Epoch 858/1000 | Batch 200/237 | Loss: 11899.5586\n",
      "Epoch 858/1000 complete | Avg Loss: 4517.2974\n",
      "Epoch 859/1000 | Batch 0/237 | Loss: 9878.6797\n",
      "Epoch 859/1000 | Batch 100/237 | Loss: 4220.5913\n",
      "Epoch 859/1000 | Batch 200/237 | Loss: 3834.9622\n",
      "Epoch 859/1000 complete | Avg Loss: 4499.6786\n",
      "Epoch 860/1000 | Batch 0/237 | Loss: 4528.6855\n",
      "Epoch 860/1000 | Batch 100/237 | Loss: 1793.6464\n",
      "Epoch 860/1000 | Batch 200/237 | Loss: 888.0245\n",
      "Epoch 860/1000 complete | Avg Loss: 4484.1360\n",
      "Epoch 861/1000 | Batch 0/237 | Loss: 1662.8572\n",
      "Epoch 861/1000 | Batch 100/237 | Loss: 7171.5581\n",
      "Epoch 861/1000 | Batch 200/237 | Loss: 1397.5302\n",
      "Epoch 861/1000 complete | Avg Loss: 4484.3529\n",
      "Epoch 862/1000 | Batch 0/237 | Loss: 7236.2158\n",
      "Epoch 862/1000 | Batch 100/237 | Loss: 1068.7640\n",
      "Epoch 862/1000 | Batch 200/237 | Loss: 8260.9668\n",
      "Epoch 862/1000 complete | Avg Loss: 4599.8066\n",
      "Epoch 863/1000 | Batch 0/237 | Loss: 5592.0581\n",
      "Epoch 863/1000 | Batch 100/237 | Loss: 7689.2998\n",
      "Epoch 863/1000 | Batch 200/237 | Loss: 10405.2695\n",
      "Epoch 863/1000 complete | Avg Loss: 4477.9827\n",
      "Epoch 864/1000 | Batch 0/237 | Loss: 1688.2069\n",
      "Epoch 864/1000 | Batch 100/237 | Loss: 5595.0693\n",
      "Epoch 864/1000 | Batch 200/237 | Loss: 2544.7354\n",
      "Epoch 864/1000 complete | Avg Loss: 4484.6519\n",
      "Epoch 865/1000 | Batch 0/237 | Loss: 2201.7119\n",
      "Epoch 865/1000 | Batch 100/237 | Loss: 5680.3193\n",
      "Epoch 865/1000 | Batch 200/237 | Loss: 7820.5112\n",
      "Epoch 865/1000 complete | Avg Loss: 4484.9410\n",
      "Epoch 866/1000 | Batch 0/237 | Loss: 2962.7815\n",
      "Epoch 866/1000 | Batch 100/237 | Loss: 3688.5046\n",
      "Epoch 866/1000 | Batch 200/237 | Loss: 2117.1567\n",
      "Epoch 866/1000 complete | Avg Loss: 4479.5990\n",
      "Epoch 867/1000 | Batch 0/237 | Loss: 1359.7727\n",
      "Epoch 867/1000 | Batch 100/237 | Loss: 1131.9938\n",
      "Epoch 867/1000 | Batch 200/237 | Loss: 2732.6348\n",
      "Epoch 867/1000 complete | Avg Loss: 4485.0652\n",
      "Epoch 868/1000 | Batch 0/237 | Loss: 4277.4683\n",
      "Epoch 868/1000 | Batch 100/237 | Loss: 37922.5195\n",
      "Epoch 868/1000 | Batch 200/237 | Loss: 7135.2114\n",
      "Epoch 868/1000 complete | Avg Loss: 4483.0398\n",
      "Epoch 869/1000 | Batch 0/237 | Loss: 23714.4531\n",
      "Epoch 869/1000 | Batch 100/237 | Loss: 2413.3750\n",
      "Epoch 869/1000 | Batch 200/237 | Loss: 2723.5474\n",
      "Epoch 869/1000 complete | Avg Loss: 4481.4977\n",
      "Epoch 870/1000 | Batch 0/237 | Loss: 2862.0017\n",
      "Epoch 870/1000 | Batch 100/237 | Loss: 1536.5480\n",
      "Epoch 870/1000 | Batch 200/237 | Loss: 2102.7061\n",
      "Epoch 870/1000 complete | Avg Loss: 4505.6684\n",
      "Epoch 871/1000 | Batch 0/237 | Loss: 1014.7531\n",
      "Epoch 871/1000 | Batch 100/237 | Loss: 12070.5146\n",
      "Epoch 871/1000 | Batch 200/237 | Loss: 8888.0898\n",
      "Epoch 871/1000 complete | Avg Loss: 4500.5087\n",
      "Epoch 872/1000 | Batch 0/237 | Loss: 10736.4717\n",
      "Epoch 872/1000 | Batch 100/237 | Loss: 2417.9307\n",
      "Epoch 872/1000 | Batch 200/237 | Loss: 3355.8467\n",
      "Epoch 872/1000 complete | Avg Loss: 4483.8139\n",
      "Epoch 873/1000 | Batch 0/237 | Loss: 3014.8108\n",
      "Epoch 873/1000 | Batch 100/237 | Loss: 3756.0491\n",
      "Epoch 873/1000 | Batch 200/237 | Loss: 2765.3511\n",
      "Epoch 873/1000 complete | Avg Loss: 4478.9866\n",
      "Epoch 874/1000 | Batch 0/237 | Loss: 6722.9053\n",
      "Epoch 874/1000 | Batch 100/237 | Loss: 6273.7876\n",
      "Epoch 874/1000 | Batch 200/237 | Loss: 2533.9617\n",
      "Epoch 874/1000 complete | Avg Loss: 4479.1385\n",
      "Epoch 875/1000 | Batch 0/237 | Loss: 4217.3706\n",
      "Epoch 875/1000 | Batch 100/237 | Loss: 7155.2993\n",
      "Epoch 875/1000 | Batch 200/237 | Loss: 2304.4619\n",
      "Epoch 875/1000 complete | Avg Loss: 4481.0723\n",
      "Epoch 876/1000 | Batch 0/237 | Loss: 1847.7670\n",
      "Epoch 876/1000 | Batch 100/237 | Loss: 3209.3064\n",
      "Epoch 876/1000 | Batch 200/237 | Loss: 6698.3086\n",
      "Epoch 876/1000 complete | Avg Loss: 4477.8097\n",
      "Epoch 877/1000 | Batch 0/237 | Loss: 5317.4629\n",
      "Epoch 877/1000 | Batch 100/237 | Loss: 2501.7981\n",
      "Epoch 877/1000 | Batch 200/237 | Loss: 33243.1016\n",
      "Epoch 877/1000 complete | Avg Loss: 4475.8937\n",
      "Epoch 878/1000 | Batch 0/237 | Loss: 5023.1172\n",
      "Epoch 878/1000 | Batch 100/237 | Loss: 1031.7793\n",
      "Epoch 878/1000 | Batch 200/237 | Loss: 1231.4354\n",
      "Epoch 878/1000 complete | Avg Loss: 4494.4327\n",
      "Epoch 879/1000 | Batch 0/237 | Loss: 2286.1790\n",
      "Epoch 879/1000 | Batch 100/237 | Loss: 3146.7507\n",
      "Epoch 879/1000 | Batch 200/237 | Loss: 2397.0444\n",
      "Epoch 879/1000 complete | Avg Loss: 4497.9792\n",
      "Epoch 880/1000 | Batch 0/237 | Loss: 625.7794\n",
      "Epoch 880/1000 | Batch 100/237 | Loss: 2183.1121\n",
      "Epoch 880/1000 | Batch 200/237 | Loss: 4418.3481\n",
      "Epoch 880/1000 complete | Avg Loss: 4496.6083\n",
      "Epoch 881/1000 | Batch 0/237 | Loss: 890.7615\n",
      "Epoch 881/1000 | Batch 100/237 | Loss: 2224.8379\n",
      "Epoch 881/1000 | Batch 200/237 | Loss: 3231.7415\n",
      "Epoch 881/1000 complete | Avg Loss: 4472.6012\n",
      "Epoch 882/1000 | Batch 0/237 | Loss: 2867.4399\n",
      "Epoch 882/1000 | Batch 100/237 | Loss: 2197.0115\n",
      "Epoch 882/1000 | Batch 200/237 | Loss: 10854.7979\n",
      "Epoch 882/1000 complete | Avg Loss: 4477.5316\n",
      "Epoch 883/1000 | Batch 0/237 | Loss: 856.2007\n",
      "Epoch 883/1000 | Batch 100/237 | Loss: 1553.6396\n",
      "Epoch 883/1000 | Batch 200/237 | Loss: 2397.4993\n",
      "Epoch 883/1000 complete | Avg Loss: 4479.3337\n",
      "Epoch 884/1000 | Batch 0/237 | Loss: 4224.5479\n",
      "Epoch 884/1000 | Batch 100/237 | Loss: 5319.8013\n",
      "Epoch 884/1000 | Batch 200/237 | Loss: 4037.7090\n",
      "Epoch 884/1000 complete | Avg Loss: 4487.4281\n",
      "Epoch 885/1000 | Batch 0/237 | Loss: 7695.3057\n",
      "Epoch 885/1000 | Batch 100/237 | Loss: 18200.1172\n",
      "Epoch 885/1000 | Batch 200/237 | Loss: 1183.3469\n",
      "Epoch 885/1000 complete | Avg Loss: 4479.3185\n",
      "Epoch 886/1000 | Batch 0/237 | Loss: 1953.5419\n",
      "Epoch 886/1000 | Batch 100/237 | Loss: 2652.2390\n",
      "Epoch 886/1000 | Batch 200/237 | Loss: 1551.4238\n",
      "Epoch 886/1000 complete | Avg Loss: 4483.5566\n",
      "Epoch 887/1000 | Batch 0/237 | Loss: 2924.9326\n",
      "Epoch 887/1000 | Batch 100/237 | Loss: 2072.0105\n",
      "Epoch 887/1000 | Batch 200/237 | Loss: 3383.3594\n",
      "Epoch 887/1000 complete | Avg Loss: 4473.9528\n",
      "Epoch 888/1000 | Batch 0/237 | Loss: 790.7530\n",
      "Epoch 888/1000 | Batch 100/237 | Loss: 2104.8025\n",
      "Epoch 888/1000 | Batch 200/237 | Loss: 2036.3760\n",
      "Epoch 888/1000 complete | Avg Loss: 4474.0539\n",
      "Epoch 889/1000 | Batch 0/237 | Loss: 2542.2273\n",
      "Epoch 889/1000 | Batch 100/237 | Loss: 1665.4312\n",
      "Epoch 889/1000 | Batch 200/237 | Loss: 744.2217\n",
      "Epoch 889/1000 complete | Avg Loss: 4482.3862\n",
      "Epoch 890/1000 | Batch 0/237 | Loss: 1064.0341\n",
      "Epoch 890/1000 | Batch 100/237 | Loss: 1147.6709\n",
      "Epoch 890/1000 | Batch 200/237 | Loss: 2898.3806\n",
      "Epoch 890/1000 complete | Avg Loss: 4477.6561\n",
      "Epoch 891/1000 | Batch 0/237 | Loss: 1286.2831\n",
      "Epoch 891/1000 | Batch 100/237 | Loss: 1303.3633\n",
      "Epoch 891/1000 | Batch 200/237 | Loss: 1612.3342\n",
      "Epoch 891/1000 complete | Avg Loss: 4472.7650\n",
      "Epoch 892/1000 | Batch 0/237 | Loss: 1798.7772\n",
      "Epoch 892/1000 | Batch 100/237 | Loss: 7245.8647\n",
      "Epoch 892/1000 | Batch 200/237 | Loss: 2953.3389\n",
      "Epoch 892/1000 complete | Avg Loss: 4478.0839\n",
      "Epoch 893/1000 | Batch 0/237 | Loss: 3215.8022\n",
      "Epoch 893/1000 | Batch 100/237 | Loss: 3167.5090\n",
      "Epoch 893/1000 | Batch 200/237 | Loss: 2095.3835\n",
      "Epoch 893/1000 complete | Avg Loss: 4479.8789\n",
      "Epoch 894/1000 | Batch 0/237 | Loss: 2810.6440\n",
      "Epoch 894/1000 | Batch 100/237 | Loss: 1582.0286\n",
      "Epoch 894/1000 | Batch 200/237 | Loss: 1272.3699\n",
      "Epoch 894/1000 complete | Avg Loss: 4483.6993\n",
      "Epoch 895/1000 | Batch 0/237 | Loss: 3678.8140\n",
      "Epoch 895/1000 | Batch 100/237 | Loss: 2049.4358\n",
      "Epoch 895/1000 | Batch 200/237 | Loss: 941.6163\n",
      "Epoch 895/1000 complete | Avg Loss: 4502.0684\n",
      "Epoch 896/1000 | Batch 0/237 | Loss: 1975.6136\n",
      "Epoch 896/1000 | Batch 100/237 | Loss: 2233.5493\n",
      "Epoch 896/1000 | Batch 200/237 | Loss: 2014.8218\n",
      "Epoch 896/1000 complete | Avg Loss: 4463.3360\n",
      "Epoch 897/1000 | Batch 0/237 | Loss: 1541.5446\n",
      "Epoch 897/1000 | Batch 100/237 | Loss: 804.8632\n",
      "Epoch 897/1000 | Batch 200/237 | Loss: 2201.2026\n",
      "Epoch 897/1000 complete | Avg Loss: 4470.9755\n",
      "Epoch 898/1000 | Batch 0/237 | Loss: 1315.8000\n",
      "Epoch 898/1000 | Batch 100/237 | Loss: 10712.0586\n",
      "Epoch 898/1000 | Batch 200/237 | Loss: 914.5469\n",
      "Epoch 898/1000 complete | Avg Loss: 4476.7971\n",
      "Epoch 899/1000 | Batch 0/237 | Loss: 3188.7737\n",
      "Epoch 899/1000 | Batch 100/237 | Loss: 4459.8584\n",
      "Epoch 899/1000 | Batch 200/237 | Loss: 2058.1455\n",
      "Epoch 899/1000 complete | Avg Loss: 4468.6387\n",
      "Epoch 900/1000 | Batch 0/237 | Loss: 2609.6853\n",
      "Epoch 900/1000 | Batch 100/237 | Loss: 707.2790\n",
      "Epoch 900/1000 | Batch 200/237 | Loss: 8514.3447\n",
      "Epoch 900/1000 complete | Avg Loss: 4471.7641\n",
      "Epoch 901/1000 | Batch 0/237 | Loss: 845.9830\n",
      "Epoch 901/1000 | Batch 100/237 | Loss: 1652.8105\n",
      "Epoch 901/1000 | Batch 200/237 | Loss: 4604.5068\n",
      "Epoch 901/1000 complete | Avg Loss: 4503.5886\n",
      "Epoch 902/1000 | Batch 0/237 | Loss: 2876.8755\n",
      "Epoch 902/1000 | Batch 100/237 | Loss: 5034.5093\n",
      "Epoch 902/1000 | Batch 200/237 | Loss: 1469.4603\n",
      "Epoch 902/1000 complete | Avg Loss: 4471.1501\n",
      "Epoch 903/1000 | Batch 0/237 | Loss: 908.4398\n",
      "Epoch 903/1000 | Batch 100/237 | Loss: 6976.1665\n",
      "Epoch 903/1000 | Batch 200/237 | Loss: 2872.6072\n",
      "Epoch 903/1000 complete | Avg Loss: 4473.5112\n",
      "Epoch 904/1000 | Batch 0/237 | Loss: 2151.1401\n",
      "Epoch 904/1000 | Batch 100/237 | Loss: 5490.7935\n",
      "Epoch 904/1000 | Batch 200/237 | Loss: 1077.0624\n",
      "Epoch 904/1000 complete | Avg Loss: 4469.4387\n",
      "Epoch 905/1000 | Batch 0/237 | Loss: 859.8733\n",
      "Epoch 905/1000 | Batch 100/237 | Loss: 2562.8091\n",
      "Epoch 905/1000 | Batch 200/237 | Loss: 1873.7050\n",
      "Epoch 905/1000 complete | Avg Loss: 4470.1610\n",
      "Epoch 906/1000 | Batch 0/237 | Loss: 800.2153\n",
      "Epoch 906/1000 | Batch 100/237 | Loss: 2609.1177\n",
      "Epoch 906/1000 | Batch 200/237 | Loss: 1403.3340\n",
      "Epoch 906/1000 complete | Avg Loss: 4468.3382\n",
      "Epoch 907/1000 | Batch 0/237 | Loss: 720.6694\n",
      "Epoch 907/1000 | Batch 100/237 | Loss: 1035.3776\n",
      "Epoch 907/1000 | Batch 200/237 | Loss: 1683.2568\n",
      "Epoch 907/1000 complete | Avg Loss: 4466.6904\n",
      "Epoch 908/1000 | Batch 0/237 | Loss: 7833.1807\n",
      "Epoch 908/1000 | Batch 100/237 | Loss: 2052.3120\n",
      "Epoch 908/1000 | Batch 200/237 | Loss: 3286.2959\n",
      "Epoch 908/1000 complete | Avg Loss: 4475.1880\n",
      "Epoch 909/1000 | Batch 0/237 | Loss: 904.3192\n",
      "Epoch 909/1000 | Batch 100/237 | Loss: 953.4235\n",
      "Epoch 909/1000 | Batch 200/237 | Loss: 1863.8599\n",
      "Epoch 909/1000 complete | Avg Loss: 4465.1255\n",
      "Epoch 910/1000 | Batch 0/237 | Loss: 5469.1704\n",
      "Epoch 910/1000 | Batch 100/237 | Loss: 4289.2080\n",
      "Epoch 910/1000 | Batch 200/237 | Loss: 5815.4263\n",
      "Epoch 910/1000 complete | Avg Loss: 4469.7631\n",
      "Epoch 911/1000 | Batch 0/237 | Loss: 2951.9116\n",
      "Epoch 911/1000 | Batch 100/237 | Loss: 3692.9951\n",
      "Epoch 911/1000 | Batch 200/237 | Loss: 1161.1749\n",
      "Epoch 911/1000 complete | Avg Loss: 4478.3361\n",
      "Epoch 912/1000 | Batch 0/237 | Loss: 12315.6172\n",
      "Epoch 912/1000 | Batch 100/237 | Loss: 2425.1333\n",
      "Epoch 912/1000 | Batch 200/237 | Loss: 4070.9690\n",
      "Epoch 912/1000 complete | Avg Loss: 4469.5202\n",
      "Epoch 913/1000 | Batch 0/237 | Loss: 7390.8276\n",
      "Epoch 913/1000 | Batch 100/237 | Loss: 7170.8521\n",
      "Epoch 913/1000 | Batch 200/237 | Loss: 13595.1582\n",
      "Epoch 913/1000 complete | Avg Loss: 4476.0797\n",
      "Epoch 914/1000 | Batch 0/237 | Loss: 4253.9287\n",
      "Epoch 914/1000 | Batch 100/237 | Loss: 1676.0724\n",
      "Epoch 914/1000 | Batch 200/237 | Loss: 637.5185\n",
      "Epoch 914/1000 complete | Avg Loss: 4465.4252\n",
      "Epoch 915/1000 | Batch 0/237 | Loss: 17063.1719\n",
      "Epoch 915/1000 | Batch 100/237 | Loss: 649.6445\n",
      "Epoch 915/1000 | Batch 200/237 | Loss: 6189.8340\n",
      "Epoch 915/1000 complete | Avg Loss: 4498.7310\n",
      "Epoch 916/1000 | Batch 0/237 | Loss: 3976.2893\n",
      "Epoch 916/1000 | Batch 100/237 | Loss: 1006.7462\n",
      "Epoch 916/1000 | Batch 200/237 | Loss: 4807.0938\n",
      "Epoch 916/1000 complete | Avg Loss: 4471.2451\n",
      "Epoch 917/1000 | Batch 0/237 | Loss: 4363.5552\n",
      "Epoch 917/1000 | Batch 100/237 | Loss: 9887.3271\n",
      "Epoch 917/1000 | Batch 200/237 | Loss: 1698.7822\n",
      "Epoch 917/1000 complete | Avg Loss: 4467.6761\n",
      "Epoch 918/1000 | Batch 0/237 | Loss: 8320.0859\n",
      "Epoch 918/1000 | Batch 100/237 | Loss: 2577.0188\n",
      "Epoch 918/1000 | Batch 200/237 | Loss: 24319.5273\n",
      "Epoch 918/1000 complete | Avg Loss: 4525.1528\n",
      "Epoch 919/1000 | Batch 0/237 | Loss: 9835.9775\n",
      "Epoch 919/1000 | Batch 100/237 | Loss: 4531.1836\n",
      "Epoch 919/1000 | Batch 200/237 | Loss: 3606.7505\n",
      "Epoch 919/1000 complete | Avg Loss: 4462.2253\n",
      "Epoch 920/1000 | Batch 0/237 | Loss: 2649.4407\n",
      "Epoch 920/1000 | Batch 100/237 | Loss: 837.7903\n",
      "Epoch 920/1000 | Batch 200/237 | Loss: 35634.7617\n",
      "Epoch 920/1000 complete | Avg Loss: 4468.6913\n",
      "Epoch 921/1000 | Batch 0/237 | Loss: 1408.4490\n",
      "Epoch 921/1000 | Batch 100/237 | Loss: 1279.9326\n",
      "Epoch 921/1000 | Batch 200/237 | Loss: 14774.2480\n",
      "Epoch 921/1000 complete | Avg Loss: 4466.6697\n",
      "Epoch 922/1000 | Batch 0/237 | Loss: 2566.1716\n",
      "Epoch 922/1000 | Batch 100/237 | Loss: 2993.3616\n",
      "Epoch 922/1000 | Batch 200/237 | Loss: 1335.5002\n",
      "Epoch 922/1000 complete | Avg Loss: 4469.8644\n",
      "Epoch 923/1000 | Batch 0/237 | Loss: 2227.5942\n",
      "Epoch 923/1000 | Batch 100/237 | Loss: 981.5214\n",
      "Epoch 923/1000 | Batch 200/237 | Loss: 1362.5483\n",
      "Epoch 923/1000 complete | Avg Loss: 4474.0189\n",
      "Epoch 924/1000 | Batch 0/237 | Loss: 1915.2754\n",
      "Epoch 924/1000 | Batch 100/237 | Loss: 968.2867\n",
      "Epoch 924/1000 | Batch 200/237 | Loss: 7527.7417\n",
      "Epoch 924/1000 complete | Avg Loss: 4469.6078\n",
      "Epoch 925/1000 | Batch 0/237 | Loss: 3426.9324\n",
      "Epoch 925/1000 | Batch 100/237 | Loss: 2709.4429\n",
      "Epoch 925/1000 | Batch 200/237 | Loss: 1703.1367\n",
      "Epoch 925/1000 complete | Avg Loss: 4468.1854\n",
      "Epoch 926/1000 | Batch 0/237 | Loss: 3167.0549\n",
      "Epoch 926/1000 | Batch 100/237 | Loss: 1356.3962\n",
      "Epoch 926/1000 | Batch 200/237 | Loss: 10792.7266\n",
      "Epoch 926/1000 complete | Avg Loss: 4470.4645\n",
      "Epoch 927/1000 | Batch 0/237 | Loss: 672.8036\n",
      "Epoch 927/1000 | Batch 100/237 | Loss: 1669.7157\n",
      "Epoch 927/1000 | Batch 200/237 | Loss: 7878.7510\n",
      "Epoch 927/1000 complete | Avg Loss: 4474.2500\n",
      "Epoch 928/1000 | Batch 0/237 | Loss: 2080.1316\n",
      "Epoch 928/1000 | Batch 100/237 | Loss: 1273.4138\n",
      "Epoch 928/1000 | Batch 200/237 | Loss: 828.7574\n",
      "Epoch 928/1000 complete | Avg Loss: 4459.2958\n",
      "Epoch 929/1000 | Batch 0/237 | Loss: 6244.1450\n",
      "Epoch 929/1000 | Batch 100/237 | Loss: 853.9362\n",
      "Epoch 929/1000 | Batch 200/237 | Loss: 2379.7698\n",
      "Epoch 929/1000 complete | Avg Loss: 4587.8663\n",
      "Epoch 930/1000 | Batch 0/237 | Loss: 1027.6754\n",
      "Epoch 930/1000 | Batch 100/237 | Loss: 1810.6544\n",
      "Epoch 930/1000 | Batch 200/237 | Loss: 43179.8281\n",
      "Epoch 930/1000 complete | Avg Loss: 4474.4200\n",
      "Epoch 931/1000 | Batch 0/237 | Loss: 1499.2332\n",
      "Epoch 931/1000 | Batch 100/237 | Loss: 1389.2614\n",
      "Epoch 931/1000 | Batch 200/237 | Loss: 1120.4249\n",
      "Epoch 931/1000 complete | Avg Loss: 4470.8195\n",
      "Epoch 932/1000 | Batch 0/237 | Loss: 2323.1431\n",
      "Epoch 932/1000 | Batch 100/237 | Loss: 1914.9122\n",
      "Epoch 932/1000 | Batch 200/237 | Loss: 10620.7031\n",
      "Epoch 932/1000 complete | Avg Loss: 4468.3179\n",
      "Epoch 933/1000 | Batch 0/237 | Loss: 917.8798\n",
      "Epoch 933/1000 | Batch 100/237 | Loss: 1577.4290\n",
      "Epoch 933/1000 | Batch 200/237 | Loss: 1652.3352\n",
      "Epoch 933/1000 complete | Avg Loss: 4455.5742\n",
      "Epoch 934/1000 | Batch 0/237 | Loss: 918.2528\n",
      "Epoch 934/1000 | Batch 100/237 | Loss: 1067.9888\n",
      "Epoch 934/1000 | Batch 200/237 | Loss: 3194.0698\n",
      "Epoch 934/1000 complete | Avg Loss: 4463.2755\n",
      "Epoch 935/1000 | Batch 0/237 | Loss: 21747.4023\n",
      "Epoch 935/1000 | Batch 100/237 | Loss: 2226.5901\n",
      "Epoch 935/1000 | Batch 200/237 | Loss: 3122.2148\n",
      "Epoch 935/1000 complete | Avg Loss: 4474.3620\n",
      "Epoch 936/1000 | Batch 0/237 | Loss: 1195.6605\n",
      "Epoch 936/1000 | Batch 100/237 | Loss: 1873.6873\n",
      "Epoch 936/1000 | Batch 200/237 | Loss: 8249.7217\n",
      "Epoch 936/1000 complete | Avg Loss: 4458.7168\n",
      "Epoch 937/1000 | Batch 0/237 | Loss: 14359.4277\n",
      "Epoch 937/1000 | Batch 100/237 | Loss: 1146.4979\n",
      "Epoch 937/1000 | Batch 200/237 | Loss: 977.7184\n",
      "Epoch 937/1000 complete | Avg Loss: 4502.4298\n",
      "Epoch 938/1000 | Batch 0/237 | Loss: 3668.1450\n",
      "Epoch 938/1000 | Batch 100/237 | Loss: 1412.7427\n",
      "Epoch 938/1000 | Batch 200/237 | Loss: 734.8043\n",
      "Epoch 938/1000 complete | Avg Loss: 4467.9419\n",
      "Epoch 939/1000 | Batch 0/237 | Loss: 1806.4084\n",
      "Epoch 939/1000 | Batch 100/237 | Loss: 1507.5419\n",
      "Epoch 939/1000 | Batch 200/237 | Loss: 1876.6598\n",
      "Epoch 939/1000 complete | Avg Loss: 4467.2121\n",
      "Epoch 940/1000 | Batch 0/237 | Loss: 3329.7654\n",
      "Epoch 940/1000 | Batch 100/237 | Loss: 621.4088\n",
      "Epoch 940/1000 | Batch 200/237 | Loss: 17965.3906\n",
      "Epoch 940/1000 complete | Avg Loss: 4460.2107\n",
      "Epoch 941/1000 | Batch 0/237 | Loss: 22350.0078\n",
      "Epoch 941/1000 | Batch 100/237 | Loss: 890.6907\n",
      "Epoch 941/1000 | Batch 200/237 | Loss: 2027.0310\n",
      "Epoch 941/1000 complete | Avg Loss: 4486.0698\n",
      "Epoch 942/1000 | Batch 0/237 | Loss: 1668.4010\n",
      "Epoch 942/1000 | Batch 100/237 | Loss: 1401.7958\n",
      "Epoch 942/1000 | Batch 200/237 | Loss: 1414.1414\n",
      "Epoch 942/1000 complete | Avg Loss: 4457.3958\n",
      "Epoch 943/1000 | Batch 0/237 | Loss: 1159.5012\n",
      "Epoch 943/1000 | Batch 100/237 | Loss: 5633.9854\n",
      "Epoch 943/1000 | Batch 200/237 | Loss: 9658.4941\n",
      "Epoch 943/1000 complete | Avg Loss: 4465.7283\n",
      "Epoch 944/1000 | Batch 0/237 | Loss: 5183.8018\n",
      "Epoch 944/1000 | Batch 100/237 | Loss: 1656.7803\n",
      "Epoch 944/1000 | Batch 200/237 | Loss: 1627.5439\n",
      "Epoch 944/1000 complete | Avg Loss: 4457.1394\n",
      "Epoch 945/1000 | Batch 0/237 | Loss: 1312.0444\n",
      "Epoch 945/1000 | Batch 100/237 | Loss: 689.4072\n",
      "Epoch 945/1000 | Batch 200/237 | Loss: 2297.8706\n",
      "Epoch 945/1000 complete | Avg Loss: 4470.8314\n",
      "Epoch 946/1000 | Batch 0/237 | Loss: 1199.3896\n",
      "Epoch 946/1000 | Batch 100/237 | Loss: 1841.1824\n",
      "Epoch 946/1000 | Batch 200/237 | Loss: 4099.2920\n",
      "Epoch 946/1000 complete | Avg Loss: 4455.6067\n",
      "Epoch 947/1000 | Batch 0/237 | Loss: 3717.3171\n",
      "Epoch 947/1000 | Batch 100/237 | Loss: 7352.9668\n",
      "Epoch 947/1000 | Batch 200/237 | Loss: 1083.4818\n",
      "Epoch 947/1000 complete | Avg Loss: 4459.9867\n",
      "Epoch 948/1000 | Batch 0/237 | Loss: 4460.7002\n",
      "Epoch 948/1000 | Batch 100/237 | Loss: 755.0610\n",
      "Epoch 948/1000 | Batch 200/237 | Loss: 1387.4955\n",
      "Epoch 948/1000 complete | Avg Loss: 4457.5243\n",
      "Epoch 949/1000 | Batch 0/237 | Loss: 2122.9043\n",
      "Epoch 949/1000 | Batch 100/237 | Loss: 7688.5439\n",
      "Epoch 949/1000 | Batch 200/237 | Loss: 1233.4708\n",
      "Epoch 949/1000 complete | Avg Loss: 4464.0499\n",
      "Epoch 950/1000 | Batch 0/237 | Loss: 2182.1509\n",
      "Epoch 950/1000 | Batch 100/237 | Loss: 5621.4033\n",
      "Epoch 950/1000 | Batch 200/237 | Loss: 4418.7871\n",
      "Epoch 950/1000 complete | Avg Loss: 4458.8894\n",
      "Epoch 951/1000 | Batch 0/237 | Loss: 11787.0332\n",
      "Epoch 951/1000 | Batch 100/237 | Loss: 1849.3823\n",
      "Epoch 951/1000 | Batch 200/237 | Loss: 1270.4008\n",
      "Epoch 951/1000 complete | Avg Loss: 4470.5655\n",
      "Epoch 952/1000 | Batch 0/237 | Loss: 2269.8145\n",
      "Epoch 952/1000 | Batch 100/237 | Loss: 8181.7397\n",
      "Epoch 952/1000 | Batch 200/237 | Loss: 1830.1470\n",
      "Epoch 952/1000 complete | Avg Loss: 4475.2986\n",
      "Epoch 953/1000 | Batch 0/237 | Loss: 2485.0342\n",
      "Epoch 953/1000 | Batch 100/237 | Loss: 3719.1860\n",
      "Epoch 953/1000 | Batch 200/237 | Loss: 1138.5919\n",
      "Epoch 953/1000 complete | Avg Loss: 4459.0583\n",
      "Epoch 954/1000 | Batch 0/237 | Loss: 702.0328\n",
      "Epoch 954/1000 | Batch 100/237 | Loss: 733.5106\n",
      "Epoch 954/1000 | Batch 200/237 | Loss: 1502.9849\n",
      "Epoch 954/1000 complete | Avg Loss: 4461.2066\n",
      "Epoch 955/1000 | Batch 0/237 | Loss: 1916.8037\n",
      "Epoch 955/1000 | Batch 100/237 | Loss: 1121.1096\n",
      "Epoch 955/1000 | Batch 200/237 | Loss: 2012.1851\n",
      "Epoch 955/1000 complete | Avg Loss: 4457.9491\n",
      "Epoch 956/1000 | Batch 0/237 | Loss: 1755.2566\n",
      "Epoch 956/1000 | Batch 100/237 | Loss: 911.8631\n",
      "Epoch 956/1000 | Batch 200/237 | Loss: 2983.8638\n",
      "Epoch 956/1000 complete | Avg Loss: 4464.1420\n",
      "Epoch 957/1000 | Batch 0/237 | Loss: 6243.1499\n",
      "Epoch 957/1000 | Batch 100/237 | Loss: 1547.9291\n",
      "Epoch 957/1000 | Batch 200/237 | Loss: 1656.6301\n",
      "Epoch 957/1000 complete | Avg Loss: 4457.2776\n",
      "Epoch 958/1000 | Batch 0/237 | Loss: 2449.3801\n",
      "Epoch 958/1000 | Batch 100/237 | Loss: 4418.5005\n",
      "Epoch 958/1000 | Batch 200/237 | Loss: 2065.0171\n",
      "Epoch 958/1000 complete | Avg Loss: 4472.0334\n",
      "Epoch 959/1000 | Batch 0/237 | Loss: 2236.1440\n",
      "Epoch 959/1000 | Batch 100/237 | Loss: 7749.0566\n",
      "Epoch 959/1000 | Batch 200/237 | Loss: 1145.8693\n",
      "Epoch 959/1000 complete | Avg Loss: 4484.6173\n",
      "Epoch 960/1000 | Batch 0/237 | Loss: 669.5102\n",
      "Epoch 960/1000 | Batch 100/237 | Loss: 2411.5720\n",
      "Epoch 960/1000 | Batch 200/237 | Loss: 4371.8008\n",
      "Epoch 960/1000 complete | Avg Loss: 4455.5519\n",
      "Epoch 961/1000 | Batch 0/237 | Loss: 5767.5205\n",
      "Epoch 961/1000 | Batch 100/237 | Loss: 1674.3199\n",
      "Epoch 961/1000 | Batch 200/237 | Loss: 2017.2026\n",
      "Epoch 961/1000 complete | Avg Loss: 4457.9008\n",
      "Epoch 962/1000 | Batch 0/237 | Loss: 1002.3905\n",
      "Epoch 962/1000 | Batch 100/237 | Loss: 2570.1091\n",
      "Epoch 962/1000 | Batch 200/237 | Loss: 4581.1533\n",
      "Epoch 962/1000 complete | Avg Loss: 4520.6315\n",
      "Epoch 963/1000 | Batch 0/237 | Loss: 1307.9520\n",
      "Epoch 963/1000 | Batch 100/237 | Loss: 1821.8094\n",
      "Epoch 963/1000 | Batch 200/237 | Loss: 6243.3887\n",
      "Epoch 963/1000 complete | Avg Loss: 4456.6168\n",
      "Epoch 964/1000 | Batch 0/237 | Loss: 624.5494\n",
      "Epoch 964/1000 | Batch 100/237 | Loss: 5204.0142\n",
      "Epoch 964/1000 | Batch 200/237 | Loss: 1579.3407\n",
      "Epoch 964/1000 complete | Avg Loss: 4474.3627\n",
      "Epoch 965/1000 | Batch 0/237 | Loss: 2231.8770\n",
      "Epoch 965/1000 | Batch 100/237 | Loss: 7224.3325\n",
      "Epoch 965/1000 | Batch 200/237 | Loss: 1247.0920\n",
      "Epoch 965/1000 complete | Avg Loss: 4449.9082\n",
      "Epoch 966/1000 | Batch 0/237 | Loss: 2973.0515\n",
      "Epoch 966/1000 | Batch 100/237 | Loss: 15918.9521\n",
      "Epoch 966/1000 | Batch 200/237 | Loss: 4797.8130\n",
      "Epoch 966/1000 complete | Avg Loss: 4456.9014\n",
      "Epoch 967/1000 | Batch 0/237 | Loss: 6436.8027\n",
      "Epoch 967/1000 | Batch 100/237 | Loss: 3364.4243\n",
      "Epoch 967/1000 | Batch 200/237 | Loss: 6585.8833\n",
      "Epoch 967/1000 complete | Avg Loss: 4456.0251\n",
      "Epoch 968/1000 | Batch 0/237 | Loss: 1325.9808\n",
      "Epoch 968/1000 | Batch 100/237 | Loss: 2235.3108\n",
      "Epoch 968/1000 | Batch 200/237 | Loss: 4206.3750\n",
      "Epoch 968/1000 complete | Avg Loss: 4456.5995\n",
      "Epoch 969/1000 | Batch 0/237 | Loss: 561.7670\n",
      "Epoch 969/1000 | Batch 100/237 | Loss: 6524.4399\n",
      "Epoch 969/1000 | Batch 200/237 | Loss: 2794.0911\n",
      "Epoch 969/1000 complete | Avg Loss: 4456.7000\n",
      "Epoch 970/1000 | Batch 0/237 | Loss: 1387.9811\n",
      "Epoch 970/1000 | Batch 100/237 | Loss: 2058.6606\n",
      "Epoch 970/1000 | Batch 200/237 | Loss: 1478.0925\n",
      "Epoch 970/1000 complete | Avg Loss: 4568.1771\n",
      "Epoch 971/1000 | Batch 0/237 | Loss: 1556.4622\n",
      "Epoch 971/1000 | Batch 100/237 | Loss: 1124.6985\n",
      "Epoch 971/1000 | Batch 200/237 | Loss: 13685.4756\n",
      "Epoch 971/1000 complete | Avg Loss: 4485.0996\n",
      "Epoch 972/1000 | Batch 0/237 | Loss: 5610.2104\n",
      "Epoch 972/1000 | Batch 100/237 | Loss: 4787.3701\n",
      "Epoch 972/1000 | Batch 200/237 | Loss: 1714.7034\n",
      "Epoch 972/1000 complete | Avg Loss: 4499.1312\n",
      "Epoch 973/1000 | Batch 0/237 | Loss: 1338.8527\n",
      "Epoch 973/1000 | Batch 100/237 | Loss: 1108.9403\n",
      "Epoch 973/1000 | Batch 200/237 | Loss: 3752.6809\n",
      "Epoch 973/1000 complete | Avg Loss: 4463.9056\n",
      "Epoch 974/1000 | Batch 0/237 | Loss: 2575.7310\n",
      "Epoch 974/1000 | Batch 100/237 | Loss: 616.2259\n",
      "Epoch 974/1000 | Batch 200/237 | Loss: 7401.1270\n",
      "Epoch 974/1000 complete | Avg Loss: 4446.3974\n",
      "Epoch 975/1000 | Batch 0/237 | Loss: 1583.7192\n",
      "Epoch 975/1000 | Batch 100/237 | Loss: 1480.0533\n",
      "Epoch 975/1000 | Batch 200/237 | Loss: 4688.1274\n",
      "Epoch 975/1000 complete | Avg Loss: 4449.6630\n",
      "Epoch 976/1000 | Batch 0/237 | Loss: 2921.8823\n",
      "Epoch 976/1000 | Batch 100/237 | Loss: 2720.2407\n",
      "Epoch 976/1000 | Batch 200/237 | Loss: 1934.3411\n",
      "Epoch 976/1000 complete | Avg Loss: 4455.6650\n",
      "Epoch 977/1000 | Batch 0/237 | Loss: 2724.2102\n",
      "Epoch 977/1000 | Batch 100/237 | Loss: 929.9121\n",
      "Epoch 977/1000 | Batch 200/237 | Loss: 1876.1176\n",
      "Epoch 977/1000 complete | Avg Loss: 4447.8639\n",
      "Epoch 978/1000 | Batch 0/237 | Loss: 6492.4126\n",
      "Epoch 978/1000 | Batch 100/237 | Loss: 1561.3350\n",
      "Epoch 978/1000 | Batch 200/237 | Loss: 1175.7515\n",
      "Epoch 978/1000 complete | Avg Loss: 4453.3282\n",
      "Epoch 979/1000 | Batch 0/237 | Loss: 857.8654\n",
      "Epoch 979/1000 | Batch 100/237 | Loss: 2578.9468\n",
      "Epoch 979/1000 | Batch 200/237 | Loss: 16268.4453\n",
      "Epoch 979/1000 complete | Avg Loss: 4461.5329\n",
      "Epoch 980/1000 | Batch 0/237 | Loss: 2211.5276\n",
      "Epoch 980/1000 | Batch 100/237 | Loss: 3947.7109\n",
      "Epoch 980/1000 | Batch 200/237 | Loss: 4388.1406\n",
      "Epoch 980/1000 complete | Avg Loss: 4456.4090\n",
      "Epoch 981/1000 | Batch 0/237 | Loss: 1807.5187\n",
      "Epoch 981/1000 | Batch 100/237 | Loss: 6435.4487\n",
      "Epoch 981/1000 | Batch 200/237 | Loss: 4018.4893\n",
      "Epoch 981/1000 complete | Avg Loss: 4444.5276\n",
      "Epoch 982/1000 | Batch 0/237 | Loss: 36062.1094\n",
      "Epoch 982/1000 | Batch 100/237 | Loss: 2374.3462\n",
      "Epoch 982/1000 | Batch 200/237 | Loss: 1173.7310\n",
      "Epoch 982/1000 complete | Avg Loss: 4455.3796\n",
      "Epoch 983/1000 | Batch 0/237 | Loss: 2383.2200\n",
      "Epoch 983/1000 | Batch 100/237 | Loss: 1132.1099\n",
      "Epoch 983/1000 | Batch 200/237 | Loss: 1620.8954\n",
      "Epoch 983/1000 complete | Avg Loss: 4451.3840\n",
      "Epoch 984/1000 | Batch 0/237 | Loss: 655.7560\n",
      "Epoch 984/1000 | Batch 100/237 | Loss: 5497.2051\n",
      "Epoch 984/1000 | Batch 200/237 | Loss: 2101.7207\n",
      "Epoch 984/1000 complete | Avg Loss: 4451.6838\n",
      "Epoch 985/1000 | Batch 0/237 | Loss: 861.5259\n",
      "Epoch 985/1000 | Batch 100/237 | Loss: 3678.1299\n",
      "Epoch 985/1000 | Batch 200/237 | Loss: 2025.3896\n",
      "Epoch 985/1000 complete | Avg Loss: 4461.0772\n",
      "Epoch 986/1000 | Batch 0/237 | Loss: 1856.4016\n",
      "Epoch 986/1000 | Batch 100/237 | Loss: 1300.5490\n",
      "Epoch 986/1000 | Batch 200/237 | Loss: 1845.2080\n",
      "Epoch 986/1000 complete | Avg Loss: 4447.6456\n",
      "Epoch 987/1000 | Batch 0/237 | Loss: 10118.8721\n",
      "Epoch 987/1000 | Batch 100/237 | Loss: 1247.1104\n",
      "Epoch 987/1000 | Batch 200/237 | Loss: 3187.4331\n",
      "Epoch 987/1000 complete | Avg Loss: 4458.3042\n",
      "Epoch 988/1000 | Batch 0/237 | Loss: 1297.2263\n",
      "Epoch 988/1000 | Batch 100/237 | Loss: 2939.7544\n",
      "Epoch 988/1000 | Batch 200/237 | Loss: 2751.9084\n",
      "Epoch 988/1000 complete | Avg Loss: 4451.9958\n",
      "Epoch 989/1000 | Batch 0/237 | Loss: 1231.6639\n",
      "Epoch 989/1000 | Batch 100/237 | Loss: 759.8317\n",
      "Epoch 989/1000 | Batch 200/237 | Loss: 773.7610\n",
      "Epoch 989/1000 complete | Avg Loss: 4444.2595\n",
      "Epoch 990/1000 | Batch 0/237 | Loss: 7253.4229\n",
      "Epoch 990/1000 | Batch 100/237 | Loss: 6756.3281\n",
      "Epoch 990/1000 | Batch 200/237 | Loss: 3691.1372\n",
      "Epoch 990/1000 complete | Avg Loss: 4449.8672\n",
      "Epoch 991/1000 | Batch 0/237 | Loss: 1676.0211\n",
      "Epoch 991/1000 | Batch 100/237 | Loss: 3224.6865\n",
      "Epoch 991/1000 | Batch 200/237 | Loss: 1223.5745\n",
      "Epoch 991/1000 complete | Avg Loss: 4452.0568\n",
      "Epoch 992/1000 | Batch 0/237 | Loss: 1159.3743\n",
      "Epoch 992/1000 | Batch 100/237 | Loss: 11184.0342\n",
      "Epoch 992/1000 | Batch 200/237 | Loss: 3039.4060\n",
      "Epoch 992/1000 complete | Avg Loss: 4443.4478\n",
      "Epoch 993/1000 | Batch 0/237 | Loss: 9603.5684\n",
      "Epoch 993/1000 | Batch 100/237 | Loss: 3734.3110\n",
      "Epoch 993/1000 | Batch 200/237 | Loss: 1084.1089\n",
      "Epoch 993/1000 complete | Avg Loss: 4448.9409\n",
      "Epoch 994/1000 | Batch 0/237 | Loss: 2679.1057\n",
      "Epoch 994/1000 | Batch 100/237 | Loss: 2195.0659\n",
      "Epoch 994/1000 | Batch 200/237 | Loss: 1235.2050\n",
      "Epoch 994/1000 complete | Avg Loss: 4447.9706\n",
      "Epoch 995/1000 | Batch 0/237 | Loss: 819.1988\n",
      "Epoch 995/1000 | Batch 100/237 | Loss: 2209.0117\n",
      "Epoch 995/1000 | Batch 200/237 | Loss: 1572.9941\n",
      "Epoch 995/1000 complete | Avg Loss: 4449.2511\n",
      "Epoch 996/1000 | Batch 0/237 | Loss: 617.2460\n",
      "Epoch 996/1000 | Batch 100/237 | Loss: 788.4062\n",
      "Epoch 996/1000 | Batch 200/237 | Loss: 1709.4423\n",
      "Epoch 996/1000 complete | Avg Loss: 4452.0700\n",
      "Epoch 997/1000 | Batch 0/237 | Loss: 685.3280\n",
      "Epoch 997/1000 | Batch 100/237 | Loss: 14512.5898\n",
      "Epoch 997/1000 | Batch 200/237 | Loss: 5034.4961\n",
      "Epoch 997/1000 complete | Avg Loss: 4447.6476\n",
      "Epoch 998/1000 | Batch 0/237 | Loss: 1125.5743\n",
      "Epoch 998/1000 | Batch 100/237 | Loss: 943.9742\n",
      "Epoch 998/1000 | Batch 200/237 | Loss: 3180.6313\n",
      "Epoch 998/1000 complete | Avg Loss: 4443.0580\n",
      "Epoch 999/1000 | Batch 0/237 | Loss: 1089.3591\n",
      "Epoch 999/1000 | Batch 100/237 | Loss: 8820.4990\n",
      "Epoch 999/1000 | Batch 200/237 | Loss: 3777.6460\n",
      "Epoch 999/1000 complete | Avg Loss: 4450.7078\n",
      "Epoch 1000/1000 | Batch 0/237 | Loss: 1245.1201\n",
      "Epoch 1000/1000 | Batch 100/237 | Loss: 1355.9402\n",
      "Epoch 1000/1000 | Batch 200/237 | Loss: 2714.6733\n",
      "Epoch 1000/1000 complete | Avg Loss: 4451.1644\n"
     ]
    }
   ],
   "source": [
    "# Update 2\n",
    "\n",
    "# Training loop\n",
    "reg_epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(X_titles, Y_scores)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=True)\n",
    "\n",
    "# Initialize optimizer\n",
    "regression_optimizer = torch.optim.Adam(regression_model.parameters())\n",
    "losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Dataset size: {len(X_titles)}\")\n",
    "print(f\"Number of batches: {len(dataloader)}\")\n",
    "\n",
    "print(f\"X_titles shape: {X_titles.shape}\")\n",
    "print(f\"Y_scores shape: {Y_scores.shape}\")\n",
    "print(f\"Sample batch shapes: {next(iter(dataloader))[0].shape}, {next(iter(dataloader))[1].shape}\")\n",
    "\n",
    "for epoch in range(reg_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (batch_X, batch_y) in enumerate(dataloader):\n",
    "        \n",
    "        # Zero gradients\n",
    "        regression_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = regression_model(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = regression_loss_fn(predictions, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        regression_optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{reg_epochs} | Batch {batch_idx}/{len(dataloader)} | \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{reg_epochs} complete | Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
